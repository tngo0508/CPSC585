{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3x-7PivhUl7i"
   },
   "source": [
    "# THOMAS NGO\n",
    "# TEVIN VU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xI4xQeTjHhBh"
   },
   "source": [
    "# 1. Use from dataset import * to load the module, then examine TRAINING_SET, TEST_SET, and MESSAGE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Kin0nXXuHhBw"
   },
   "outputs": [],
   "source": [
    "from dataset import * \n",
    "from keras.utils import to_categorical\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.activations import softmax\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l1, l2, l1_l2\n",
    "import numpy as np\n",
    "import math\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "13AMoyDVUurK",
    "outputId": "926867be-7d97-420f-ac84-6a5428c38ba1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1], 'A')\n"
     ]
    }
   ],
   "source": [
    "#TRAINING_SET\n",
    "#print letter A data\n",
    "print(TRAINING_SET[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sm5a80-pU5N6",
    "outputId": "02a52f6c-7a34-4854-f85b-157af3409ef7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1], 'A')\n"
     ]
    }
   ],
   "source": [
    "#TEST_SET\n",
    "#print letter A data\n",
    "print(TEST_SET[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wMXUkBzeU7eL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHOX10oEHhBx"
   },
   "source": [
    "# 2. In order to use the images in TRAINING_SET, TEST_SET, and MESSAGE, convert them into two-dimensional NumPy arrays of feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qaxON5woHhBy",
    "outputId": "eebc02c4-cfc7-40c5-c052-0c7a413d5d6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1], 'A')\n"
     ]
    }
   ],
   "source": [
    "print(TRAINING_SET[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zwyV7tPoHhBz"
   },
   "outputs": [],
   "source": [
    "def convert_to_2d(dataset):\n",
    "    if len(dataset) == 0: return None\n",
    "    res = []\n",
    "    if len(dataset[0]) == 2:\n",
    "        for x, _ in dataset:\n",
    "            res.append(np.array(x))\n",
    "    else:\n",
    "        for x in dataset:\n",
    "            res.append(np.array(x))\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_e8cKUW1HhBz"
   },
   "outputs": [],
   "source": [
    "TRAINING_SET_2D = convert_to_2d(TRAINING_SET)\n",
    "TEST_SET_2D = convert_to_2d(TEST_SET)\n",
    "MESSAGE_2D = convert_to_2d(MESSAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G4w4iz19HhB0",
    "outputId": "c2965a29-e359-4ae0-e49e-4f813ecb3f91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 35)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MESSAGE_2D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tjtAZ6OBHhB0",
    "outputId": "623cd1c1-8f2c-42ea-e5c4-f3af60a18240"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 35)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_SET_2D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_497v29KHhB1",
    "outputId": "12cf2159-d680-4490-bca7-238ff469d760"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 35)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_SET_2D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "aQWiWjqeHhB1"
   },
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    n = len(img)\n",
    "    for i in range(n):\n",
    "        if img[i] == 1:\n",
    "            print('#', end='')\n",
    "        else:\n",
    "            print(' ', end='')\n",
    "        if (i+1) % 5 == 0:\n",
    "            print('\\n', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vTDJYq1gHhB2",
    "outputId": "9d9dc9fa-6523-4b8e-d058-fe9e99c3e82e",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ### \n",
      "#   #\n",
      "#   #\n",
      "#   #\n",
      "#####\n",
      "#   #\n",
      "#   #\n"
     ]
    }
   ],
   "source": [
    "show(TRAINING_SET_2D[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymGe9do5HhB4"
   },
   "source": [
    "# 3. In order to use the character labels in TRAINING_SET and TEST_SET, convert them into an integer class vector using ord(), then into one-hot encoded categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "dRH6qtIXHhB5"
   },
   "outputs": [],
   "source": [
    "def convert_labels_to_int(dataset):\n",
    "    res = []\n",
    "    for _, letter in dataset:\n",
    "        res.append(ord(letter)-ord('A'))\n",
    "    \n",
    "    n = len(res)\n",
    "    return to_categorical(res, num_classes=26)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "xhOICpxiHhB5"
   },
   "outputs": [],
   "source": [
    "TRAINING_SET_LABELS = convert_labels_to_int(TRAINING_SET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "brSfn7-kHhB6",
    "outputId": "5300c9ef-4c6e-477b-e184-3938994b0a78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 26)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_SET_LABELS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4SbEroOmHhB6",
    "outputId": "ed44de21-05b3-4a0f-b536-4fc4a0061af5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_SET_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "bRlvx0sOHhB7"
   },
   "outputs": [],
   "source": [
    "TEST_SET_LABELS = convert_labels_to_int(TEST_SET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FH7L53DCHhB7",
    "outputId": "37d30355-0caf-4b23-e1b5-6b32f6330a28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 26)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_SET_LABELS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uuh6RrRuHhB7",
    "outputId": "e731d949-50fa-4267-9bf3-c3c7d173a5ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_SET_LABELS[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWMdme8oHhB8"
   },
   "source": [
    "# 4. Create a Sequential Keras model with a Dense hidden layer and an output layer with softmax activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jc70RaMUHhB9",
    "outputId": "90c005d8-b410-4467-fda8-6e2f9d7eafae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 26)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ask professor about activation function, explain what I understand\n",
    "# can sigmoid be used as activation function?\n",
    "# ask why if I use sigmoid for the first layer, the accuracy is better\n",
    "# than when I use relu.\n",
    "model = Sequential()\n",
    "model.add(Dense(26, \n",
    "                input_shape=(35,), \n",
    "                activation='relu', \n",
    "                kernel_initializer='random_normal',\n",
    "                name=\"hidden_layer_1\"))\n",
    "model.add(Dense(26, \n",
    "                input_shape=(35,), \n",
    "                activation='softmax', \n",
    "                name=\"output_layer\"))\n",
    "\n",
    "model.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cER99leqHhB_"
   },
   "source": [
    "# 5. compile and fit the model to the training set. Train the model until the accuracy is as high as possible. You may wish to use an EarlyStopping callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j04eglNRHhCA",
    "outputId": "4ef1481f-e6f8-4d6e-ff6d-88ab1e7ec922",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "2/2 - 0s - loss: 3.2857 - accuracy: 0.0385\n",
      "Epoch 2/2000\n",
      "2/2 - 0s - loss: 3.2575 - accuracy: 0.0769\n",
      "Epoch 3/2000\n",
      "2/2 - 0s - loss: 3.2383 - accuracy: 0.0769\n",
      "Epoch 4/2000\n",
      "2/2 - 0s - loss: 3.2223 - accuracy: 0.0769\n",
      "Epoch 5/2000\n",
      "2/2 - 0s - loss: 3.2098 - accuracy: 0.0769\n",
      "Epoch 6/2000\n",
      "2/2 - 0s - loss: 3.1997 - accuracy: 0.0962\n",
      "Epoch 7/2000\n",
      "2/2 - 0s - loss: 3.1859 - accuracy: 0.1538\n",
      "Epoch 8/2000\n",
      "2/2 - 0s - loss: 3.1734 - accuracy: 0.1923\n",
      "Epoch 9/2000\n",
      "2/2 - 0s - loss: 3.1621 - accuracy: 0.1538\n",
      "Epoch 10/2000\n",
      "2/2 - 0s - loss: 3.1510 - accuracy: 0.1923\n",
      "Epoch 11/2000\n",
      "2/2 - 0s - loss: 3.1392 - accuracy: 0.1923\n",
      "Epoch 12/2000\n",
      "2/2 - 0s - loss: 3.1291 - accuracy: 0.2115\n",
      "Epoch 13/2000\n",
      "2/2 - 0s - loss: 3.1167 - accuracy: 0.2308\n",
      "Epoch 14/2000\n",
      "2/2 - 0s - loss: 3.1035 - accuracy: 0.2308\n",
      "Epoch 15/2000\n",
      "2/2 - 0s - loss: 3.0914 - accuracy: 0.2500\n",
      "Epoch 16/2000\n",
      "2/2 - 0s - loss: 3.0802 - accuracy: 0.2500\n",
      "Epoch 17/2000\n",
      "2/2 - 0s - loss: 3.0691 - accuracy: 0.2500\n",
      "Epoch 18/2000\n",
      "2/2 - 0s - loss: 3.0594 - accuracy: 0.2500\n",
      "Epoch 19/2000\n",
      "2/2 - 0s - loss: 3.0475 - accuracy: 0.2115\n",
      "Epoch 20/2000\n",
      "2/2 - 0s - loss: 3.0353 - accuracy: 0.2308\n",
      "Epoch 21/2000\n",
      "2/2 - 0s - loss: 3.0249 - accuracy: 0.2308\n",
      "Epoch 22/2000\n",
      "2/2 - 0s - loss: 3.0144 - accuracy: 0.2308\n",
      "Epoch 23/2000\n",
      "2/2 - 0s - loss: 3.0018 - accuracy: 0.2692\n",
      "Epoch 24/2000\n",
      "2/2 - 0s - loss: 2.9933 - accuracy: 0.2692\n",
      "Epoch 25/2000\n",
      "2/2 - 0s - loss: 2.9811 - accuracy: 0.2885\n",
      "Epoch 26/2000\n",
      "2/2 - 0s - loss: 2.9706 - accuracy: 0.2885\n",
      "Epoch 27/2000\n",
      "2/2 - 0s - loss: 2.9570 - accuracy: 0.2885\n",
      "Epoch 28/2000\n",
      "2/2 - 0s - loss: 2.9458 - accuracy: 0.3269\n",
      "Epoch 29/2000\n",
      "2/2 - 0s - loss: 2.9333 - accuracy: 0.3077\n",
      "Epoch 30/2000\n",
      "2/2 - 0s - loss: 2.9207 - accuracy: 0.3269\n",
      "Epoch 31/2000\n",
      "2/2 - 0s - loss: 2.9085 - accuracy: 0.3269\n",
      "Epoch 32/2000\n",
      "2/2 - 0s - loss: 2.8964 - accuracy: 0.3269\n",
      "Epoch 33/2000\n",
      "2/2 - 0s - loss: 2.8830 - accuracy: 0.3077\n",
      "Epoch 34/2000\n",
      "2/2 - 0s - loss: 2.8704 - accuracy: 0.3269\n",
      "Epoch 35/2000\n",
      "2/2 - 0s - loss: 2.8582 - accuracy: 0.3269\n",
      "Epoch 36/2000\n",
      "2/2 - 0s - loss: 2.8441 - accuracy: 0.3077\n",
      "Epoch 37/2000\n",
      "2/2 - 0s - loss: 2.8331 - accuracy: 0.3269\n",
      "Epoch 38/2000\n",
      "2/2 - 0s - loss: 2.8183 - accuracy: 0.3654\n",
      "Epoch 39/2000\n",
      "2/2 - 0s - loss: 2.8067 - accuracy: 0.3846\n",
      "Epoch 40/2000\n",
      "2/2 - 0s - loss: 2.7920 - accuracy: 0.4038\n",
      "Epoch 41/2000\n",
      "2/2 - 0s - loss: 2.7797 - accuracy: 0.4038\n",
      "Epoch 42/2000\n",
      "2/2 - 0s - loss: 2.7645 - accuracy: 0.3846\n",
      "Epoch 43/2000\n",
      "2/2 - 0s - loss: 2.7528 - accuracy: 0.3846\n",
      "Epoch 44/2000\n",
      "2/2 - 0s - loss: 2.7382 - accuracy: 0.4615\n",
      "Epoch 45/2000\n",
      "2/2 - 0s - loss: 2.7247 - accuracy: 0.4423\n",
      "Epoch 46/2000\n",
      "2/2 - 0s - loss: 2.7089 - accuracy: 0.4808\n",
      "Epoch 47/2000\n",
      "2/2 - 0s - loss: 2.6949 - accuracy: 0.4615\n",
      "Epoch 48/2000\n",
      "2/2 - 0s - loss: 2.6840 - accuracy: 0.4423\n",
      "Epoch 49/2000\n",
      "2/2 - 0s - loss: 2.6679 - accuracy: 0.4423\n",
      "Epoch 50/2000\n",
      "2/2 - 0s - loss: 2.6509 - accuracy: 0.4615\n",
      "Epoch 51/2000\n",
      "2/2 - 0s - loss: 2.6389 - accuracy: 0.4231\n",
      "Epoch 52/2000\n",
      "2/2 - 0s - loss: 2.6214 - accuracy: 0.4615\n",
      "Epoch 53/2000\n",
      "2/2 - 0s - loss: 2.6079 - accuracy: 0.4615\n",
      "Epoch 54/2000\n",
      "2/2 - 0s - loss: 2.5932 - accuracy: 0.4808\n",
      "Epoch 55/2000\n",
      "2/2 - 0s - loss: 2.5784 - accuracy: 0.4808\n",
      "Epoch 56/2000\n",
      "2/2 - 0s - loss: 2.5648 - accuracy: 0.5192\n",
      "Epoch 57/2000\n",
      "2/2 - 0s - loss: 2.5491 - accuracy: 0.5192\n",
      "Epoch 58/2000\n",
      "2/2 - 0s - loss: 2.5331 - accuracy: 0.5385\n",
      "Epoch 59/2000\n",
      "2/2 - 0s - loss: 2.5192 - accuracy: 0.5385\n",
      "Epoch 60/2000\n",
      "2/2 - 0s - loss: 2.5035 - accuracy: 0.5385\n",
      "Epoch 61/2000\n",
      "2/2 - 0s - loss: 2.4888 - accuracy: 0.5385\n",
      "Epoch 62/2000\n",
      "2/2 - 0s - loss: 2.4745 - accuracy: 0.5577\n",
      "Epoch 63/2000\n",
      "2/2 - 0s - loss: 2.4594 - accuracy: 0.5577\n",
      "Epoch 64/2000\n",
      "2/2 - 0s - loss: 2.4436 - accuracy: 0.5769\n",
      "Epoch 65/2000\n",
      "2/2 - 0s - loss: 2.4299 - accuracy: 0.5769\n",
      "Epoch 66/2000\n",
      "2/2 - 0s - loss: 2.4131 - accuracy: 0.5769\n",
      "Epoch 67/2000\n",
      "2/2 - 0s - loss: 2.3977 - accuracy: 0.5962\n",
      "Epoch 68/2000\n",
      "2/2 - 0s - loss: 2.3826 - accuracy: 0.5962\n",
      "Epoch 69/2000\n",
      "2/2 - 0s - loss: 2.3666 - accuracy: 0.5769\n",
      "Epoch 70/2000\n",
      "2/2 - 0s - loss: 2.3525 - accuracy: 0.5769\n",
      "Epoch 71/2000\n",
      "2/2 - 0s - loss: 2.3370 - accuracy: 0.5962\n",
      "Epoch 72/2000\n",
      "2/2 - 0s - loss: 2.3197 - accuracy: 0.5769\n",
      "Epoch 73/2000\n",
      "2/2 - 0s - loss: 2.3047 - accuracy: 0.5962\n",
      "Epoch 74/2000\n",
      "2/2 - 0s - loss: 2.2887 - accuracy: 0.5962\n",
      "Epoch 75/2000\n",
      "2/2 - 0s - loss: 2.2732 - accuracy: 0.6154\n",
      "Epoch 76/2000\n",
      "2/2 - 0s - loss: 2.2583 - accuracy: 0.6154\n",
      "Epoch 77/2000\n",
      "2/2 - 0s - loss: 2.2396 - accuracy: 0.6154\n",
      "Epoch 78/2000\n",
      "2/2 - 0s - loss: 2.2258 - accuracy: 0.6154\n",
      "Epoch 79/2000\n",
      "2/2 - 0s - loss: 2.2086 - accuracy: 0.6154\n",
      "Epoch 80/2000\n",
      "2/2 - 0s - loss: 2.1929 - accuracy: 0.6154\n",
      "Epoch 81/2000\n",
      "2/2 - 0s - loss: 2.1771 - accuracy: 0.6346\n",
      "Epoch 82/2000\n",
      "2/2 - 0s - loss: 2.1616 - accuracy: 0.6346\n",
      "Epoch 83/2000\n",
      "2/2 - 0s - loss: 2.1451 - accuracy: 0.6346\n",
      "Epoch 84/2000\n",
      "2/2 - 0s - loss: 2.1295 - accuracy: 0.6346\n",
      "Epoch 85/2000\n",
      "2/2 - 0s - loss: 2.1129 - accuracy: 0.6538\n",
      "Epoch 86/2000\n",
      "2/2 - 0s - loss: 2.0981 - accuracy: 0.6346\n",
      "Epoch 87/2000\n",
      "2/2 - 0s - loss: 2.0804 - accuracy: 0.6346\n",
      "Epoch 88/2000\n",
      "2/2 - 0s - loss: 2.0644 - accuracy: 0.6346\n",
      "Epoch 89/2000\n",
      "2/2 - 0s - loss: 2.0480 - accuracy: 0.6346\n",
      "Epoch 90/2000\n",
      "2/2 - 0s - loss: 2.0330 - accuracy: 0.6346\n",
      "Epoch 91/2000\n",
      "2/2 - 0s - loss: 2.0161 - accuracy: 0.6346\n",
      "Epoch 92/2000\n",
      "2/2 - 0s - loss: 2.0005 - accuracy: 0.6346\n",
      "Epoch 93/2000\n",
      "2/2 - 0s - loss: 1.9853 - accuracy: 0.6346\n",
      "Epoch 94/2000\n",
      "2/2 - 0s - loss: 1.9708 - accuracy: 0.6346\n",
      "Epoch 95/2000\n",
      "2/2 - 0s - loss: 1.9521 - accuracy: 0.6346\n",
      "Epoch 96/2000\n",
      "2/2 - 0s - loss: 1.9374 - accuracy: 0.6346\n",
      "Epoch 97/2000\n",
      "2/2 - 0s - loss: 1.9222 - accuracy: 0.6346\n",
      "Epoch 98/2000\n",
      "2/2 - 0s - loss: 1.9067 - accuracy: 0.6731\n",
      "Epoch 99/2000\n",
      "2/2 - 0s - loss: 1.8917 - accuracy: 0.6731\n",
      "Epoch 100/2000\n",
      "2/2 - 0s - loss: 1.8757 - accuracy: 0.6731\n",
      "Epoch 101/2000\n",
      "2/2 - 0s - loss: 1.8576 - accuracy: 0.6731\n",
      "Epoch 102/2000\n",
      "2/2 - 0s - loss: 1.8412 - accuracy: 0.6731\n",
      "Epoch 103/2000\n",
      "2/2 - 0s - loss: 1.8263 - accuracy: 0.6731\n",
      "Epoch 104/2000\n",
      "2/2 - 0s - loss: 1.8106 - accuracy: 0.6731\n",
      "Epoch 105/2000\n",
      "2/2 - 0s - loss: 1.7962 - accuracy: 0.6731\n",
      "Epoch 106/2000\n",
      "2/2 - 0s - loss: 1.7822 - accuracy: 0.6923\n",
      "Epoch 107/2000\n",
      "2/2 - 0s - loss: 1.7623 - accuracy: 0.6923\n",
      "Epoch 108/2000\n",
      "2/2 - 0s - loss: 1.7479 - accuracy: 0.7308\n",
      "Epoch 109/2000\n",
      "2/2 - 0s - loss: 1.7344 - accuracy: 0.7308\n",
      "Epoch 110/2000\n",
      "2/2 - 0s - loss: 1.7158 - accuracy: 0.7308\n",
      "Epoch 111/2000\n",
      "2/2 - 0s - loss: 1.7025 - accuracy: 0.7308\n",
      "Epoch 112/2000\n",
      "2/2 - 0s - loss: 1.6877 - accuracy: 0.7308\n",
      "Epoch 113/2000\n",
      "2/2 - 0s - loss: 1.6725 - accuracy: 0.7308\n",
      "Epoch 114/2000\n",
      "2/2 - 0s - loss: 1.6554 - accuracy: 0.7308\n",
      "Epoch 115/2000\n",
      "2/2 - 0s - loss: 1.6408 - accuracy: 0.7308\n",
      "Epoch 116/2000\n",
      "2/2 - 0s - loss: 1.6255 - accuracy: 0.7308\n",
      "Epoch 117/2000\n",
      "2/2 - 0s - loss: 1.6113 - accuracy: 0.7308\n",
      "Epoch 118/2000\n",
      "2/2 - 0s - loss: 1.5965 - accuracy: 0.7308\n",
      "Epoch 119/2000\n",
      "2/2 - 0s - loss: 1.5808 - accuracy: 0.7308\n",
      "Epoch 120/2000\n",
      "2/2 - 0s - loss: 1.5669 - accuracy: 0.7308\n",
      "Epoch 121/2000\n",
      "2/2 - 0s - loss: 1.5513 - accuracy: 0.7308\n",
      "Epoch 122/2000\n",
      "2/2 - 0s - loss: 1.5358 - accuracy: 0.7308\n",
      "Epoch 123/2000\n",
      "2/2 - 0s - loss: 1.5199 - accuracy: 0.7308\n",
      "Epoch 124/2000\n",
      "2/2 - 0s - loss: 1.5075 - accuracy: 0.7308\n",
      "Epoch 125/2000\n",
      "2/2 - 0s - loss: 1.4910 - accuracy: 0.7500\n",
      "Epoch 126/2000\n",
      "2/2 - 0s - loss: 1.4779 - accuracy: 0.7692\n",
      "Epoch 127/2000\n",
      "2/2 - 0s - loss: 1.4642 - accuracy: 0.7692\n",
      "Epoch 128/2000\n",
      "2/2 - 0s - loss: 1.4500 - accuracy: 0.7885\n",
      "Epoch 129/2000\n",
      "2/2 - 0s - loss: 1.4369 - accuracy: 0.8269\n",
      "Epoch 130/2000\n",
      "2/2 - 0s - loss: 1.4210 - accuracy: 0.7885\n",
      "Epoch 131/2000\n",
      "2/2 - 0s - loss: 1.4059 - accuracy: 0.8269\n",
      "Epoch 132/2000\n",
      "2/2 - 0s - loss: 1.3959 - accuracy: 0.8462\n",
      "Epoch 133/2000\n",
      "2/2 - 0s - loss: 1.3798 - accuracy: 0.8269\n",
      "Epoch 134/2000\n",
      "2/2 - 0s - loss: 1.3653 - accuracy: 0.8462\n",
      "Epoch 135/2000\n",
      "2/2 - 0s - loss: 1.3535 - accuracy: 0.8654\n",
      "Epoch 136/2000\n",
      "2/2 - 0s - loss: 1.3391 - accuracy: 0.8654\n",
      "Epoch 137/2000\n",
      "2/2 - 0s - loss: 1.3244 - accuracy: 0.8654\n",
      "Epoch 138/2000\n",
      "2/2 - 0s - loss: 1.3106 - accuracy: 0.8654\n",
      "Epoch 139/2000\n",
      "2/2 - 0s - loss: 1.2981 - accuracy: 0.8654\n",
      "Epoch 140/2000\n",
      "2/2 - 0s - loss: 1.2858 - accuracy: 0.8462\n",
      "Epoch 141/2000\n",
      "2/2 - 0s - loss: 1.2713 - accuracy: 0.8654\n",
      "Epoch 142/2000\n",
      "2/2 - 0s - loss: 1.2614 - accuracy: 0.8654\n",
      "Epoch 143/2000\n",
      "2/2 - 0s - loss: 1.2448 - accuracy: 0.8462\n",
      "Epoch 144/2000\n",
      "2/2 - 0s - loss: 1.2324 - accuracy: 0.8654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/2000\n",
      "2/2 - 0s - loss: 1.2236 - accuracy: 0.8654\n",
      "Epoch 146/2000\n",
      "2/2 - 0s - loss: 1.2080 - accuracy: 0.8654\n",
      "Epoch 147/2000\n",
      "2/2 - 0s - loss: 1.1951 - accuracy: 0.8654\n",
      "Epoch 148/2000\n",
      "2/2 - 0s - loss: 1.1831 - accuracy: 0.8654\n",
      "Epoch 149/2000\n",
      "2/2 - 0s - loss: 1.1707 - accuracy: 0.8846\n",
      "Epoch 150/2000\n",
      "2/2 - 0s - loss: 1.1572 - accuracy: 0.9038\n",
      "Epoch 151/2000\n",
      "2/2 - 0s - loss: 1.1460 - accuracy: 0.9038\n",
      "Epoch 152/2000\n",
      "2/2 - 0s - loss: 1.1332 - accuracy: 0.8846\n",
      "Epoch 153/2000\n",
      "2/2 - 0s - loss: 1.1242 - accuracy: 0.9038\n",
      "Epoch 154/2000\n",
      "2/2 - 0s - loss: 1.1106 - accuracy: 0.9038\n",
      "Epoch 155/2000\n",
      "2/2 - 0s - loss: 1.0993 - accuracy: 0.8654\n",
      "Epoch 156/2000\n",
      "2/2 - 0s - loss: 1.0871 - accuracy: 0.9038\n",
      "Epoch 157/2000\n",
      "2/2 - 0s - loss: 1.0741 - accuracy: 0.9423\n",
      "Epoch 158/2000\n",
      "2/2 - 0s - loss: 1.0637 - accuracy: 0.9423\n",
      "Epoch 159/2000\n",
      "2/2 - 0s - loss: 1.0532 - accuracy: 0.9231\n",
      "Epoch 160/2000\n",
      "2/2 - 0s - loss: 1.0429 - accuracy: 0.9423\n",
      "Epoch 161/2000\n",
      "2/2 - 0s - loss: 1.0297 - accuracy: 0.9038\n",
      "Epoch 162/2000\n",
      "2/2 - 0s - loss: 1.0180 - accuracy: 0.9423\n",
      "Epoch 163/2000\n",
      "2/2 - 0s - loss: 1.0086 - accuracy: 0.9038\n",
      "Epoch 164/2000\n",
      "2/2 - 0s - loss: 0.9973 - accuracy: 0.9423\n",
      "Epoch 165/2000\n",
      "2/2 - 0s - loss: 0.9851 - accuracy: 0.9423\n",
      "Epoch 166/2000\n",
      "2/2 - 0s - loss: 0.9755 - accuracy: 0.9423\n",
      "Epoch 167/2000\n",
      "2/2 - 0s - loss: 0.9651 - accuracy: 0.9423\n",
      "Epoch 168/2000\n",
      "2/2 - 0s - loss: 0.9539 - accuracy: 0.9615\n",
      "Epoch 169/2000\n",
      "2/2 - 0s - loss: 0.9448 - accuracy: 0.9615\n",
      "Epoch 170/2000\n",
      "2/2 - 0s - loss: 0.9341 - accuracy: 0.9615\n",
      "Epoch 171/2000\n",
      "2/2 - 0s - loss: 0.9256 - accuracy: 0.9615\n",
      "Epoch 172/2000\n",
      "2/2 - 0s - loss: 0.9133 - accuracy: 0.9615\n",
      "Epoch 173/2000\n",
      "2/2 - 0s - loss: 0.9037 - accuracy: 0.9615\n",
      "Epoch 174/2000\n",
      "2/2 - 0s - loss: 0.8919 - accuracy: 0.9615\n",
      "Epoch 175/2000\n",
      "2/2 - 0s - loss: 0.8867 - accuracy: 0.9615\n",
      "Epoch 176/2000\n",
      "2/2 - 0s - loss: 0.8741 - accuracy: 0.9615\n",
      "Epoch 177/2000\n",
      "2/2 - 0s - loss: 0.8644 - accuracy: 0.9615\n",
      "Epoch 178/2000\n",
      "2/2 - 0s - loss: 0.8544 - accuracy: 0.9615\n",
      "Epoch 179/2000\n",
      "2/2 - 0s - loss: 0.8444 - accuracy: 0.9615\n",
      "Epoch 180/2000\n",
      "2/2 - 0s - loss: 0.8364 - accuracy: 0.9615\n",
      "Epoch 181/2000\n",
      "2/2 - 0s - loss: 0.8287 - accuracy: 0.9615\n",
      "Epoch 182/2000\n",
      "2/2 - 0s - loss: 0.8178 - accuracy: 0.9615\n",
      "Epoch 183/2000\n",
      "2/2 - 0s - loss: 0.8105 - accuracy: 0.9615\n",
      "Epoch 184/2000\n",
      "2/2 - 0s - loss: 0.7995 - accuracy: 0.9615\n",
      "Epoch 185/2000\n",
      "2/2 - 0s - loss: 0.7923 - accuracy: 0.9615\n",
      "Epoch 186/2000\n",
      "2/2 - 0s - loss: 0.7839 - accuracy: 0.9615\n",
      "Epoch 187/2000\n",
      "2/2 - 0s - loss: 0.7724 - accuracy: 0.9615\n",
      "Epoch 188/2000\n",
      "2/2 - 0s - loss: 0.7670 - accuracy: 0.9615\n",
      "Epoch 189/2000\n",
      "2/2 - 0s - loss: 0.7577 - accuracy: 0.9615\n",
      "Epoch 190/2000\n",
      "2/2 - 0s - loss: 0.7479 - accuracy: 0.9615\n",
      "Epoch 191/2000\n",
      "2/2 - 0s - loss: 0.7396 - accuracy: 0.9615\n",
      "Epoch 192/2000\n",
      "2/2 - 0s - loss: 0.7316 - accuracy: 0.9615\n",
      "Epoch 193/2000\n",
      "2/2 - 0s - loss: 0.7239 - accuracy: 0.9615\n",
      "Epoch 194/2000\n",
      "2/2 - 0s - loss: 0.7156 - accuracy: 0.9615\n",
      "Epoch 195/2000\n",
      "2/2 - 0s - loss: 0.7094 - accuracy: 0.9615\n",
      "Epoch 196/2000\n",
      "2/2 - 0s - loss: 0.6984 - accuracy: 0.9808\n",
      "Epoch 197/2000\n",
      "2/2 - 0s - loss: 0.6927 - accuracy: 0.9808\n",
      "Epoch 198/2000\n",
      "2/2 - 0s - loss: 0.6851 - accuracy: 0.9808\n",
      "Epoch 199/2000\n",
      "2/2 - 0s - loss: 0.6767 - accuracy: 0.9808\n",
      "Epoch 200/2000\n",
      "2/2 - 0s - loss: 0.6701 - accuracy: 0.9615\n",
      "Epoch 201/2000\n",
      "2/2 - 0s - loss: 0.6621 - accuracy: 0.9808\n",
      "Epoch 202/2000\n",
      "2/2 - 0s - loss: 0.6577 - accuracy: 0.9808\n",
      "Epoch 203/2000\n",
      "2/2 - 0s - loss: 0.6455 - accuracy: 0.9808\n",
      "Epoch 204/2000\n",
      "2/2 - 0s - loss: 0.6403 - accuracy: 0.9808\n",
      "Epoch 205/2000\n",
      "2/2 - 0s - loss: 0.6328 - accuracy: 0.9808\n",
      "Epoch 206/2000\n",
      "2/2 - 0s - loss: 0.6243 - accuracy: 0.9808\n",
      "Epoch 207/2000\n",
      "2/2 - 0s - loss: 0.6193 - accuracy: 0.9808\n",
      "Epoch 208/2000\n",
      "2/2 - 0s - loss: 0.6128 - accuracy: 0.9808\n",
      "Epoch 209/2000\n",
      "2/2 - 0s - loss: 0.6036 - accuracy: 0.9808\n",
      "Epoch 210/2000\n",
      "2/2 - 0s - loss: 0.6006 - accuracy: 0.9808\n",
      "Epoch 211/2000\n",
      "2/2 - 0s - loss: 0.5915 - accuracy: 0.9808\n",
      "Epoch 212/2000\n",
      "2/2 - 0s - loss: 0.5875 - accuracy: 0.9808\n",
      "Epoch 213/2000\n",
      "2/2 - 0s - loss: 0.5785 - accuracy: 0.9808\n",
      "Epoch 214/2000\n",
      "2/2 - 0s - loss: 0.5735 - accuracy: 0.9808\n",
      "Epoch 215/2000\n",
      "2/2 - 0s - loss: 0.5648 - accuracy: 0.9808\n",
      "Epoch 216/2000\n",
      "2/2 - 0s - loss: 0.5618 - accuracy: 0.9808\n",
      "Epoch 217/2000\n",
      "2/2 - 0s - loss: 0.5550 - accuracy: 0.9808\n",
      "Epoch 218/2000\n",
      "2/2 - 0s - loss: 0.5468 - accuracy: 0.9808\n",
      "Epoch 219/2000\n",
      "2/2 - 0s - loss: 0.5431 - accuracy: 0.9808\n",
      "Epoch 220/2000\n",
      "2/2 - 0s - loss: 0.5350 - accuracy: 0.9808\n",
      "Epoch 221/2000\n",
      "2/2 - 0s - loss: 0.5320 - accuracy: 0.9808\n",
      "Epoch 222/2000\n",
      "2/2 - 0s - loss: 0.5238 - accuracy: 0.9808\n",
      "Epoch 223/2000\n",
      "2/2 - 0s - loss: 0.5207 - accuracy: 0.9808\n",
      "Epoch 224/2000\n",
      "2/2 - 0s - loss: 0.5127 - accuracy: 1.0000\n",
      "Epoch 225/2000\n",
      "2/2 - 0s - loss: 0.5066 - accuracy: 0.9808\n",
      "Epoch 226/2000\n",
      "2/2 - 0s - loss: 0.5026 - accuracy: 1.0000\n",
      "Epoch 227/2000\n",
      "2/2 - 0s - loss: 0.4973 - accuracy: 1.0000\n",
      "Epoch 228/2000\n",
      "2/2 - 0s - loss: 0.4904 - accuracy: 1.0000\n",
      "Epoch 229/2000\n",
      "2/2 - 0s - loss: 0.4865 - accuracy: 0.9808\n",
      "Epoch 230/2000\n",
      "2/2 - 0s - loss: 0.4801 - accuracy: 1.0000\n",
      "Epoch 231/2000\n",
      "2/2 - 0s - loss: 0.4747 - accuracy: 1.0000\n",
      "Epoch 232/2000\n",
      "2/2 - 0s - loss: 0.4701 - accuracy: 1.0000\n",
      "Epoch 233/2000\n",
      "2/2 - 0s - loss: 0.4651 - accuracy: 1.0000\n",
      "Epoch 234/2000\n",
      "2/2 - 0s - loss: 0.4623 - accuracy: 1.0000\n",
      "Epoch 235/2000\n",
      "2/2 - 0s - loss: 0.4554 - accuracy: 1.0000\n",
      "Epoch 236/2000\n",
      "2/2 - 0s - loss: 0.4511 - accuracy: 1.0000\n",
      "Epoch 237/2000\n",
      "2/2 - 0s - loss: 0.4464 - accuracy: 1.0000\n",
      "Epoch 238/2000\n",
      "2/2 - 0s - loss: 0.4430 - accuracy: 1.0000\n",
      "Epoch 239/2000\n",
      "2/2 - 0s - loss: 0.4364 - accuracy: 1.0000\n",
      "Epoch 240/2000\n",
      "2/2 - 0s - loss: 0.4328 - accuracy: 1.0000\n",
      "Epoch 241/2000\n",
      "2/2 - 0s - loss: 0.4269 - accuracy: 1.0000\n",
      "Epoch 242/2000\n",
      "2/2 - 0s - loss: 0.4220 - accuracy: 1.0000\n",
      "Epoch 243/2000\n",
      "2/2 - 0s - loss: 0.4183 - accuracy: 1.0000\n",
      "Epoch 244/2000\n",
      "2/2 - 0s - loss: 0.4138 - accuracy: 1.0000\n",
      "Epoch 245/2000\n",
      "2/2 - 0s - loss: 0.4095 - accuracy: 1.0000\n",
      "Epoch 246/2000\n",
      "2/2 - 0s - loss: 0.4033 - accuracy: 1.0000\n",
      "Epoch 247/2000\n",
      "2/2 - 0s - loss: 0.3999 - accuracy: 1.0000\n",
      "Epoch 248/2000\n",
      "2/2 - 0s - loss: 0.3947 - accuracy: 1.0000\n",
      "Epoch 249/2000\n",
      "2/2 - 0s - loss: 0.3941 - accuracy: 1.0000\n",
      "Epoch 250/2000\n",
      "2/2 - 0s - loss: 0.3872 - accuracy: 1.0000\n",
      "Epoch 251/2000\n",
      "2/2 - 0s - loss: 0.3817 - accuracy: 1.0000\n",
      "Epoch 252/2000\n",
      "2/2 - 0s - loss: 0.3780 - accuracy: 1.0000\n",
      "Epoch 253/2000\n",
      "2/2 - 0s - loss: 0.3737 - accuracy: 1.0000\n",
      "Epoch 254/2000\n",
      "2/2 - 0s - loss: 0.3699 - accuracy: 1.0000\n",
      "Epoch 255/2000\n",
      "2/2 - 0s - loss: 0.3664 - accuracy: 1.0000\n",
      "Epoch 256/2000\n",
      "2/2 - 0s - loss: 0.3621 - accuracy: 1.0000\n",
      "Epoch 257/2000\n",
      "2/2 - 0s - loss: 0.3573 - accuracy: 1.0000\n",
      "Epoch 258/2000\n",
      "2/2 - 0s - loss: 0.3546 - accuracy: 1.0000\n",
      "Epoch 259/2000\n",
      "2/2 - 0s - loss: 0.3510 - accuracy: 1.0000\n",
      "Epoch 260/2000\n",
      "2/2 - 0s - loss: 0.3475 - accuracy: 1.0000\n",
      "Epoch 261/2000\n",
      "2/2 - 0s - loss: 0.3452 - accuracy: 1.0000\n",
      "Epoch 262/2000\n",
      "2/2 - 0s - loss: 0.3390 - accuracy: 1.0000\n",
      "Epoch 263/2000\n",
      "2/2 - 0s - loss: 0.3344 - accuracy: 1.0000\n",
      "Epoch 264/2000\n",
      "2/2 - 0s - loss: 0.3335 - accuracy: 1.0000\n",
      "Epoch 265/2000\n",
      "2/2 - 0s - loss: 0.3288 - accuracy: 1.0000\n",
      "Epoch 266/2000\n",
      "2/2 - 0s - loss: 0.3245 - accuracy: 1.0000\n",
      "Epoch 267/2000\n",
      "2/2 - 0s - loss: 0.3231 - accuracy: 1.0000\n",
      "Epoch 268/2000\n",
      "2/2 - 0s - loss: 0.3175 - accuracy: 1.0000\n",
      "Epoch 269/2000\n",
      "2/2 - 0s - loss: 0.3125 - accuracy: 1.0000\n",
      "Epoch 270/2000\n",
      "2/2 - 0s - loss: 0.3111 - accuracy: 1.0000\n",
      "Epoch 271/2000\n",
      "2/2 - 0s - loss: 0.3072 - accuracy: 1.0000\n",
      "Epoch 272/2000\n",
      "2/2 - 0s - loss: 0.3057 - accuracy: 1.0000\n",
      "Epoch 273/2000\n",
      "2/2 - 0s - loss: 0.2999 - accuracy: 1.0000\n",
      "Epoch 274/2000\n",
      "2/2 - 0s - loss: 0.2994 - accuracy: 1.0000\n",
      "Epoch 275/2000\n",
      "2/2 - 0s - loss: 0.2970 - accuracy: 1.0000\n",
      "Epoch 276/2000\n",
      "2/2 - 0s - loss: 0.2933 - accuracy: 1.0000\n",
      "Epoch 277/2000\n",
      "2/2 - 0s - loss: 0.2864 - accuracy: 1.0000\n",
      "Epoch 278/2000\n",
      "2/2 - 0s - loss: 0.2856 - accuracy: 1.0000\n",
      "Epoch 279/2000\n",
      "2/2 - 0s - loss: 0.2827 - accuracy: 1.0000\n",
      "Epoch 280/2000\n",
      "2/2 - 0s - loss: 0.2810 - accuracy: 1.0000\n",
      "Epoch 281/2000\n",
      "2/2 - 0s - loss: 0.2750 - accuracy: 1.0000\n",
      "Epoch 282/2000\n",
      "2/2 - 0s - loss: 0.2741 - accuracy: 1.0000\n",
      "Epoch 283/2000\n",
      "2/2 - 0s - loss: 0.2718 - accuracy: 1.0000\n",
      "Epoch 284/2000\n",
      "2/2 - 0s - loss: 0.2666 - accuracy: 1.0000\n",
      "Epoch 285/2000\n",
      "2/2 - 0s - loss: 0.2647 - accuracy: 1.0000\n",
      "Epoch 286/2000\n",
      "2/2 - 0s - loss: 0.2618 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 287/2000\n",
      "2/2 - 0s - loss: 0.2598 - accuracy: 1.0000\n",
      "Epoch 288/2000\n",
      "2/2 - 0s - loss: 0.2574 - accuracy: 1.0000\n",
      "Epoch 289/2000\n",
      "2/2 - 0s - loss: 0.2535 - accuracy: 1.0000\n",
      "Epoch 290/2000\n",
      "2/2 - 0s - loss: 0.2521 - accuracy: 1.0000\n",
      "Epoch 291/2000\n",
      "2/2 - 0s - loss: 0.2482 - accuracy: 1.0000\n",
      "Epoch 292/2000\n",
      "2/2 - 0s - loss: 0.2461 - accuracy: 1.0000\n",
      "Epoch 293/2000\n",
      "2/2 - 0s - loss: 0.2429 - accuracy: 1.0000\n",
      "Epoch 294/2000\n",
      "2/2 - 0s - loss: 0.2395 - accuracy: 1.0000\n",
      "Epoch 295/2000\n",
      "2/2 - 0s - loss: 0.2408 - accuracy: 1.0000\n",
      "Epoch 296/2000\n",
      "2/2 - 0s - loss: 0.2344 - accuracy: 1.0000\n",
      "Epoch 297/2000\n",
      "2/2 - 0s - loss: 0.2334 - accuracy: 1.0000\n",
      "Epoch 298/2000\n",
      "2/2 - 0s - loss: 0.2303 - accuracy: 1.0000\n",
      "Epoch 299/2000\n",
      "2/2 - 0s - loss: 0.2276 - accuracy: 1.0000\n",
      "Epoch 300/2000\n",
      "2/2 - 0s - loss: 0.2259 - accuracy: 1.0000\n",
      "Epoch 301/2000\n",
      "2/2 - 0s - loss: 0.2235 - accuracy: 1.0000\n",
      "Epoch 302/2000\n",
      "2/2 - 0s - loss: 0.2198 - accuracy: 1.0000\n",
      "Epoch 303/2000\n",
      "2/2 - 0s - loss: 0.2179 - accuracy: 1.0000\n",
      "Epoch 304/2000\n",
      "2/2 - 0s - loss: 0.2163 - accuracy: 1.0000\n",
      "Epoch 305/2000\n",
      "2/2 - 0s - loss: 0.2129 - accuracy: 1.0000\n",
      "Epoch 306/2000\n",
      "2/2 - 0s - loss: 0.2098 - accuracy: 1.0000\n",
      "Epoch 307/2000\n",
      "2/2 - 0s - loss: 0.2080 - accuracy: 1.0000\n",
      "Epoch 308/2000\n",
      "2/2 - 0s - loss: 0.2088 - accuracy: 1.0000\n",
      "Epoch 309/2000\n",
      "2/2 - 0s - loss: 0.2047 - accuracy: 1.0000\n",
      "Epoch 310/2000\n",
      "2/2 - 0s - loss: 0.2014 - accuracy: 1.0000\n",
      "Epoch 311/2000\n",
      "2/2 - 0s - loss: 0.1993 - accuracy: 1.0000\n",
      "Epoch 312/2000\n",
      "2/2 - 0s - loss: 0.1965 - accuracy: 1.0000\n",
      "Epoch 313/2000\n",
      "2/2 - 0s - loss: 0.1957 - accuracy: 1.0000\n",
      "Epoch 314/2000\n",
      "2/2 - 0s - loss: 0.1940 - accuracy: 1.0000\n",
      "Epoch 315/2000\n",
      "2/2 - 0s - loss: 0.1920 - accuracy: 1.0000\n",
      "Epoch 316/2000\n",
      "2/2 - 0s - loss: 0.1881 - accuracy: 1.0000\n",
      "Epoch 317/2000\n",
      "2/2 - 0s - loss: 0.1868 - accuracy: 1.0000\n",
      "Epoch 318/2000\n",
      "2/2 - 0s - loss: 0.1852 - accuracy: 1.0000\n",
      "Epoch 319/2000\n",
      "2/2 - 0s - loss: 0.1840 - accuracy: 1.0000\n",
      "Epoch 320/2000\n",
      "2/2 - 0s - loss: 0.1811 - accuracy: 1.0000\n",
      "Epoch 321/2000\n",
      "2/2 - 0s - loss: 0.1796 - accuracy: 1.0000\n",
      "Epoch 322/2000\n",
      "2/2 - 0s - loss: 0.1777 - accuracy: 1.0000\n",
      "Epoch 323/2000\n",
      "2/2 - 0s - loss: 0.1768 - accuracy: 1.0000\n",
      "Epoch 324/2000\n",
      "2/2 - 0s - loss: 0.1732 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20092ee8b50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = EarlyStopping(monitor='accuracy', \n",
    "                         patience=100,\n",
    "                         restore_best_weights=True)\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(TRAINING_SET_2D, \n",
    "          TRAINING_SET_LABELS, \n",
    "          epochs=2000,\n",
    "          callbacks=[callback], \n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tVDCPhgLHhCB",
    "outputId": "fe2114f9-fbb9-4ae8-c54d-5f1ec0becc77",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden_layer_1 (Dense)       (None, 26)                936       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 26)                702       \n",
      "=================================================================\n",
      "Total params: 1,638\n",
      "Trainable params: 1,638\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rfg8UH46HhCC"
   },
   "source": [
    "# 6. evaluate the model on TEST_SET. What accuracy do you obtain? If the accuracy is less than 100%, which test images are misclassified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lHsj6kJgHhCC",
    "outputId": "a7136c89-5a5e-4e2a-d2c3-b7e7ec2ada37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 997us/step - loss: 0.6485 - accuracy: 0.9231\n"
     ]
    }
   ],
   "source": [
    "model_eval = model.evaluate(TEST_SET_2D, TEST_SET_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NL00IDq0HhCD",
    "outputId": "39c6ad1c-faec-45e8-fc38-fb843c4d1d49",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FF3T167tHhCD"
   },
   "source": [
    "## What accuracy do you obtain?\n",
    "- We get above 80%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cS5RaX-HhCE"
   },
   "source": [
    "##  If the accuracy is less than 100%, which test images are misclassified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "eNR5EW94HhCE"
   },
   "outputs": [],
   "source": [
    "pred = model.predict(TEST_SET_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vp8E0-hFHhCE",
    "outputId": "0a387540-cb78-43ec-d0a0-312d47708c4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9QmBD4eRHhCE",
    "outputId": "4e454e30-5226-4624-bc20-ff180d930682"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEST_SET_LABELS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21jBMVuHHhCF",
    "outputId": "a220d52d-232d-4cbd-be5c-49d66894f06b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.54328579e-01, 8.35768122e-04, 3.05859103e-05, 9.69880745e-02,\n",
       "        2.32906794e-04, 8.01440270e-04, 5.39286248e-03, 2.64083408e-03,\n",
       "        1.36232688e-04, 1.00417258e-02, 1.03555508e-02, 8.11726146e-04,\n",
       "        3.11657667e-01, 1.42509356e-01, 7.41883297e-04, 3.06754746e-03,\n",
       "        5.41751683e-02, 2.18214989e-02, 2.30996477e-04, 4.53567103e-04,\n",
       "        1.34221243e-03, 5.34600392e-03, 6.44786581e-02, 1.13737192e-02,\n",
       "        1.59700008e-04, 4.56799098e-05],\n",
       "       [6.71770563e-03, 5.24846852e-01, 1.42907817e-02, 2.34660339e-02,\n",
       "        3.53609174e-02, 8.23186710e-03, 1.39266793e-02, 7.01266201e-03,\n",
       "        8.51458870e-04, 3.20004323e-03, 1.57801071e-04, 4.36321879e-03,\n",
       "        3.85783584e-04, 1.23369769e-04, 3.01907677e-02, 5.20337708e-02,\n",
       "        1.23141031e-03, 2.59690434e-02, 2.32228681e-01, 3.15063080e-04,\n",
       "        1.18456446e-02, 2.18078145e-04, 2.98240542e-04, 1.69988016e-05,\n",
       "        2.24614562e-03, 4.70867555e-04],\n",
       "       [1.60071172e-03, 2.65432522e-02, 5.26162744e-01, 3.46874371e-02,\n",
       "        1.84678640e-02, 1.76952302e-03, 2.03184694e-01, 1.20895311e-04,\n",
       "        1.96000352e-03, 1.28709367e-02, 2.66142742e-05, 1.13310842e-02,\n",
       "        8.20556379e-05, 2.09351729e-05, 1.19919762e-01, 3.33436299e-03,\n",
       "        7.69137777e-03, 9.60168312e-04, 1.70348622e-02, 9.04154673e-04,\n",
       "        8.68783146e-03, 5.51449775e-04, 2.46381125e-04, 2.00692375e-06,\n",
       "        1.85843470e-04, 1.65311922e-03],\n",
       "       [2.32004616e-02, 7.10092708e-02, 5.44036515e-02, 3.50391954e-01,\n",
       "        7.25006312e-03, 1.15778635e-03, 1.18958719e-01, 2.19703908e-03,\n",
       "        8.16862041e-04, 2.10215375e-02, 1.11648442e-04, 6.14379905e-03,\n",
       "        3.71522852e-03, 5.20899019e-04, 2.02155858e-01, 1.12753902e-02,\n",
       "        2.52913218e-02, 8.14700034e-03, 2.39584204e-02, 7.51335640e-04,\n",
       "        5.15861288e-02, 8.76459945e-03, 6.23210380e-03, 3.61228522e-05,\n",
       "        3.42371553e-04, 5.60574117e-04],\n",
       "       [3.05133552e-04, 5.99299408e-02, 6.41564280e-03, 1.87460368e-03,\n",
       "        6.47616923e-01, 8.57131332e-02, 3.93211422e-03, 5.83507307e-03,\n",
       "        1.95894111e-03, 2.23410549e-03, 5.52432286e-03, 9.02834982e-02,\n",
       "        6.58127829e-05, 1.66019629e-04, 2.70899455e-03, 1.09504806e-02,\n",
       "        6.50796690e-04, 5.40763931e-03, 5.51026911e-02, 1.32418016e-03,\n",
       "        1.59896933e-03, 1.98022535e-05, 2.38435634e-04, 1.64173573e-04,\n",
       "        1.80324959e-03, 8.17539822e-03],\n",
       "       [6.83736056e-03, 3.18910182e-02, 8.01428570e-04, 1.74783019e-03,\n",
       "        7.85745084e-02, 5.90914726e-01, 2.05096346e-03, 1.32657476e-02,\n",
       "        4.82348230e-04, 1.27896972e-04, 5.17903781e-03, 4.04623942e-03,\n",
       "        1.11008456e-04, 1.05867244e-03, 1.39591389e-03, 1.52994454e-01,\n",
       "        3.39319534e-03, 6.51943460e-02, 2.40944009e-02, 1.86330802e-03,\n",
       "        5.38308232e-04, 5.43709357e-05, 1.64076439e-04, 6.48052373e-04,\n",
       "        1.08690253e-02, 1.70180248e-03],\n",
       "       [7.00273318e-03, 2.58323587e-02, 1.05138540e-01, 5.96225634e-02,\n",
       "        4.24763747e-02, 2.22112355e-03, 4.22182143e-01, 9.77486838e-04,\n",
       "        2.86836829e-03, 1.12459108e-01, 5.12441329e-04, 2.00258698e-02,\n",
       "        1.01717457e-03, 6.61687402e-04, 9.24480259e-02, 1.73636037e-03,\n",
       "        4.57764603e-02, 1.50259002e-03, 1.49100805e-02, 2.54097674e-03,\n",
       "        3.02859824e-02, 1.64310972e-03, 4.96043731e-03, 2.31008653e-05,\n",
       "        2.13261112e-04, 9.61636484e-04],\n",
       "       [2.20973417e-02, 1.43435225e-02, 2.48668475e-05, 4.05804906e-03,\n",
       "        7.57396175e-03, 3.79372225e-03, 4.57545219e-04, 6.79226041e-01,\n",
       "        1.32417888e-04, 1.24135031e-03, 2.83101350e-02, 9.25648084e-04,\n",
       "        2.15261728e-02, 1.17615484e-01, 1.39564369e-03, 1.24315880e-02,\n",
       "        4.80254972e-03, 2.60140635e-02, 8.49014707e-03, 4.99744667e-04,\n",
       "        8.16195179e-03, 1.54660130e-03, 2.49745175e-02, 6.76556304e-03,\n",
       "        3.53199732e-03, 5.94236481e-05],\n",
       "       [1.87378988e-04, 5.54430066e-04, 1.65991485e-03, 2.32884879e-04,\n",
       "        3.32497549e-03, 1.08424039e-03, 6.64117606e-03, 2.86106679e-05,\n",
       "        7.20620036e-01, 3.18728737e-03, 1.89921902e-05, 3.05516087e-03,\n",
       "        1.97529618e-04, 9.09540977e-05, 1.34889013e-03, 8.40625376e-04,\n",
       "        2.95858772e-04, 4.61221614e-04, 4.28237533e-03, 2.32551068e-01,\n",
       "        3.72489711e-04, 1.48112682e-04, 1.34328016e-04, 6.63247920e-05,\n",
       "        9.33132041e-03, 9.28383227e-03],\n",
       "       [4.75713023e-04, 9.99937486e-03, 6.62465580e-03, 1.13035729e-02,\n",
       "        2.57037338e-02, 1.97724579e-03, 3.43343839e-02, 1.90646941e-04,\n",
       "        5.51724434e-03, 8.21763694e-01, 2.15355889e-03, 3.82122546e-02,\n",
       "        2.89013050e-03, 3.00798245e-04, 7.84219895e-03, 9.87440348e-04,\n",
       "        3.31616215e-03, 1.06814865e-03, 3.84184392e-03, 1.64329691e-03,\n",
       "        8.26717820e-03, 1.43052114e-03, 1.35336304e-03, 7.88944191e-04,\n",
       "        1.41894014e-03, 6.59463881e-03],\n",
       "       [9.70303139e-04, 1.48783636e-03, 6.01116108e-06, 1.40428916e-03,\n",
       "        9.23580397e-03, 1.03903245e-02, 9.00298983e-05, 2.38829814e-02,\n",
       "        1.57543356e-04, 1.42187672e-03, 8.26712608e-01, 1.81736797e-02,\n",
       "        9.87630151e-03, 2.49496400e-02, 7.58281094e-05, 6.80150290e-04,\n",
       "        1.53112656e-03, 2.68710824e-03, 1.91122599e-04, 1.74297311e-04,\n",
       "        7.39079551e-04, 2.68714532e-04, 1.72986090e-02, 4.66585271e-02,\n",
       "        5.22607530e-04, 4.13716713e-04],\n",
       "       [2.42508366e-04, 1.47910127e-02, 1.08205359e-02, 1.48281148e-02,\n",
       "        1.30968317e-01, 4.29683831e-03, 5.70013793e-03, 5.26877772e-03,\n",
       "        3.01585440e-03, 2.51227561e-02, 2.21686587e-02, 7.19209075e-01,\n",
       "        2.51082354e-03, 9.49973590e-04, 5.19878278e-03, 1.00219052e-03,\n",
       "        6.78913260e-04, 7.08324427e-04, 6.08059298e-03, 6.36340992e-04,\n",
       "        9.51349456e-03, 2.85332149e-04, 6.54444564e-03, 2.03051511e-03,\n",
       "        3.16349062e-04, 7.11133750e-03],\n",
       "       [1.62291396e-02, 5.61019813e-04, 1.57081092e-06, 9.41795204e-03,\n",
       "        5.09012141e-04, 5.48546726e-04, 2.61772977e-04, 2.48068944e-02,\n",
       "        4.32366855e-04, 3.67176207e-03, 2.56097335e-02, 1.20437855e-03,\n",
       "        3.99585247e-01, 3.44486266e-01, 3.45628359e-04, 3.09594790e-03,\n",
       "        5.35964360e-03, 8.74454807e-03, 2.78454798e-04, 1.31385750e-03,\n",
       "        1.81311800e-03, 3.27861751e-03, 9.24086124e-02, 5.50506674e-02,\n",
       "        9.10622941e-04, 7.47843078e-05],\n",
       "       [5.09778187e-02, 9.57562181e-04, 5.72601130e-06, 1.02585554e-02,\n",
       "        8.37510452e-04, 9.95430863e-04, 1.08770095e-03, 1.03716359e-01,\n",
       "        1.83082593e-04, 2.86512007e-03, 1.98349450e-02, 5.10098645e-04,\n",
       "        1.38527349e-01, 4.97305512e-01, 8.74348276e-04, 3.41153471e-03,\n",
       "        1.89607255e-02, 9.90312453e-03, 4.54422930e-04, 1.30259863e-03,\n",
       "        6.06632140e-03, 5.53789269e-03, 9.40539017e-02, 2.97040213e-02,\n",
       "        1.64576143e-03, 2.26780248e-05],\n",
       "       [1.22297136e-02, 2.86170393e-02, 1.05895773e-01, 1.28165394e-01,\n",
       "        2.48582452e-03, 2.86525406e-04, 2.25728616e-01, 4.68823971e-04,\n",
       "        5.44853450e-04, 2.55634021e-02, 1.67433409e-05, 1.24808331e-03,\n",
       "        8.16327927e-04, 1.62250217e-04, 3.63744378e-01, 3.14563280e-03,\n",
       "        3.71745303e-02, 1.61840394e-03, 9.30421241e-03, 5.93422446e-04,\n",
       "        4.20872681e-02, 8.08764994e-03, 1.70549005e-03, 2.40752433e-06,\n",
       "        1.69607185e-04, 1.37473500e-04],\n",
       "       [4.05215845e-02, 3.88077162e-02, 6.25653833e-04, 5.76038659e-03,\n",
       "        7.30717462e-03, 1.33451432e-01, 2.20386568e-03, 8.19991250e-03,\n",
       "        2.22537652e-04, 5.10932150e-05, 4.58169205e-04, 4.67506616e-04,\n",
       "        3.32683703e-04, 1.10163505e-03, 2.98438780e-03, 4.77136314e-01,\n",
       "        6.72169635e-03, 2.38235533e-01, 2.09201630e-02, 9.64397623e-04,\n",
       "        4.30466345e-04, 1.47696977e-04, 1.17604817e-04, 1.86720004e-04,\n",
       "        1.23325130e-02, 3.11078358e-04],\n",
       "       [6.79034218e-02, 2.54680240e-03, 3.20903026e-03, 1.05744712e-01,\n",
       "        7.02162390e-04, 5.68274991e-04, 6.24054819e-02, 8.87950824e-04,\n",
       "        1.56748036e-04, 5.19663887e-03, 1.89942803e-04, 3.53037118e-04,\n",
       "        4.53026406e-03, 3.21980240e-03, 3.97669710e-02, 2.05566734e-03,\n",
       "        6.43246710e-01, 8.18634778e-03, 6.02331012e-04, 1.28317147e-03,\n",
       "        6.80491980e-03, 2.62958594e-02, 1.38370628e-02, 3.38511963e-05,\n",
       "        1.81947646e-04, 9.08418224e-05],\n",
       "       [1.00535728e-01, 1.38167692e-02, 8.10743368e-05, 7.12931901e-03,\n",
       "        5.15588140e-03, 1.09001622e-01, 1.05604273e-03, 2.03940161e-02,\n",
       "        1.45543410e-04, 4.68978906e-05, 4.54445975e-03, 4.55674774e-04,\n",
       "        1.90589135e-03, 8.69424269e-03, 6.43121195e-04, 1.47598803e-01,\n",
       "        3.10623944e-02, 5.30398011e-01, 5.92143182e-03, 1.10906572e-03,\n",
       "        2.85108836e-04, 3.54356336e-04, 1.51018740e-03, 1.39603589e-03,\n",
       "        6.40804321e-03, 3.50310787e-04],\n",
       "       [2.97146081e-03, 2.33141676e-01, 6.38582483e-02, 1.21998638e-02,\n",
       "        3.40887494e-02, 6.23841211e-03, 4.18910086e-02, 1.39764592e-03,\n",
       "        6.28442131e-03, 8.17090273e-03, 5.25481300e-05, 4.42322809e-03,\n",
       "        2.14669897e-04, 4.53747671e-05, 3.99581939e-02, 3.66910584e-02,\n",
       "        1.18864374e-03, 1.21457204e-02, 4.76631790e-01, 1.32821174e-03,\n",
       "        1.00902794e-02, 2.73495622e-04, 2.08590704e-04, 1.13784490e-05,\n",
       "        3.77461198e-03, 2.71966937e-03],\n",
       "       [5.52352285e-04, 1.63907665e-04, 1.34534304e-04, 1.16857445e-04,\n",
       "        8.74517253e-04, 3.11989174e-03, 1.06674503e-03, 8.76022677e-05,\n",
       "        1.59289956e-01, 1.87311991e-04, 2.05758570e-05, 1.56469207e-04,\n",
       "        1.80232251e-04, 3.14898876e-04, 1.00955879e-03, 3.85596673e-03,\n",
       "        1.75723433e-03, 1.98074989e-03, 7.99217203e-04, 7.08213508e-01,\n",
       "        3.38740501e-04, 1.11126807e-03, 1.27089486e-04, 2.20782618e-04,\n",
       "        1.07580073e-01, 6.73989858e-03],\n",
       "       [7.97468470e-04, 2.65185274e-02, 6.74873963e-03, 2.14855950e-02,\n",
       "        7.10344268e-03, 1.35368537e-04, 9.37849376e-03, 1.27516948e-02,\n",
       "        9.64982901e-04, 1.33898333e-01, 1.01072842e-03, 5.65069634e-03,\n",
       "        4.77220817e-03, 8.30657547e-04, 9.79265571e-02, 5.09374193e-04,\n",
       "        2.79817800e-03, 3.30951065e-04, 4.79124486e-03, 4.70368657e-04,\n",
       "        5.95456660e-01, 4.49002534e-02, 1.87209118e-02, 2.23127106e-04,\n",
       "        1.35751930e-03, 4.68025770e-04],\n",
       "       [2.21078517e-03, 6.47176348e-04, 3.09900614e-04, 1.36404661e-02,\n",
       "        2.81993125e-04, 7.95461820e-05, 1.74376555e-03, 4.95238649e-03,\n",
       "        1.60400479e-04, 4.83549898e-03, 4.26825718e-04, 1.77347465e-04,\n",
       "        5.38365031e-03, 1.54722319e-03, 1.61561985e-02, 2.53960985e-04,\n",
       "        3.87415886e-02, 8.54176702e-04, 2.36162974e-04, 9.80499550e-04,\n",
       "        5.57009093e-02, 7.83860207e-01, 6.45519495e-02, 7.51220796e-04,\n",
       "        1.01872731e-03, 4.97461529e-04],\n",
       "       [9.89141129e-03, 3.86304520e-02, 9.26402339e-04, 1.31539311e-02,\n",
       "        1.09953741e-02, 1.66313373e-03, 8.40863399e-03, 7.30205998e-02,\n",
       "        2.01005042e-02, 7.48481080e-02, 8.29884131e-03, 5.27013186e-03,\n",
       "        4.15010937e-02, 2.01404020e-02, 3.22091356e-02, 5.38392505e-03,\n",
       "        7.11638434e-03, 6.51999470e-03, 1.32916356e-02, 1.19960913e-02,\n",
       "        4.17100608e-01, 5.20691015e-02, 6.36448190e-02, 5.47000347e-03,\n",
       "        5.71648143e-02, 1.18449004e-03],\n",
       "       [3.83791234e-03, 9.83750098e-04, 1.95780358e-05, 2.49407114e-03,\n",
       "        4.96786414e-03, 9.03189834e-03, 2.97596212e-04, 1.28285876e-02,\n",
       "        3.29172658e-03, 4.08019964e-03, 4.78022806e-02, 4.63337451e-03,\n",
       "        3.12009584e-02, 2.19775755e-02, 1.43826954e-04, 6.59602834e-03,\n",
       "        9.95870447e-04, 1.30473636e-02, 1.28542131e-03, 4.07680962e-03,\n",
       "        2.27495492e-03, 2.94311345e-03, 2.52347589e-02, 7.67435014e-01,\n",
       "        1.30283963e-02, 1.54909994e-02],\n",
       "       [4.84865363e-04, 8.84152716e-04, 6.36678014e-05, 2.32047780e-04,\n",
       "        1.85041502e-03, 3.47897457e-03, 4.03801008e-04, 1.28649105e-03,\n",
       "        2.65927725e-02, 2.92230025e-03, 1.05040101e-03, 3.75296280e-04,\n",
       "        1.56602089e-03, 1.07108674e-03, 1.08850596e-03, 4.82537225e-03,\n",
       "        1.13699841e-03, 2.97090271e-03, 6.79268909e-04, 5.08829355e-02,\n",
       "        5.89115079e-03, 7.87531119e-03, 5.20352274e-04, 9.41968616e-03,\n",
       "        8.65078986e-01, 7.36824889e-03],\n",
       "       [3.09618219e-04, 2.56218333e-02, 5.07078413e-03, 1.49069983e-03,\n",
       "        1.47908911e-01, 2.14206688e-02, 1.01952290e-03, 1.95456995e-03,\n",
       "        1.58725157e-02, 5.06670913e-03, 2.36814213e-03, 2.02534422e-02,\n",
       "        3.00892949e-04, 7.74231594e-05, 9.66934313e-04, 8.13675672e-03,\n",
       "        3.45033011e-04, 1.66573953e-02, 5.66331968e-02, 6.74572727e-03,\n",
       "        2.55837664e-03, 4.54813358e-04, 7.40078744e-04, 3.34272883e-03,\n",
       "        1.65172201e-02, 6.38166070e-01]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7QCjnzlrHhCF"
   },
   "source": [
    "## If the accuracy is less than 100%, which test images are misclassified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Sz51JUUaHhCI"
   },
   "outputs": [],
   "source": [
    "def show_misclassified_img(pred):\n",
    "    n = len(pred)\n",
    "    if n == 0: return None\n",
    "    res = []\n",
    "    misclf_count = 0\n",
    "    for i in range(n):\n",
    "        # inspired from https://stackoverflow.com/questions/6193498/pythonic-way-to-find-maximum-value-and-its-index-in-a-list\n",
    "        idx, _ = max(enumerate(pred[i]), key=operator.itemgetter(1))\n",
    "        curr = chr(idx + ord('A'))\n",
    "        true_letter = chr(i + ord('A'))\n",
    "        if curr != true_letter:\n",
    "            prompt = 'Pred: ' + curr + ' True: ' + true_letter\n",
    "            print(prompt)\n",
    "            res += true_letter\n",
    "            misclf_count += 1\n",
    "    return [res, misclf_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VDV4HctPHhCJ",
    "outputId": "00fd0226-e303-4ac4-e624-c221b06bed31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: M True: A\n",
      "Pred: U True: W\n"
     ]
    }
   ],
   "source": [
    "misclassfication_orgin_model = show_misclassified_img(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C__3xc0FHhCJ"
   },
   "source": [
    "## test images are misclassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DI3ADbNxHhCJ",
    "outputId": "b7e19919-79e0-4ec8-ca0e-0f3eea7a8809"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'W']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassfication_orgin_model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xLjRk5MiHhCK",
    "outputId": "926ec66b-3edc-427d-84e8-f04a2a1fe27f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9230769230769231"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(26-misclassfication_orgin_model[1])/26 # accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xpXyX-97HhCL",
    "outputId": "b50ef760-335c-41fa-82fa-d67eedd74831"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9230769276618958"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_eval[1] # accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cmbgJsduHhCL"
   },
   "source": [
    "# 7. Use your trained model and chr() to identify the letters in MESSAGE. What does it say in English? (Note that there are no spaces between words.) Why do you suppose this was chosen as the message?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xHhCzpfnHhCL",
    "outputId": "e05a9231-cb0b-49b4-f67a-06f7e87d7031"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(MESSAGE_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h1txu00GHhCM",
    "outputId": "81074584-552e-4eb8-f3d7-dd628613ee41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(MESSAGE_2D[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "LhL9kf9eHhCM"
   },
   "outputs": [],
   "source": [
    "msg_pred_arr = model.predict(MESSAGE_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p1KurFGHHhCM",
    "outputId": "9b5ed56a-e770-4446-b65e-f18960a86df4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(msg_pred_arr[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TG57BXr_HhCM"
   },
   "source": [
    "## What does it say in English?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "TmvUTQj5HhCN",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_msg_pred(msg_pred):\n",
    "    res = \"\"\n",
    "    for letter_img in msg_pred:\n",
    "        idx, _ = max(enumerate(letter_img), key=operator.itemgetter(1))\n",
    "        letter_pred = chr(idx + ord('A'))\n",
    "        print(letter_pred, end='')\n",
    "        res += letter_pred\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0DPASIjDHhCN",
    "outputId": "74ddf66f-6e6d-40ea-9cba-9291f3956036"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UATCHJEOPARDYMLEXTREBEKSFUNTVQUIZGAME"
     ]
    }
   ],
   "source": [
    "msg_pred = get_msg_pred(msg_pred_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ux7kVVR4HhCN"
   },
   "source": [
    "## Why do you suppose this was chosen as the message?\n",
    "WATCHJEOPARDYALEXTREBEKSFUNTVQUIZGAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKqv2hdvHhCN"
   },
   "source": [
    "## Compare the true message with predicted message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "NzvKvAToHhCO"
   },
   "outputs": [],
   "source": [
    "def compare_with_true_message(msg_pred):\n",
    "    true_msg = \"WATCHJEOPARDYALEXTREBEKSFUNTVQUIZGAME\"\n",
    "    print('{:<7}{:<7}'.format(\"True\", \"Predict\"))\n",
    "    for true_letter, pred_letter in zip(true_msg, msg_pred):\n",
    "        if true_letter != pred_letter:\n",
    "            print('{:<7}{:<7}'.format(true_letter, pred_letter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dEF5LUiiHhCP",
    "outputId": "048593d4-0102-46f6-d6a2-bf9e4acc55ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True   Predict\n",
      "W      U      \n",
      "A      M      \n"
     ]
    }
   ],
   "source": [
    "compare_with_true_message(msg_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-q2fMtvFHhCP"
   },
   "source": [
    "## If you completed Project 1, how does this model compare with the performance of your perceptron models? Were any letters misclassified?\n",
    "This model performs far better than project 1. And, yes there are still some letters that are misclassified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vhUKAcLIHhCQ"
   },
   "source": [
    "# 8. All of the letters in MESSAGE were likely not decoded correctly, so lets try to improve the performance of the model by adding additional hidden layers. Add two additional hidden layers of the same size as your original hidden layer, then repeat experiments (5) and (7). Does the performance improve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VNwzjGKwHhCQ",
    "outputId": "65aed4a1-7c27-4ec2-e311-e052e7d63686"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 26)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_mul_layers = Sequential()\n",
    "model_with_mul_layers.add(Dense(26, \n",
    "                input_shape=(35,), \n",
    "                kernel_initializer='random_normal',\n",
    "                activation='relu',\n",
    "                name=\"hidden_layer_1\"))\n",
    "model_with_mul_layers.add(Dense(26, \n",
    "                input_shape=(35,), \n",
    "                activation='relu',\n",
    "                name=\"hidden_layer_2\"))\n",
    "model_with_mul_layers.add(Dense(26, \n",
    "                input_shape=(35,), \n",
    "                activation='relu',\n",
    "                name=\"hidden_layer_3\"))\n",
    "model_with_mul_layers.add(Dense(26, \n",
    "                input_shape=(35,), \n",
    "                activation='softmax', \n",
    "                name=\"output_layer\"))\n",
    "# model_with_mul_layers.add(Activation('softmax'))\n",
    "model_with_mul_layers.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dkhrSN-lHhCR",
    "outputId": "d128dc12-e7e3-404f-b915-d878ff2f7508"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "2/2 - 0s - loss: 3.2669 - accuracy: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "2/2 - 0s - loss: 3.2458 - accuracy: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "2/2 - 0s - loss: 3.2374 - accuracy: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "2/2 - 0s - loss: 3.2271 - accuracy: 0.0000e+00\n",
      "Epoch 5/2000\n",
      "2/2 - 0s - loss: 3.2206 - accuracy: 0.0000e+00\n",
      "Epoch 6/2000\n",
      "2/2 - 0s - loss: 3.2138 - accuracy: 0.0385\n",
      "Epoch 7/2000\n",
      "2/2 - 0s - loss: 3.2059 - accuracy: 0.0192\n",
      "Epoch 8/2000\n",
      "2/2 - 0s - loss: 3.1974 - accuracy: 0.0385\n",
      "Epoch 9/2000\n",
      "2/2 - 0s - loss: 3.1898 - accuracy: 0.0962\n",
      "Epoch 10/2000\n",
      "2/2 - 0s - loss: 3.1831 - accuracy: 0.0577\n",
      "Epoch 11/2000\n",
      "2/2 - 0s - loss: 3.1725 - accuracy: 0.0962\n",
      "Epoch 12/2000\n",
      "2/2 - 0s - loss: 3.1660 - accuracy: 0.0769\n",
      "Epoch 13/2000\n",
      "2/2 - 0s - loss: 3.1563 - accuracy: 0.0962\n",
      "Epoch 14/2000\n",
      "2/2 - 0s - loss: 3.1472 - accuracy: 0.0962\n",
      "Epoch 15/2000\n",
      "2/2 - 0s - loss: 3.1369 - accuracy: 0.1154\n",
      "Epoch 16/2000\n",
      "2/2 - 0s - loss: 3.1280 - accuracy: 0.0962\n",
      "Epoch 17/2000\n",
      "2/2 - 0s - loss: 3.1175 - accuracy: 0.1731\n",
      "Epoch 18/2000\n",
      "2/2 - 0s - loss: 3.1061 - accuracy: 0.1538\n",
      "Epoch 19/2000\n",
      "2/2 - 0s - loss: 3.0942 - accuracy: 0.1346\n",
      "Epoch 20/2000\n",
      "2/2 - 0s - loss: 3.0833 - accuracy: 0.1538\n",
      "Epoch 21/2000\n",
      "2/2 - 0s - loss: 3.0699 - accuracy: 0.1346\n",
      "Epoch 22/2000\n",
      "2/2 - 0s - loss: 3.0556 - accuracy: 0.1923\n",
      "Epoch 23/2000\n",
      "2/2 - 0s - loss: 3.0428 - accuracy: 0.1731\n",
      "Epoch 24/2000\n",
      "2/2 - 0s - loss: 3.0283 - accuracy: 0.1731\n",
      "Epoch 25/2000\n",
      "2/2 - 0s - loss: 3.0140 - accuracy: 0.1923\n",
      "Epoch 26/2000\n",
      "2/2 - 0s - loss: 2.9982 - accuracy: 0.1923\n",
      "Epoch 27/2000\n",
      "2/2 - 0s - loss: 2.9834 - accuracy: 0.1923\n",
      "Epoch 28/2000\n",
      "2/2 - 0s - loss: 2.9659 - accuracy: 0.1923\n",
      "Epoch 29/2000\n",
      "2/2 - 0s - loss: 2.9491 - accuracy: 0.1923\n",
      "Epoch 30/2000\n",
      "2/2 - 0s - loss: 2.9369 - accuracy: 0.1923\n",
      "Epoch 31/2000\n",
      "2/2 - 0s - loss: 2.9162 - accuracy: 0.1923\n",
      "Epoch 32/2000\n",
      "2/2 - 0s - loss: 2.8963 - accuracy: 0.2500\n",
      "Epoch 33/2000\n",
      "2/2 - 0s - loss: 2.8808 - accuracy: 0.2692\n",
      "Epoch 34/2000\n",
      "2/2 - 0s - loss: 2.8618 - accuracy: 0.2500\n",
      "Epoch 35/2000\n",
      "2/2 - 0s - loss: 2.8440 - accuracy: 0.2500\n",
      "Epoch 36/2000\n",
      "2/2 - 0s - loss: 2.8235 - accuracy: 0.3269\n",
      "Epoch 37/2000\n",
      "2/2 - 0s - loss: 2.8052 - accuracy: 0.3077\n",
      "Epoch 38/2000\n",
      "2/2 - 0s - loss: 2.7853 - accuracy: 0.3077\n",
      "Epoch 39/2000\n",
      "2/2 - 0s - loss: 2.7663 - accuracy: 0.3462\n",
      "Epoch 40/2000\n",
      "2/2 - 0s - loss: 2.7453 - accuracy: 0.3654\n",
      "Epoch 41/2000\n",
      "2/2 - 0s - loss: 2.7260 - accuracy: 0.3654\n",
      "Epoch 42/2000\n",
      "2/2 - 0s - loss: 2.7071 - accuracy: 0.3654\n",
      "Epoch 43/2000\n",
      "2/2 - 0s - loss: 2.6863 - accuracy: 0.3654\n",
      "Epoch 44/2000\n",
      "2/2 - 0s - loss: 2.6635 - accuracy: 0.3654\n",
      "Epoch 45/2000\n",
      "2/2 - 0s - loss: 2.6383 - accuracy: 0.3462\n",
      "Epoch 46/2000\n",
      "2/2 - 0s - loss: 2.6196 - accuracy: 0.4038\n",
      "Epoch 47/2000\n",
      "2/2 - 0s - loss: 2.5982 - accuracy: 0.3654\n",
      "Epoch 48/2000\n",
      "2/2 - 0s - loss: 2.5811 - accuracy: 0.3654\n",
      "Epoch 49/2000\n",
      "2/2 - 0s - loss: 2.5530 - accuracy: 0.4038\n",
      "Epoch 50/2000\n",
      "2/2 - 0s - loss: 2.5279 - accuracy: 0.4038\n",
      "Epoch 51/2000\n",
      "2/2 - 0s - loss: 2.5041 - accuracy: 0.4808\n",
      "Epoch 52/2000\n",
      "2/2 - 0s - loss: 2.4906 - accuracy: 0.3462\n",
      "Epoch 53/2000\n",
      "2/2 - 0s - loss: 2.4594 - accuracy: 0.5000\n",
      "Epoch 54/2000\n",
      "2/2 - 0s - loss: 2.4385 - accuracy: 0.4808\n",
      "Epoch 55/2000\n",
      "2/2 - 0s - loss: 2.4149 - accuracy: 0.5000\n",
      "Epoch 56/2000\n",
      "2/2 - 0s - loss: 2.3928 - accuracy: 0.5192\n",
      "Epoch 57/2000\n",
      "2/2 - 0s - loss: 2.3642 - accuracy: 0.5192\n",
      "Epoch 58/2000\n",
      "2/2 - 0s - loss: 2.3424 - accuracy: 0.4615\n",
      "Epoch 59/2000\n",
      "2/2 - 0s - loss: 2.3184 - accuracy: 0.5385\n",
      "Epoch 60/2000\n",
      "2/2 - 0s - loss: 2.2940 - accuracy: 0.5577\n",
      "Epoch 61/2000\n",
      "2/2 - 0s - loss: 2.2696 - accuracy: 0.5385\n",
      "Epoch 62/2000\n",
      "2/2 - 0s - loss: 2.2465 - accuracy: 0.5385\n",
      "Epoch 63/2000\n",
      "2/2 - 0s - loss: 2.2204 - accuracy: 0.5769\n",
      "Epoch 64/2000\n",
      "2/2 - 0s - loss: 2.1980 - accuracy: 0.5385\n",
      "Epoch 65/2000\n",
      "2/2 - 0s - loss: 2.1652 - accuracy: 0.6154\n",
      "Epoch 66/2000\n",
      "2/2 - 0s - loss: 2.1368 - accuracy: 0.6154\n",
      "Epoch 67/2000\n",
      "2/2 - 0s - loss: 2.1107 - accuracy: 0.6538\n",
      "Epoch 68/2000\n",
      "2/2 - 0s - loss: 2.0932 - accuracy: 0.5962\n",
      "Epoch 69/2000\n",
      "2/2 - 0s - loss: 2.0629 - accuracy: 0.6538\n",
      "Epoch 70/2000\n",
      "2/2 - 0s - loss: 2.0359 - accuracy: 0.6154\n",
      "Epoch 71/2000\n",
      "2/2 - 0s - loss: 2.0087 - accuracy: 0.6346\n",
      "Epoch 72/2000\n",
      "2/2 - 0s - loss: 1.9760 - accuracy: 0.7115\n",
      "Epoch 73/2000\n",
      "2/2 - 0s - loss: 1.9471 - accuracy: 0.6731\n",
      "Epoch 74/2000\n",
      "2/2 - 0s - loss: 1.9195 - accuracy: 0.6923\n",
      "Epoch 75/2000\n",
      "2/2 - 0s - loss: 1.8940 - accuracy: 0.7115\n",
      "Epoch 76/2000\n",
      "2/2 - 0s - loss: 1.8606 - accuracy: 0.7115\n",
      "Epoch 77/2000\n",
      "2/2 - 0s - loss: 1.8364 - accuracy: 0.7308\n",
      "Epoch 78/2000\n",
      "2/2 - 0s - loss: 1.8042 - accuracy: 0.7308\n",
      "Epoch 79/2000\n",
      "2/2 - 0s - loss: 1.7793 - accuracy: 0.7308\n",
      "Epoch 80/2000\n",
      "2/2 - 0s - loss: 1.7506 - accuracy: 0.7500\n",
      "Epoch 81/2000\n",
      "2/2 - 0s - loss: 1.7239 - accuracy: 0.7500\n",
      "Epoch 82/2000\n",
      "2/2 - 0s - loss: 1.6943 - accuracy: 0.7500\n",
      "Epoch 83/2000\n",
      "2/2 - 0s - loss: 1.6743 - accuracy: 0.7308\n",
      "Epoch 84/2000\n",
      "2/2 - 0s - loss: 1.6395 - accuracy: 0.7500\n",
      "Epoch 85/2000\n",
      "2/2 - 0s - loss: 1.6128 - accuracy: 0.7500\n",
      "Epoch 86/2000\n",
      "2/2 - 0s - loss: 1.5891 - accuracy: 0.7500\n",
      "Epoch 87/2000\n",
      "2/2 - 0s - loss: 1.5588 - accuracy: 0.7500\n",
      "Epoch 88/2000\n",
      "2/2 - 0s - loss: 1.5330 - accuracy: 0.7500\n",
      "Epoch 89/2000\n",
      "2/2 - 0s - loss: 1.5057 - accuracy: 0.7500\n",
      "Epoch 90/2000\n",
      "2/2 - 0s - loss: 1.4795 - accuracy: 0.7500\n",
      "Epoch 91/2000\n",
      "2/2 - 0s - loss: 1.4482 - accuracy: 0.8077\n",
      "Epoch 92/2000\n",
      "2/2 - 0s - loss: 1.4237 - accuracy: 0.7885\n",
      "Epoch 93/2000\n",
      "2/2 - 0s - loss: 1.3945 - accuracy: 0.8269\n",
      "Epoch 94/2000\n",
      "2/2 - 0s - loss: 1.3674 - accuracy: 0.8077\n",
      "Epoch 95/2000\n",
      "2/2 - 0s - loss: 1.3377 - accuracy: 0.8269\n",
      "Epoch 96/2000\n",
      "2/2 - 0s - loss: 1.3198 - accuracy: 0.7885\n",
      "Epoch 97/2000\n",
      "2/2 - 0s - loss: 1.2914 - accuracy: 0.8269\n",
      "Epoch 98/2000\n",
      "2/2 - 0s - loss: 1.2657 - accuracy: 0.8462\n",
      "Epoch 99/2000\n",
      "2/2 - 0s - loss: 1.2448 - accuracy: 0.8462\n",
      "Epoch 100/2000\n",
      "2/2 - 0s - loss: 1.2152 - accuracy: 0.8846\n",
      "Epoch 101/2000\n",
      "2/2 - 0s - loss: 1.1888 - accuracy: 0.8462\n",
      "Epoch 102/2000\n",
      "2/2 - 0s - loss: 1.1623 - accuracy: 0.9038\n",
      "Epoch 103/2000\n",
      "2/2 - 0s - loss: 1.1378 - accuracy: 0.9038\n",
      "Epoch 104/2000\n",
      "2/2 - 0s - loss: 1.1184 - accuracy: 0.8654\n",
      "Epoch 105/2000\n",
      "2/2 - 0s - loss: 1.0944 - accuracy: 0.9038\n",
      "Epoch 106/2000\n",
      "2/2 - 0s - loss: 1.0675 - accuracy: 0.9038\n",
      "Epoch 107/2000\n",
      "2/2 - 0s - loss: 1.0493 - accuracy: 0.9231\n",
      "Epoch 108/2000\n",
      "2/2 - 0s - loss: 1.0250 - accuracy: 0.9231\n",
      "Epoch 109/2000\n",
      "2/2 - 0s - loss: 1.0014 - accuracy: 0.9231\n",
      "Epoch 110/2000\n",
      "2/2 - 0s - loss: 0.9753 - accuracy: 0.9423\n",
      "Epoch 111/2000\n",
      "2/2 - 0s - loss: 0.9594 - accuracy: 0.9231\n",
      "Epoch 112/2000\n",
      "2/2 - 0s - loss: 0.9327 - accuracy: 0.9423\n",
      "Epoch 113/2000\n",
      "2/2 - 0s - loss: 0.9083 - accuracy: 0.9423\n",
      "Epoch 114/2000\n",
      "2/2 - 0s - loss: 0.8897 - accuracy: 0.9423\n",
      "Epoch 115/2000\n",
      "2/2 - 0s - loss: 0.8665 - accuracy: 0.9423\n",
      "Epoch 116/2000\n",
      "2/2 - 0s - loss: 0.8520 - accuracy: 0.9423\n",
      "Epoch 117/2000\n",
      "2/2 - 0s - loss: 0.8264 - accuracy: 0.9423\n",
      "Epoch 118/2000\n",
      "2/2 - 0s - loss: 0.8132 - accuracy: 0.9615\n",
      "Epoch 119/2000\n",
      "2/2 - 0s - loss: 0.7889 - accuracy: 0.9615\n",
      "Epoch 120/2000\n",
      "2/2 - 0s - loss: 0.7719 - accuracy: 0.9615\n",
      "Epoch 121/2000\n",
      "2/2 - 0s - loss: 0.7517 - accuracy: 0.9423\n",
      "Epoch 122/2000\n",
      "2/2 - 0s - loss: 0.7269 - accuracy: 0.9615\n",
      "Epoch 123/2000\n",
      "2/2 - 0s - loss: 0.7138 - accuracy: 0.9615\n",
      "Epoch 124/2000\n",
      "2/2 - 0s - loss: 0.6968 - accuracy: 0.9615\n",
      "Epoch 125/2000\n",
      "2/2 - 0s - loss: 0.6844 - accuracy: 0.9615\n",
      "Epoch 126/2000\n",
      "2/2 - 0s - loss: 0.6671 - accuracy: 0.9615\n",
      "Epoch 127/2000\n",
      "2/2 - 0s - loss: 0.6478 - accuracy: 0.9808\n",
      "Epoch 128/2000\n",
      "2/2 - 0s - loss: 0.6308 - accuracy: 1.0000\n",
      "Epoch 129/2000\n",
      "2/2 - 0s - loss: 0.6158 - accuracy: 0.9808\n",
      "Epoch 130/2000\n",
      "2/2 - 0s - loss: 0.5979 - accuracy: 0.9615\n",
      "Epoch 131/2000\n",
      "2/2 - 0s - loss: 0.5865 - accuracy: 0.9615\n",
      "Epoch 132/2000\n",
      "2/2 - 0s - loss: 0.5703 - accuracy: 1.0000\n",
      "Epoch 133/2000\n",
      "2/2 - 0s - loss: 0.5549 - accuracy: 0.9808\n",
      "Epoch 134/2000\n",
      "2/2 - 0s - loss: 0.5426 - accuracy: 0.9615\n",
      "Epoch 135/2000\n",
      "2/2 - 0s - loss: 0.5307 - accuracy: 0.9615\n",
      "Epoch 136/2000\n",
      "2/2 - 0s - loss: 0.5106 - accuracy: 1.0000\n",
      "Epoch 137/2000\n",
      "2/2 - 0s - loss: 0.5056 - accuracy: 1.0000\n",
      "Epoch 138/2000\n",
      "2/2 - 0s - loss: 0.4880 - accuracy: 1.0000\n",
      "Epoch 139/2000\n",
      "2/2 - 0s - loss: 0.4755 - accuracy: 1.0000\n",
      "Epoch 140/2000\n",
      "2/2 - 0s - loss: 0.4630 - accuracy: 1.0000\n",
      "Epoch 141/2000\n",
      "2/2 - 0s - loss: 0.4512 - accuracy: 0.9615\n",
      "Epoch 142/2000\n",
      "2/2 - 0s - loss: 0.4373 - accuracy: 1.0000\n",
      "Epoch 143/2000\n",
      "2/2 - 0s - loss: 0.4281 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/2000\n",
      "2/2 - 0s - loss: 0.4190 - accuracy: 1.0000\n",
      "Epoch 145/2000\n",
      "2/2 - 0s - loss: 0.4094 - accuracy: 1.0000\n",
      "Epoch 146/2000\n",
      "2/2 - 0s - loss: 0.3940 - accuracy: 0.9808\n",
      "Epoch 147/2000\n",
      "2/2 - 0s - loss: 0.3843 - accuracy: 1.0000\n",
      "Epoch 148/2000\n",
      "2/2 - 0s - loss: 0.3758 - accuracy: 1.0000\n",
      "Epoch 149/2000\n",
      "2/2 - 0s - loss: 0.3639 - accuracy: 1.0000\n",
      "Epoch 150/2000\n",
      "2/2 - 0s - loss: 0.3606 - accuracy: 0.9808\n",
      "Epoch 151/2000\n",
      "2/2 - 0s - loss: 0.3447 - accuracy: 0.9808\n",
      "Epoch 152/2000\n",
      "2/2 - 0s - loss: 0.3334 - accuracy: 1.0000\n",
      "Epoch 153/2000\n",
      "2/2 - 0s - loss: 0.3258 - accuracy: 1.0000\n",
      "Epoch 154/2000\n",
      "2/2 - 0s - loss: 0.3231 - accuracy: 1.0000\n",
      "Epoch 155/2000\n",
      "2/2 - 0s - loss: 0.3103 - accuracy: 1.0000\n",
      "Epoch 156/2000\n",
      "2/2 - 0s - loss: 0.2981 - accuracy: 1.0000\n",
      "Epoch 157/2000\n",
      "2/2 - 0s - loss: 0.2957 - accuracy: 1.0000\n",
      "Epoch 158/2000\n",
      "2/2 - 0s - loss: 0.2893 - accuracy: 1.0000\n",
      "Epoch 159/2000\n",
      "2/2 - 0s - loss: 0.2830 - accuracy: 1.0000\n",
      "Epoch 160/2000\n",
      "2/2 - 0s - loss: 0.2740 - accuracy: 1.0000\n",
      "Epoch 161/2000\n",
      "2/2 - 0s - loss: 0.2709 - accuracy: 1.0000\n",
      "Epoch 162/2000\n",
      "2/2 - 0s - loss: 0.2615 - accuracy: 1.0000\n",
      "Epoch 163/2000\n",
      "2/2 - 0s - loss: 0.2585 - accuracy: 1.0000\n",
      "Epoch 164/2000\n",
      "2/2 - 0s - loss: 0.2475 - accuracy: 1.0000\n",
      "Epoch 165/2000\n",
      "2/2 - 0s - loss: 0.2421 - accuracy: 1.0000\n",
      "Epoch 166/2000\n",
      "2/2 - 0s - loss: 0.2303 - accuracy: 1.0000\n",
      "Epoch 167/2000\n",
      "2/2 - 0s - loss: 0.2222 - accuracy: 1.0000\n",
      "Epoch 168/2000\n",
      "2/2 - 0s - loss: 0.2241 - accuracy: 1.0000\n",
      "Epoch 169/2000\n",
      "2/2 - 0s - loss: 0.2170 - accuracy: 1.0000\n",
      "Epoch 170/2000\n",
      "2/2 - 0s - loss: 0.2102 - accuracy: 1.0000\n",
      "Epoch 171/2000\n",
      "2/2 - 0s - loss: 0.2046 - accuracy: 1.0000\n",
      "Epoch 172/2000\n",
      "2/2 - 0s - loss: 0.2003 - accuracy: 1.0000\n",
      "Epoch 173/2000\n",
      "2/2 - 0s - loss: 0.1952 - accuracy: 1.0000\n",
      "Epoch 174/2000\n",
      "2/2 - 0s - loss: 0.1911 - accuracy: 1.0000\n",
      "Epoch 175/2000\n",
      "2/2 - 0s - loss: 0.1851 - accuracy: 1.0000\n",
      "Epoch 176/2000\n",
      "2/2 - 0s - loss: 0.1761 - accuracy: 1.0000\n",
      "Epoch 177/2000\n",
      "2/2 - 0s - loss: 0.1731 - accuracy: 1.0000\n",
      "Epoch 178/2000\n",
      "2/2 - 0s - loss: 0.1664 - accuracy: 1.0000\n",
      "Epoch 179/2000\n",
      "2/2 - 0s - loss: 0.1629 - accuracy: 1.0000\n",
      "Epoch 180/2000\n",
      "2/2 - 0s - loss: 0.1655 - accuracy: 1.0000\n",
      "Epoch 181/2000\n",
      "2/2 - 0s - loss: 0.1587 - accuracy: 1.0000\n",
      "Epoch 182/2000\n",
      "2/2 - 0s - loss: 0.1525 - accuracy: 1.0000\n",
      "Epoch 183/2000\n",
      "2/2 - 0s - loss: 0.1504 - accuracy: 1.0000\n",
      "Epoch 184/2000\n",
      "2/2 - 0s - loss: 0.1482 - accuracy: 1.0000\n",
      "Epoch 185/2000\n",
      "2/2 - 0s - loss: 0.1374 - accuracy: 1.0000\n",
      "Epoch 186/2000\n",
      "2/2 - 0s - loss: 0.1362 - accuracy: 1.0000\n",
      "Epoch 187/2000\n",
      "2/2 - 0s - loss: 0.1355 - accuracy: 1.0000\n",
      "Epoch 188/2000\n",
      "2/2 - 0s - loss: 0.1285 - accuracy: 1.0000\n",
      "Epoch 189/2000\n",
      "2/2 - 0s - loss: 0.1292 - accuracy: 1.0000\n",
      "Epoch 190/2000\n",
      "2/2 - 0s - loss: 0.1220 - accuracy: 1.0000\n",
      "Epoch 191/2000\n",
      "2/2 - 0s - loss: 0.1179 - accuracy: 1.0000\n",
      "Epoch 192/2000\n",
      "2/2 - 0s - loss: 0.1178 - accuracy: 1.0000\n",
      "Epoch 193/2000\n",
      "2/2 - 0s - loss: 0.1120 - accuracy: 1.0000\n",
      "Epoch 194/2000\n",
      "2/2 - 0s - loss: 0.1064 - accuracy: 1.0000\n",
      "Epoch 195/2000\n",
      "2/2 - 0s - loss: 0.1062 - accuracy: 1.0000\n",
      "Epoch 196/2000\n",
      "2/2 - 0s - loss: 0.1024 - accuracy: 1.0000\n",
      "Epoch 197/2000\n",
      "2/2 - 0s - loss: 0.1001 - accuracy: 1.0000\n",
      "Epoch 198/2000\n",
      "2/2 - 0s - loss: 0.0984 - accuracy: 1.0000\n",
      "Epoch 199/2000\n",
      "2/2 - 0s - loss: 0.1000 - accuracy: 1.0000\n",
      "Epoch 200/2000\n",
      "2/2 - 0s - loss: 0.0930 - accuracy: 1.0000\n",
      "Epoch 201/2000\n",
      "2/2 - 0s - loss: 0.0878 - accuracy: 1.0000\n",
      "Epoch 202/2000\n",
      "2/2 - 0s - loss: 0.0899 - accuracy: 1.0000\n",
      "Epoch 203/2000\n",
      "2/2 - 0s - loss: 0.0907 - accuracy: 1.0000\n",
      "Epoch 204/2000\n",
      "2/2 - 0s - loss: 0.0866 - accuracy: 1.0000\n",
      "Epoch 205/2000\n",
      "2/2 - 0s - loss: 0.0785 - accuracy: 1.0000\n",
      "Epoch 206/2000\n",
      "2/2 - 0s - loss: 0.0762 - accuracy: 1.0000\n",
      "Epoch 207/2000\n",
      "2/2 - 0s - loss: 0.0748 - accuracy: 1.0000\n",
      "Epoch 208/2000\n",
      "2/2 - 0s - loss: 0.0750 - accuracy: 1.0000\n",
      "Epoch 209/2000\n",
      "2/2 - 0s - loss: 0.0735 - accuracy: 1.0000\n",
      "Epoch 210/2000\n",
      "2/2 - 0s - loss: 0.0682 - accuracy: 1.0000\n",
      "Epoch 211/2000\n",
      "2/2 - 0s - loss: 0.0686 - accuracy: 1.0000\n",
      "Epoch 212/2000\n",
      "2/2 - 0s - loss: 0.0720 - accuracy: 1.0000\n",
      "Epoch 213/2000\n",
      "2/2 - 0s - loss: 0.0700 - accuracy: 1.0000\n",
      "Epoch 214/2000\n",
      "2/2 - 0s - loss: 0.0695 - accuracy: 1.0000\n",
      "Epoch 215/2000\n",
      "2/2 - 0s - loss: 0.0608 - accuracy: 1.0000\n",
      "Epoch 216/2000\n",
      "2/2 - 0s - loss: 0.0557 - accuracy: 1.0000\n",
      "Epoch 217/2000\n",
      "2/2 - 0s - loss: 0.0561 - accuracy: 1.0000\n",
      "Epoch 218/2000\n",
      "2/2 - 0s - loss: 0.0559 - accuracy: 1.0000\n",
      "Epoch 219/2000\n",
      "2/2 - 0s - loss: 0.0540 - accuracy: 1.0000\n",
      "Epoch 220/2000\n",
      "2/2 - 0s - loss: 0.0511 - accuracy: 1.0000\n",
      "Epoch 221/2000\n",
      "2/2 - 0s - loss: 0.0504 - accuracy: 1.0000\n",
      "Epoch 222/2000\n",
      "2/2 - 0s - loss: 0.0509 - accuracy: 1.0000\n",
      "Epoch 223/2000\n",
      "2/2 - 0s - loss: 0.0483 - accuracy: 1.0000\n",
      "Epoch 224/2000\n",
      "2/2 - 0s - loss: 0.0525 - accuracy: 1.0000\n",
      "Epoch 225/2000\n",
      "2/2 - 0s - loss: 0.0454 - accuracy: 1.0000\n",
      "Epoch 226/2000\n",
      "2/2 - 0s - loss: 0.0434 - accuracy: 1.0000\n",
      "Epoch 227/2000\n",
      "2/2 - 0s - loss: 0.0417 - accuracy: 1.0000\n",
      "Epoch 228/2000\n",
      "2/2 - 0s - loss: 0.0410 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2009461d430>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = EarlyStopping(monitor='accuracy', \n",
    "                         patience=100,\n",
    "                         restore_best_weights=True)\n",
    "\n",
    "model_with_mul_layers.compile(optimizer=\"rmsprop\", \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model_with_mul_layers.fit(TRAINING_SET_2D, \n",
    "          TRAINING_SET_LABELS, \n",
    "          epochs=2000,\n",
    "          callbacks=[callback], \n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PpMyumvtHhCR",
    "outputId": "5d3741bc-086c-4267-a800-e0be67a80ecc",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden_layer_1 (Dense)       (None, 26)                936       \n",
      "_________________________________________________________________\n",
      "hidden_layer_2 (Dense)       (None, 26)                702       \n",
      "_________________________________________________________________\n",
      "hidden_layer_3 (Dense)       (None, 26)                702       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 26)                702       \n",
      "=================================================================\n",
      "Total params: 3,042\n",
      "Trainable params: 3,042\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_with_mul_layers.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ob55aU81HhCT",
    "outputId": "1f8bb15b-eb24-44b6-8b42-199b699eb771",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9214 - accuracy: 0.9231\n"
     ]
    }
   ],
   "source": [
    "model_with_mul_layers_eval = model_with_mul_layers.evaluate(TEST_SET_2D, TEST_SET_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "IO4pbgZrHhCW"
   },
   "outputs": [],
   "source": [
    "model_with_mul_layers_pred = model_with_mul_layers.predict(TEST_SET_2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6N6rE07HhCX"
   },
   "source": [
    "### show misclassified images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ET_GaCqQHhCY",
    "outputId": "dd5386cb-380c-4782-ed9c-08e053ce668e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: M True: A\n",
      "Pred: U True: W\n"
     ]
    }
   ],
   "source": [
    "misclassfication_mul_layers_model = show_misclassified_img(model_with_mul_layers_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4YY5U3yTHhCY",
    "outputId": "c0855e00-6682-4e1b-8908-85b4812b5ef1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'W']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassfication_mul_layers_model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w4MIschfHhCZ",
    "outputId": "0173df69-413b-4cf5-aa4e-a8ee747e9a24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9230769230769231"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(26-misclassfication_mul_layers_model[1])/26 # accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZVIJ1hb7HhCZ",
    "outputId": "e8a5de35-a9e1-48ac-f87c-ede51052455e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9230769276618958"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_mul_layers_eval[1] # accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJQ9juYDHhCa"
   },
   "source": [
    "## Get the predicted message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "UC_osvhWHhCa"
   },
   "outputs": [],
   "source": [
    "msg_pred_mul_layers = model_with_mul_layers.predict(MESSAGE_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NM0NEbTxHhCa",
    "outputId": "0a27c7f6-afff-4e0c-defb-a60a68346aed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATGHJEORARDYMLEXTREBEKSFUNTVQUIZGAME"
     ]
    }
   ],
   "source": [
    "msg_pred_mult_layer_res = get_msg_pred(msg_pred_mul_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxRyzsZRHhCb"
   },
   "source": [
    "## Compare the true message with predicted message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2rXOBqd3HhCb",
    "outputId": "b250e62e-5098-4290-8e47-a3152f564efe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True   Predict\n",
      "W      M      \n",
      "C      G      \n",
      "P      R      \n",
      "A      M      \n"
     ]
    }
   ],
   "source": [
    "compare_with_true_message(msg_pred_mult_layer_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9nVLKS7cHhCc"
   },
   "source": [
    "### Does the performance improve?\n",
    "Yes, the performance does improve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kqW-cciHhCc"
   },
   "source": [
    "# 9. Repeat experiment (8), adding additional layers until the message is decoded correctly. What results do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m2DW51j_HhCc",
    "outputId": "5951db13-208f-4ef4-9985-1a2c1c013b76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 26)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = Sequential()\n",
    "final_model.add(Dense(26, \n",
    "                input_shape=(35,), \n",
    "                kernel_initializer='random_normal',\n",
    "                name=\"hidden_layer_1\"))\n",
    "final_model.add(Dense(26, \n",
    "                input_shape=(35,), \n",
    "                activation='relu', \n",
    "                name=\"hidden_layer_2\"))\n",
    "final_model.add(Dense(26, \n",
    "                input_shape=(35,),\n",
    "                activation='relu',\n",
    "                name=\"hidden_layer_3\"))\n",
    "final_model.add(Dense(26, \n",
    "                input_shape=(35,),\n",
    "                activation='relu',\n",
    "                name=\"hidden_layer_4\"))\n",
    "final_model.add(Dense(26, \n",
    "                input_shape=(35,),\n",
    "                activation='relu',\n",
    "                name=\"hidden_layer_5\"))\n",
    "final_model.add(Dense(26, \n",
    "                input_shape=(35,),\n",
    "                activation='relu',\n",
    "                name=\"hidden_layer_6\"))\n",
    "final_model.add(Dense(26, \n",
    "                input_shape=(35,), \n",
    "                activation='softmax', \n",
    "                name=\"output_layer\"))\n",
    "# final_model.add(Activation('softmax'))\n",
    "final_model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "byNghaeRHhCd",
    "outputId": "4af6f898-3f37-4a57-dc12-56b2f9494ef2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2/2 - 0s - loss: 3.2629 - accuracy: 0.0192\n",
      "Epoch 2/1000\n",
      "2/2 - 0s - loss: 3.2561 - accuracy: 0.0192\n",
      "Epoch 3/1000\n",
      "2/2 - 0s - loss: 3.2493 - accuracy: 0.0577\n",
      "Epoch 4/1000\n",
      "2/2 - 0s - loss: 3.2451 - accuracy: 0.0577\n",
      "Epoch 5/1000\n",
      "2/2 - 0s - loss: 3.2373 - accuracy: 0.0962\n",
      "Epoch 6/1000\n",
      "2/2 - 0s - loss: 3.2326 - accuracy: 0.0962\n",
      "Epoch 7/1000\n",
      "2/2 - 0s - loss: 3.2266 - accuracy: 0.1154\n",
      "Epoch 8/1000\n",
      "2/2 - 0s - loss: 3.2203 - accuracy: 0.1346\n",
      "Epoch 9/1000\n",
      "2/2 - 0s - loss: 3.2129 - accuracy: 0.1346\n",
      "Epoch 10/1000\n",
      "2/2 - 0s - loss: 3.2021 - accuracy: 0.1538\n",
      "Epoch 11/1000\n",
      "2/2 - 0s - loss: 3.1952 - accuracy: 0.1538\n",
      "Epoch 12/1000\n",
      "2/2 - 0s - loss: 3.1863 - accuracy: 0.1346\n",
      "Epoch 13/1000\n",
      "2/2 - 0s - loss: 3.1739 - accuracy: 0.1346\n",
      "Epoch 14/1000\n",
      "2/2 - 0s - loss: 3.1623 - accuracy: 0.1346\n",
      "Epoch 15/1000\n",
      "2/2 - 0s - loss: 3.1468 - accuracy: 0.1346\n",
      "Epoch 16/1000\n",
      "2/2 - 0s - loss: 3.1336 - accuracy: 0.1346\n",
      "Epoch 17/1000\n",
      "2/2 - 0s - loss: 3.1174 - accuracy: 0.0962\n",
      "Epoch 18/1000\n",
      "2/2 - 0s - loss: 3.0995 - accuracy: 0.1346\n",
      "Epoch 19/1000\n",
      "2/2 - 0s - loss: 3.0784 - accuracy: 0.1538\n",
      "Epoch 20/1000\n",
      "2/2 - 0s - loss: 3.0589 - accuracy: 0.1346\n",
      "Epoch 21/1000\n",
      "2/2 - 0s - loss: 3.0346 - accuracy: 0.1538\n",
      "Epoch 22/1000\n",
      "2/2 - 0s - loss: 3.0112 - accuracy: 0.1538\n",
      "Epoch 23/1000\n",
      "2/2 - 0s - loss: 2.9814 - accuracy: 0.1731\n",
      "Epoch 24/1000\n",
      "2/2 - 0s - loss: 2.9541 - accuracy: 0.1923\n",
      "Epoch 25/1000\n",
      "2/2 - 0s - loss: 2.9264 - accuracy: 0.1923\n",
      "Epoch 26/1000\n",
      "2/2 - 0s - loss: 2.8893 - accuracy: 0.1731\n",
      "Epoch 27/1000\n",
      "2/2 - 0s - loss: 2.8522 - accuracy: 0.1923\n",
      "Epoch 28/1000\n",
      "2/2 - 0s - loss: 2.8179 - accuracy: 0.2308\n",
      "Epoch 29/1000\n",
      "2/2 - 0s - loss: 2.7768 - accuracy: 0.2692\n",
      "Epoch 30/1000\n",
      "2/2 - 0s - loss: 2.7401 - accuracy: 0.2885\n",
      "Epoch 31/1000\n",
      "2/2 - 0s - loss: 2.6912 - accuracy: 0.2885\n",
      "Epoch 32/1000\n",
      "2/2 - 0s - loss: 2.6616 - accuracy: 0.2885\n",
      "Epoch 33/1000\n",
      "2/2 - 0s - loss: 2.6104 - accuracy: 0.3077\n",
      "Epoch 34/1000\n",
      "2/2 - 0s - loss: 2.5603 - accuracy: 0.2885\n",
      "Epoch 35/1000\n",
      "2/2 - 0s - loss: 2.5211 - accuracy: 0.2885\n",
      "Epoch 36/1000\n",
      "2/2 - 0s - loss: 2.4703 - accuracy: 0.2885\n",
      "Epoch 37/1000\n",
      "2/2 - 0s - loss: 2.4320 - accuracy: 0.3077\n",
      "Epoch 38/1000\n",
      "2/2 - 0s - loss: 2.3953 - accuracy: 0.3077\n",
      "Epoch 39/1000\n",
      "2/2 - 0s - loss: 2.3354 - accuracy: 0.3077\n",
      "Epoch 40/1000\n",
      "2/2 - 0s - loss: 2.2932 - accuracy: 0.3077\n",
      "Epoch 41/1000\n",
      "2/2 - 0s - loss: 2.2590 - accuracy: 0.2885\n",
      "Epoch 42/1000\n",
      "2/2 - 0s - loss: 2.2070 - accuracy: 0.3462\n",
      "Epoch 43/1000\n",
      "2/2 - 0s - loss: 2.1597 - accuracy: 0.4615\n",
      "Epoch 44/1000\n",
      "2/2 - 0s - loss: 2.1275 - accuracy: 0.4615\n",
      "Epoch 45/1000\n",
      "2/2 - 0s - loss: 2.0942 - accuracy: 0.4038\n",
      "Epoch 46/1000\n",
      "2/2 - 0s - loss: 2.0404 - accuracy: 0.4808\n",
      "Epoch 47/1000\n",
      "2/2 - 0s - loss: 1.9862 - accuracy: 0.5000\n",
      "Epoch 48/1000\n",
      "2/2 - 0s - loss: 1.9400 - accuracy: 0.5000\n",
      "Epoch 49/1000\n",
      "2/2 - 0s - loss: 1.9131 - accuracy: 0.5385\n",
      "Epoch 50/1000\n",
      "2/2 - 0s - loss: 1.8494 - accuracy: 0.5385\n",
      "Epoch 51/1000\n",
      "2/2 - 0s - loss: 1.8063 - accuracy: 0.5385\n",
      "Epoch 52/1000\n",
      "2/2 - 0s - loss: 1.7771 - accuracy: 0.5385\n",
      "Epoch 53/1000\n",
      "2/2 - 0s - loss: 1.7254 - accuracy: 0.5385\n",
      "Epoch 54/1000\n",
      "2/2 - 0s - loss: 1.6749 - accuracy: 0.5385\n",
      "Epoch 55/1000\n",
      "2/2 - 0s - loss: 1.6314 - accuracy: 0.5577\n",
      "Epoch 56/1000\n",
      "2/2 - 0s - loss: 1.6050 - accuracy: 0.5962\n",
      "Epoch 57/1000\n",
      "2/2 - 0s - loss: 1.5414 - accuracy: 0.5577\n",
      "Epoch 58/1000\n",
      "2/2 - 0s - loss: 1.5087 - accuracy: 0.5577\n",
      "Epoch 59/1000\n",
      "2/2 - 0s - loss: 1.4451 - accuracy: 0.5577\n",
      "Epoch 60/1000\n",
      "2/2 - 0s - loss: 1.4091 - accuracy: 0.5769\n",
      "Epoch 61/1000\n",
      "2/2 - 0s - loss: 1.3791 - accuracy: 0.5962\n",
      "Epoch 62/1000\n",
      "2/2 - 0s - loss: 1.3273 - accuracy: 0.6346\n",
      "Epoch 63/1000\n",
      "2/2 - 0s - loss: 1.2873 - accuracy: 0.6154\n",
      "Epoch 64/1000\n",
      "2/2 - 0s - loss: 1.2400 - accuracy: 0.6538\n",
      "Epoch 65/1000\n",
      "2/2 - 0s - loss: 1.1930 - accuracy: 0.6346\n",
      "Epoch 66/1000\n",
      "2/2 - 0s - loss: 1.1766 - accuracy: 0.6731\n",
      "Epoch 67/1000\n",
      "2/2 - 0s - loss: 1.1829 - accuracy: 0.5962\n",
      "Epoch 68/1000\n",
      "2/2 - 0s - loss: 1.1274 - accuracy: 0.6923\n",
      "Epoch 69/1000\n",
      "2/2 - 0s - loss: 1.0905 - accuracy: 0.7115\n",
      "Epoch 70/1000\n",
      "2/2 - 0s - loss: 1.0279 - accuracy: 0.7308\n",
      "Epoch 71/1000\n",
      "2/2 - 0s - loss: 1.0070 - accuracy: 0.7115\n",
      "Epoch 72/1000\n",
      "2/2 - 0s - loss: 0.9561 - accuracy: 0.7692\n",
      "Epoch 73/1000\n",
      "2/2 - 0s - loss: 0.9359 - accuracy: 0.8462\n",
      "Epoch 74/1000\n",
      "2/2 - 0s - loss: 0.9061 - accuracy: 0.8269\n",
      "Epoch 75/1000\n",
      "2/2 - 0s - loss: 0.8787 - accuracy: 0.8269\n",
      "Epoch 76/1000\n",
      "2/2 - 0s - loss: 0.8780 - accuracy: 0.8462\n",
      "Epoch 77/1000\n",
      "2/2 - 0s - loss: 0.8241 - accuracy: 0.9038\n",
      "Epoch 78/1000\n",
      "2/2 - 0s - loss: 0.7828 - accuracy: 0.8654\n",
      "Epoch 79/1000\n",
      "2/2 - 0s - loss: 0.7655 - accuracy: 0.9423\n",
      "Epoch 80/1000\n",
      "2/2 - 0s - loss: 0.7553 - accuracy: 0.9038\n",
      "Epoch 81/1000\n",
      "2/2 - 0s - loss: 0.6940 - accuracy: 0.9423\n",
      "Epoch 82/1000\n",
      "2/2 - 0s - loss: 0.6668 - accuracy: 0.9231\n",
      "Epoch 83/1000\n",
      "2/2 - 0s - loss: 0.6661 - accuracy: 0.9423\n",
      "Epoch 84/1000\n",
      "2/2 - 0s - loss: 0.6368 - accuracy: 0.9231\n",
      "Epoch 85/1000\n",
      "2/2 - 0s - loss: 0.6022 - accuracy: 0.9808\n",
      "Epoch 86/1000\n",
      "2/2 - 0s - loss: 0.5941 - accuracy: 0.9423\n",
      "Epoch 87/1000\n",
      "2/2 - 0s - loss: 0.5459 - accuracy: 0.9808\n",
      "Epoch 88/1000\n",
      "2/2 - 0s - loss: 0.5447 - accuracy: 0.9423\n",
      "Epoch 89/1000\n",
      "2/2 - 0s - loss: 0.5300 - accuracy: 0.9808\n",
      "Epoch 90/1000\n",
      "2/2 - 0s - loss: 0.5013 - accuracy: 0.9615\n",
      "Epoch 91/1000\n",
      "2/2 - 0s - loss: 0.4728 - accuracy: 0.9615\n",
      "Epoch 92/1000\n",
      "2/2 - 0s - loss: 0.4401 - accuracy: 0.9808\n",
      "Epoch 93/1000\n",
      "2/2 - 0s - loss: 0.4448 - accuracy: 0.9808\n",
      "Epoch 94/1000\n",
      "2/2 - 0s - loss: 0.4243 - accuracy: 0.9615\n",
      "Epoch 95/1000\n",
      "2/2 - 0s - loss: 0.4407 - accuracy: 0.9615\n",
      "Epoch 96/1000\n",
      "2/2 - 0s - loss: 0.3720 - accuracy: 0.9808\n",
      "Epoch 97/1000\n",
      "2/2 - 0s - loss: 0.3574 - accuracy: 1.0000\n",
      "Epoch 98/1000\n",
      "2/2 - 0s - loss: 0.3399 - accuracy: 0.9808\n",
      "Epoch 99/1000\n",
      "2/2 - 0s - loss: 0.3369 - accuracy: 0.9808\n",
      "Epoch 100/1000\n",
      "2/2 - 0s - loss: 0.3275 - accuracy: 0.9808\n",
      "Epoch 101/1000\n",
      "2/2 - 0s - loss: 0.3002 - accuracy: 0.9808\n",
      "Epoch 102/1000\n",
      "2/2 - 0s - loss: 0.2821 - accuracy: 0.9808\n",
      "Epoch 103/1000\n",
      "2/2 - 0s - loss: 0.2758 - accuracy: 0.9808\n",
      "Epoch 104/1000\n",
      "2/2 - 0s - loss: 0.2984 - accuracy: 1.0000\n",
      "Epoch 105/1000\n",
      "2/2 - 0s - loss: 0.2928 - accuracy: 0.9615\n",
      "Epoch 106/1000\n",
      "2/2 - 0s - loss: 0.2306 - accuracy: 0.9808\n",
      "Epoch 107/1000\n",
      "2/2 - 0s - loss: 0.2144 - accuracy: 1.0000\n",
      "Epoch 108/1000\n",
      "2/2 - 0s - loss: 0.2069 - accuracy: 1.0000\n",
      "Epoch 109/1000\n",
      "2/2 - 0s - loss: 0.2041 - accuracy: 1.0000\n",
      "Epoch 110/1000\n",
      "2/2 - 0s - loss: 0.2093 - accuracy: 0.9808\n",
      "Epoch 111/1000\n",
      "2/2 - 0s - loss: 0.1924 - accuracy: 1.0000\n",
      "Epoch 112/1000\n",
      "2/2 - 0s - loss: 0.1837 - accuracy: 0.9808\n",
      "Epoch 113/1000\n",
      "2/2 - 0s - loss: 0.1695 - accuracy: 1.0000\n",
      "Epoch 114/1000\n",
      "2/2 - 0s - loss: 0.1582 - accuracy: 1.0000\n",
      "Epoch 115/1000\n",
      "2/2 - 0s - loss: 0.1481 - accuracy: 1.0000\n",
      "Epoch 116/1000\n",
      "2/2 - 0s - loss: 0.1635 - accuracy: 0.9808\n",
      "Epoch 117/1000\n",
      "2/2 - 0s - loss: 0.1318 - accuracy: 1.0000\n",
      "Epoch 118/1000\n",
      "2/2 - 0s - loss: 0.1319 - accuracy: 1.0000\n",
      "Epoch 119/1000\n",
      "2/2 - 0s - loss: 0.1217 - accuracy: 1.0000\n",
      "Epoch 120/1000\n",
      "2/2 - 0s - loss: 0.1560 - accuracy: 0.9808\n",
      "Epoch 121/1000\n",
      "2/2 - 0s - loss: 0.1188 - accuracy: 0.9808\n",
      "Epoch 122/1000\n",
      "2/2 - 0s - loss: 0.0986 - accuracy: 1.0000\n",
      "Epoch 123/1000\n",
      "2/2 - 0s - loss: 0.0897 - accuracy: 1.0000\n",
      "Epoch 124/1000\n",
      "2/2 - 0s - loss: 0.0980 - accuracy: 1.0000\n",
      "Epoch 125/1000\n",
      "2/2 - 0s - loss: 0.1329 - accuracy: 0.9808\n",
      "Epoch 126/1000\n",
      "2/2 - 0s - loss: 0.1080 - accuracy: 1.0000\n",
      "Epoch 127/1000\n",
      "2/2 - 0s - loss: 0.0790 - accuracy: 1.0000\n",
      "Epoch 128/1000\n",
      "2/2 - 0s - loss: 0.0708 - accuracy: 1.0000\n",
      "Epoch 129/1000\n",
      "2/2 - 0s - loss: 0.0843 - accuracy: 1.0000\n",
      "Epoch 130/1000\n",
      "2/2 - 0s - loss: 0.0716 - accuracy: 1.0000\n",
      "Epoch 131/1000\n",
      "2/2 - 0s - loss: 0.0696 - accuracy: 1.0000\n",
      "Epoch 132/1000\n",
      "2/2 - 0s - loss: 0.0678 - accuracy: 1.0000\n",
      "Epoch 133/1000\n",
      "2/2 - 0s - loss: 0.0636 - accuracy: 1.0000\n",
      "Epoch 134/1000\n",
      "2/2 - 0s - loss: 0.0587 - accuracy: 1.0000\n",
      "Epoch 135/1000\n",
      "2/2 - 0s - loss: 0.0515 - accuracy: 1.0000\n",
      "Epoch 136/1000\n",
      "2/2 - 0s - loss: 0.0607 - accuracy: 1.0000\n",
      "Epoch 137/1000\n",
      "2/2 - 0s - loss: 0.0569 - accuracy: 1.0000\n",
      "Epoch 138/1000\n",
      "2/2 - 0s - loss: 0.0456 - accuracy: 1.0000\n",
      "Epoch 139/1000\n",
      "2/2 - 0s - loss: 0.0435 - accuracy: 1.0000\n",
      "Epoch 140/1000\n",
      "2/2 - 0s - loss: 0.0634 - accuracy: 1.0000\n",
      "Epoch 141/1000\n",
      "2/2 - 0s - loss: 0.1460 - accuracy: 0.9423\n",
      "Epoch 142/1000\n",
      "2/2 - 0s - loss: 0.0540 - accuracy: 1.0000\n",
      "Epoch 143/1000\n",
      "2/2 - 0s - loss: 0.0326 - accuracy: 1.0000\n",
      "Epoch 144/1000\n",
      "2/2 - 0s - loss: 0.0308 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/1000\n",
      "2/2 - 0s - loss: 0.0281 - accuracy: 1.0000\n",
      "Epoch 146/1000\n",
      "2/2 - 0s - loss: 0.0280 - accuracy: 1.0000\n",
      "Epoch 147/1000\n",
      "2/2 - 0s - loss: 0.0289 - accuracy: 1.0000\n",
      "Epoch 148/1000\n",
      "2/2 - 0s - loss: 0.0257 - accuracy: 1.0000\n",
      "Epoch 149/1000\n",
      "2/2 - 0s - loss: 0.0251 - accuracy: 1.0000\n",
      "Epoch 150/1000\n",
      "2/2 - 0s - loss: 0.0232 - accuracy: 1.0000\n",
      "Epoch 151/1000\n",
      "2/2 - 0s - loss: 0.0224 - accuracy: 1.0000\n",
      "Epoch 152/1000\n",
      "2/2 - 0s - loss: 0.0229 - accuracy: 1.0000\n",
      "Epoch 153/1000\n",
      "2/2 - 0s - loss: 0.0255 - accuracy: 1.0000\n",
      "Epoch 154/1000\n",
      "2/2 - 0s - loss: 0.0255 - accuracy: 1.0000\n",
      "Epoch 155/1000\n",
      "2/2 - 0s - loss: 0.0211 - accuracy: 1.0000\n",
      "Epoch 156/1000\n",
      "2/2 - 0s - loss: 0.0281 - accuracy: 1.0000\n",
      "Epoch 157/1000\n",
      "2/2 - 0s - loss: 0.0709 - accuracy: 0.9808\n",
      "Epoch 158/1000\n",
      "2/2 - 0s - loss: 0.0306 - accuracy: 1.0000\n",
      "Epoch 159/1000\n",
      "2/2 - 0s - loss: 0.0204 - accuracy: 1.0000\n",
      "Epoch 160/1000\n",
      "2/2 - 0s - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 161/1000\n",
      "2/2 - 0s - loss: 0.0134 - accuracy: 1.0000\n",
      "Epoch 162/1000\n",
      "2/2 - 0s - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 163/1000\n",
      "2/2 - 0s - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 164/1000\n",
      "2/2 - 0s - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 165/1000\n",
      "2/2 - 0s - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 166/1000\n",
      "2/2 - 0s - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 167/1000\n",
      "2/2 - 0s - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 168/1000\n",
      "2/2 - 0s - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 169/1000\n",
      "2/2 - 0s - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 170/1000\n",
      "2/2 - 0s - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 171/1000\n",
      "2/2 - 0s - loss: 0.0237 - accuracy: 1.0000\n",
      "Epoch 172/1000\n",
      "2/2 - 0s - loss: 0.0258 - accuracy: 1.0000\n",
      "Epoch 173/1000\n",
      "2/2 - 0s - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 174/1000\n",
      "2/2 - 0s - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 175/1000\n",
      "2/2 - 0s - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 176/1000\n",
      "2/2 - 0s - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 177/1000\n",
      "2/2 - 0s - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 178/1000\n",
      "2/2 - 0s - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 179/1000\n",
      "2/2 - 0s - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 180/1000\n",
      "2/2 - 0s - loss: 0.0623 - accuracy: 0.9808\n",
      "Epoch 181/1000\n",
      "2/2 - 0s - loss: 0.0230 - accuracy: 1.0000\n",
      "Epoch 182/1000\n",
      "2/2 - 0s - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 183/1000\n",
      "2/2 - 0s - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 184/1000\n",
      "2/2 - 0s - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 185/1000\n",
      "2/2 - 0s - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 186/1000\n",
      "2/2 - 0s - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 187/1000\n",
      "2/2 - 0s - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 188/1000\n",
      "2/2 - 0s - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 189/1000\n",
      "2/2 - 0s - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 190/1000\n",
      "2/2 - 0s - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 191/1000\n",
      "2/2 - 0s - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 192/1000\n",
      "2/2 - 0s - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 193/1000\n",
      "2/2 - 0s - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 194/1000\n",
      "2/2 - 0s - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 195/1000\n",
      "2/2 - 0s - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 196/1000\n",
      "2/2 - 0s - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 197/1000\n",
      "2/2 - 0s - loss: 0.0027 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20095c4bbe0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = EarlyStopping(monitor='accuracy', \n",
    "                         patience=100,\n",
    "                         restore_best_weights=True)\n",
    "\n",
    "final_model.compile(optimizer=\"rmsprop\", \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "final_model.fit(TRAINING_SET_2D, \n",
    "          TRAINING_SET_LABELS, \n",
    "          epochs=1000,\n",
    "          callbacks=[callback], \n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1G26YmdUHhCd",
    "outputId": "fb5f3b41-326c-47b8-a790-3843b94cbf1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden_layer_1 (Dense)       (None, 26)                936       \n",
      "_________________________________________________________________\n",
      "hidden_layer_2 (Dense)       (None, 26)                702       \n",
      "_________________________________________________________________\n",
      "hidden_layer_3 (Dense)       (None, 26)                702       \n",
      "_________________________________________________________________\n",
      "hidden_layer_4 (Dense)       (None, 26)                702       \n",
      "_________________________________________________________________\n",
      "hidden_layer_5 (Dense)       (None, 26)                702       \n",
      "_________________________________________________________________\n",
      "hidden_layer_6 (Dense)       (None, 26)                702       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 26)                702       \n",
      "=================================================================\n",
      "Total params: 5,148\n",
      "Trainable params: 5,148\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hKxKw3LQHhCd",
    "outputId": "c99e86ce-e29a-46c6-84f4-8a3ff40d8738"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7603 - accuracy: 0.9231\n"
     ]
    }
   ],
   "source": [
    "final_model_eval = final_model.evaluate(TEST_SET_2D, TEST_SET_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "htxFapZMHhCd"
   },
   "outputs": [],
   "source": [
    "final_model_pred = final_model.predict(TEST_SET_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oCtZxIUAHhDV",
    "outputId": "984d91c1-ed08-449d-92e3-b2453787bede",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: M True: A\n",
      "Pred: U True: W\n"
     ]
    }
   ],
   "source": [
    "misclassfication_final_model = show_misclassified_img(final_model_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GtOy2Hr9HhDW",
    "outputId": "82d8b63a-6f1a-4aa6-9368-e0df87fb0de8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'W']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassfication_final_model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rr3l6DiRHhDX",
    "outputId": "3065ed69-cba2-4137-9c6e-05bec336a9b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9230769276618958"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model_eval[1] # accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtDc_78GHhDX"
   },
   "source": [
    "## Get the predicted message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "xnLayBBoHhDY"
   },
   "outputs": [],
   "source": [
    "msg_final_model = final_model.predict(MESSAGE_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BVE2T3kGHhDY",
    "outputId": "b5406ecc-97e7-4e96-9ea5-8051227ebdd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRTCHREOPPRDYMLEXTFEBEKSFUNTVQUIZGDMZ"
     ]
    }
   ],
   "source": [
    "msg_final_model_res = get_msg_pred(msg_final_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGhKamnkHhDa"
   },
   "source": [
    "## Compare the true message with predicted message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6t26yDusHhDb",
    "outputId": "486d3599-c52e-4546-f9a9-3370d45539d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True   Predict\n",
      "W      D      \n",
      "A      R      \n",
      "J      R      \n",
      "A      P      \n",
      "A      M      \n",
      "R      F      \n",
      "A      D      \n",
      "E      Z      \n"
     ]
    }
   ],
   "source": [
    "compare_with_true_message(msg_final_model_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ctxeojQPHhDc"
   },
   "source": [
    "## Does the performance improve?\n",
    "No, the performance doesn't improve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOIX2D0QHhDc"
   },
   "source": [
    "## What results do you observe?\n",
    "When we add more additional layers to the network, the performance gets worse than the previous two models. The network seems to be undergoing the vanishing gradient descent because the loss and accuracy are barely changed after a large number of epochs. Besides, the final model  with multi-layers is likely to recognize only one or a few letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R5ZmYEBjHhDc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Project_2_01_CPSC585.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
