{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Use from dataset import * to load the module, then examine TRAINING_SET, TEST_SET, and MESSAGE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import * \n",
    "from keras.utils import to_categorical\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.activations import softmax\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l1, l2, l1_l2\n",
    "import numpy as np\n",
    "import math\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. In order to use the images in TRAINING_SET, TEST_SET, and MESSAGE, convert them into two-dimensional NumPy arrays of feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1], 'A')\n"
     ]
    }
   ],
   "source": [
    "print(TRAINING_SET[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_2d(dataset):\n",
    "    if len(dataset) == 0: return None\n",
    "    res = []\n",
    "    if len(dataset[0]) == 2:\n",
    "        for x, _ in dataset:\n",
    "            res.append(np.array(x))\n",
    "    else:\n",
    "        for x in dataset:\n",
    "            res.append(np.array(x))\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SET_2D = convert_to_2d(TRAINING_SET)\n",
    "TEST_SET_2D = convert_to_2d(TEST_SET)\n",
    "MESSAGE_2D = convert_to_2d(MESSAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 35)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MESSAGE_2D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 35)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_SET_2D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 35)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_SET_2D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    n = len(img)\n",
    "    for i in range(n):\n",
    "        if img[i] == 1:\n",
    "            print('#', end='')\n",
    "        else:\n",
    "            print(' ', end='')\n",
    "        if (i+1) % 5 == 0:\n",
    "            print('\\n', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ### \n",
      "#   #\n",
      "#   #\n",
      "#   #\n",
      "#####\n",
      "#   #\n",
      "#   #\n"
     ]
    }
   ],
   "source": [
    "show(TRAINING_SET_2D[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_SET_2D[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. In order to use the character labels in TRAINING_SET and TEST_SET, convert them into an integer class vector using ord(), then into one-hot encoded categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_labels_to_int(dataset):\n",
    "    res = []\n",
    "    for _, letter in dataset:\n",
    "        res.append(ord(letter)-ord('A'))\n",
    "    \n",
    "    n = len(res)\n",
    "    return to_categorical(res, num_classes=26)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SET_LABELS = convert_labels_to_int(TRAINING_SET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 26)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_SET_LABELS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_SET_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SET_LABELS = convert_labels_to_int(TEST_SET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 26)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_SET_LABELS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_SET_LABELS[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create a Sequential Keras model with a Dense hidden layer and an output layer with softmax activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 26)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(26, \n",
    "                input_shape=(35,), \n",
    "                activation='relu', \n",
    "                kernel_initializer='random_normal',\n",
    "                name=\"hidden_layer_1\"))\n",
    "model.add(Dense(26, \n",
    "                input_shape=(35,), \n",
    "                activation=softmax, \n",
    "                name=\"output_layer\"))\n",
    "# add another dense layer with activation softmax here\n",
    "# model.add(Activation('softmax'))\n",
    "model.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. compile and fit the model to the training set. Train the model until the accuracy is as high as possible. You may wish to use an EarlyStopping callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "2/2 - 0s - loss: 0.0371 - accuracy: 0.0192 - mse: 0.0371\n",
      "Epoch 2/10000\n",
      "2/2 - 0s - loss: 0.0370 - accuracy: 0.0385 - mse: 0.0370\n",
      "Epoch 3/10000\n",
      "2/2 - 0s - loss: 0.0369 - accuracy: 0.1154 - mse: 0.0369\n",
      "Epoch 4/10000\n",
      "2/2 - 0s - loss: 0.0368 - accuracy: 0.1538 - mse: 0.0368\n",
      "Epoch 5/10000\n",
      "2/2 - 0s - loss: 0.0368 - accuracy: 0.1923 - mse: 0.0368\n",
      "Epoch 6/10000\n",
      "2/2 - 0s - loss: 0.0367 - accuracy: 0.1923 - mse: 0.0367\n",
      "Epoch 7/10000\n",
      "2/2 - 0s - loss: 0.0367 - accuracy: 0.1923 - mse: 0.0367\n",
      "Epoch 8/10000\n",
      "2/2 - 0s - loss: 0.0366 - accuracy: 0.1923 - mse: 0.0366\n",
      "Epoch 9/10000\n",
      "2/2 - 0s - loss: 0.0366 - accuracy: 0.2308 - mse: 0.0366\n",
      "Epoch 10/10000\n",
      "2/2 - 0s - loss: 0.0365 - accuracy: 0.2308 - mse: 0.0365\n",
      "Epoch 11/10000\n",
      "2/2 - 0s - loss: 0.0365 - accuracy: 0.2885 - mse: 0.0365\n",
      "Epoch 12/10000\n",
      "2/2 - 0s - loss: 0.0364 - accuracy: 0.2885 - mse: 0.0364\n",
      "Epoch 13/10000\n",
      "2/2 - 0s - loss: 0.0364 - accuracy: 0.2885 - mse: 0.0364\n",
      "Epoch 14/10000\n",
      "2/2 - 0s - loss: 0.0363 - accuracy: 0.3077 - mse: 0.0363\n",
      "Epoch 15/10000\n",
      "2/2 - 0s - loss: 0.0363 - accuracy: 0.3077 - mse: 0.0363\n",
      "Epoch 16/10000\n",
      "2/2 - 0s - loss: 0.0362 - accuracy: 0.3077 - mse: 0.0362\n",
      "Epoch 17/10000\n",
      "2/2 - 0s - loss: 0.0362 - accuracy: 0.3077 - mse: 0.0362\n",
      "Epoch 18/10000\n",
      "2/2 - 0s - loss: 0.0361 - accuracy: 0.3077 - mse: 0.0361\n",
      "Epoch 19/10000\n",
      "2/2 - 0s - loss: 0.0361 - accuracy: 0.3077 - mse: 0.0361\n",
      "Epoch 20/10000\n",
      "2/2 - 0s - loss: 0.0360 - accuracy: 0.3077 - mse: 0.0360\n",
      "Epoch 21/10000\n",
      "2/2 - 0s - loss: 0.0359 - accuracy: 0.3077 - mse: 0.0359\n",
      "Epoch 22/10000\n",
      "2/2 - 0s - loss: 0.0359 - accuracy: 0.3077 - mse: 0.0359\n",
      "Epoch 23/10000\n",
      "2/2 - 0s - loss: 0.0358 - accuracy: 0.3077 - mse: 0.0358\n",
      "Epoch 24/10000\n",
      "2/2 - 0s - loss: 0.0357 - accuracy: 0.3077 - mse: 0.0357\n",
      "Epoch 25/10000\n",
      "2/2 - 0s - loss: 0.0356 - accuracy: 0.3077 - mse: 0.0356\n",
      "Epoch 26/10000\n",
      "2/2 - 0s - loss: 0.0356 - accuracy: 0.3077 - mse: 0.0356\n",
      "Epoch 27/10000\n",
      "2/2 - 0s - loss: 0.0355 - accuracy: 0.3077 - mse: 0.0355\n",
      "Epoch 28/10000\n",
      "2/2 - 0s - loss: 0.0354 - accuracy: 0.3077 - mse: 0.0354\n",
      "Epoch 29/10000\n",
      "2/2 - 0s - loss: 0.0353 - accuracy: 0.3077 - mse: 0.0353\n",
      "Epoch 30/10000\n",
      "2/2 - 0s - loss: 0.0352 - accuracy: 0.3077 - mse: 0.0352\n",
      "Epoch 31/10000\n",
      "2/2 - 0s - loss: 0.0351 - accuracy: 0.3077 - mse: 0.0351\n",
      "Epoch 32/10000\n",
      "2/2 - 0s - loss: 0.0350 - accuracy: 0.3269 - mse: 0.0350\n",
      "Epoch 33/10000\n",
      "2/2 - 0s - loss: 0.0350 - accuracy: 0.3269 - mse: 0.0350\n",
      "Epoch 34/10000\n",
      "2/2 - 0s - loss: 0.0349 - accuracy: 0.3077 - mse: 0.0349\n",
      "Epoch 35/10000\n",
      "2/2 - 0s - loss: 0.0348 - accuracy: 0.3269 - mse: 0.0348\n",
      "Epoch 36/10000\n",
      "2/2 - 0s - loss: 0.0347 - accuracy: 0.3269 - mse: 0.0347\n",
      "Epoch 37/10000\n",
      "2/2 - 0s - loss: 0.0346 - accuracy: 0.3269 - mse: 0.0346\n",
      "Epoch 38/10000\n",
      "2/2 - 0s - loss: 0.0345 - accuracy: 0.3269 - mse: 0.0345\n",
      "Epoch 39/10000\n",
      "2/2 - 0s - loss: 0.0344 - accuracy: 0.3269 - mse: 0.0344\n",
      "Epoch 40/10000\n",
      "2/2 - 0s - loss: 0.0342 - accuracy: 0.3269 - mse: 0.0342\n",
      "Epoch 41/10000\n",
      "2/2 - 0s - loss: 0.0341 - accuracy: 0.3269 - mse: 0.0341\n",
      "Epoch 42/10000\n",
      "2/2 - 0s - loss: 0.0340 - accuracy: 0.3269 - mse: 0.0340\n",
      "Epoch 43/10000\n",
      "2/2 - 0s - loss: 0.0339 - accuracy: 0.3462 - mse: 0.0339\n",
      "Epoch 44/10000\n",
      "2/2 - 0s - loss: 0.0338 - accuracy: 0.3462 - mse: 0.0338\n",
      "Epoch 45/10000\n",
      "2/2 - 0s - loss: 0.0336 - accuracy: 0.3269 - mse: 0.0336\n",
      "Epoch 46/10000\n",
      "2/2 - 0s - loss: 0.0335 - accuracy: 0.3462 - mse: 0.0335\n",
      "Epoch 47/10000\n",
      "2/2 - 0s - loss: 0.0334 - accuracy: 0.3654 - mse: 0.0334\n",
      "Epoch 48/10000\n",
      "2/2 - 0s - loss: 0.0332 - accuracy: 0.3462 - mse: 0.0332\n",
      "Epoch 49/10000\n",
      "2/2 - 0s - loss: 0.0331 - accuracy: 0.3846 - mse: 0.0331\n",
      "Epoch 50/10000\n",
      "2/2 - 0s - loss: 0.0330 - accuracy: 0.3846 - mse: 0.0330\n",
      "Epoch 51/10000\n",
      "2/2 - 0s - loss: 0.0328 - accuracy: 0.3654 - mse: 0.0328\n",
      "Epoch 52/10000\n",
      "2/2 - 0s - loss: 0.0327 - accuracy: 0.3462 - mse: 0.0327\n",
      "Epoch 53/10000\n",
      "2/2 - 0s - loss: 0.0326 - accuracy: 0.3846 - mse: 0.0326\n",
      "Epoch 54/10000\n",
      "2/2 - 0s - loss: 0.0324 - accuracy: 0.4038 - mse: 0.0324\n",
      "Epoch 55/10000\n",
      "2/2 - 0s - loss: 0.0323 - accuracy: 0.3846 - mse: 0.0323\n",
      "Epoch 56/10000\n",
      "2/2 - 0s - loss: 0.0321 - accuracy: 0.4038 - mse: 0.0321\n",
      "Epoch 57/10000\n",
      "2/2 - 0s - loss: 0.0320 - accuracy: 0.4038 - mse: 0.0320\n",
      "Epoch 58/10000\n",
      "2/2 - 0s - loss: 0.0318 - accuracy: 0.4038 - mse: 0.0318\n",
      "Epoch 59/10000\n",
      "2/2 - 0s - loss: 0.0317 - accuracy: 0.4038 - mse: 0.0317\n",
      "Epoch 60/10000\n",
      "2/2 - 0s - loss: 0.0315 - accuracy: 0.4231 - mse: 0.0315\n",
      "Epoch 61/10000\n",
      "2/2 - 0s - loss: 0.0314 - accuracy: 0.4615 - mse: 0.0314\n",
      "Epoch 62/10000\n",
      "2/2 - 0s - loss: 0.0312 - accuracy: 0.4231 - mse: 0.0312\n",
      "Epoch 63/10000\n",
      "2/2 - 0s - loss: 0.0310 - accuracy: 0.4231 - mse: 0.0310\n",
      "Epoch 64/10000\n",
      "2/2 - 0s - loss: 0.0309 - accuracy: 0.4231 - mse: 0.0309\n",
      "Epoch 65/10000\n",
      "2/2 - 0s - loss: 0.0307 - accuracy: 0.4423 - mse: 0.0307\n",
      "Epoch 66/10000\n",
      "2/2 - 0s - loss: 0.0305 - accuracy: 0.4231 - mse: 0.0305\n",
      "Epoch 67/10000\n",
      "2/2 - 0s - loss: 0.0303 - accuracy: 0.4615 - mse: 0.0303\n",
      "Epoch 68/10000\n",
      "2/2 - 0s - loss: 0.0302 - accuracy: 0.4615 - mse: 0.0302\n",
      "Epoch 69/10000\n",
      "2/2 - 0s - loss: 0.0301 - accuracy: 0.4615 - mse: 0.0301\n",
      "Epoch 70/10000\n",
      "2/2 - 0s - loss: 0.0298 - accuracy: 0.4615 - mse: 0.0298\n",
      "Epoch 71/10000\n",
      "2/2 - 0s - loss: 0.0297 - accuracy: 0.4615 - mse: 0.0297\n",
      "Epoch 72/10000\n",
      "2/2 - 0s - loss: 0.0295 - accuracy: 0.4615 - mse: 0.0295\n",
      "Epoch 73/10000\n",
      "2/2 - 0s - loss: 0.0294 - accuracy: 0.4615 - mse: 0.0294\n",
      "Epoch 74/10000\n",
      "2/2 - 0s - loss: 0.0292 - accuracy: 0.4808 - mse: 0.0292\n",
      "Epoch 75/10000\n",
      "2/2 - 0s - loss: 0.0290 - accuracy: 0.4808 - mse: 0.0290\n",
      "Epoch 76/10000\n",
      "2/2 - 0s - loss: 0.0289 - accuracy: 0.4615 - mse: 0.0289\n",
      "Epoch 77/10000\n",
      "2/2 - 0s - loss: 0.0287 - accuracy: 0.4615 - mse: 0.0287\n",
      "Epoch 78/10000\n",
      "2/2 - 0s - loss: 0.0286 - accuracy: 0.4615 - mse: 0.0286\n",
      "Epoch 79/10000\n",
      "2/2 - 0s - loss: 0.0284 - accuracy: 0.4615 - mse: 0.0284\n",
      "Epoch 80/10000\n",
      "2/2 - 0s - loss: 0.0283 - accuracy: 0.4615 - mse: 0.0283\n",
      "Epoch 81/10000\n",
      "2/2 - 0s - loss: 0.0281 - accuracy: 0.4808 - mse: 0.0281\n",
      "Epoch 82/10000\n",
      "2/2 - 0s - loss: 0.0279 - accuracy: 0.4808 - mse: 0.0279\n",
      "Epoch 83/10000\n",
      "2/2 - 0s - loss: 0.0277 - accuracy: 0.4808 - mse: 0.0277\n",
      "Epoch 84/10000\n",
      "2/2 - 0s - loss: 0.0276 - accuracy: 0.4808 - mse: 0.0276\n",
      "Epoch 85/10000\n",
      "2/2 - 0s - loss: 0.0274 - accuracy: 0.4808 - mse: 0.0274\n",
      "Epoch 86/10000\n",
      "2/2 - 0s - loss: 0.0273 - accuracy: 0.4808 - mse: 0.0273\n",
      "Epoch 87/10000\n",
      "2/2 - 0s - loss: 0.0272 - accuracy: 0.4808 - mse: 0.0272\n",
      "Epoch 88/10000\n",
      "2/2 - 0s - loss: 0.0269 - accuracy: 0.4808 - mse: 0.0269\n",
      "Epoch 89/10000\n",
      "2/2 - 0s - loss: 0.0268 - accuracy: 0.4808 - mse: 0.0268\n",
      "Epoch 90/10000\n",
      "2/2 - 0s - loss: 0.0266 - accuracy: 0.4808 - mse: 0.0266\n",
      "Epoch 91/10000\n",
      "2/2 - 0s - loss: 0.0265 - accuracy: 0.4808 - mse: 0.0265\n",
      "Epoch 92/10000\n",
      "2/2 - 0s - loss: 0.0264 - accuracy: 0.4808 - mse: 0.0264\n",
      "Epoch 93/10000\n",
      "2/2 - 0s - loss: 0.0262 - accuracy: 0.5000 - mse: 0.0262\n",
      "Epoch 94/10000\n",
      "2/2 - 0s - loss: 0.0260 - accuracy: 0.5000 - mse: 0.0260\n",
      "Epoch 95/10000\n",
      "2/2 - 0s - loss: 0.0259 - accuracy: 0.5000 - mse: 0.0259\n",
      "Epoch 96/10000\n",
      "2/2 - 0s - loss: 0.0257 - accuracy: 0.5000 - mse: 0.0257\n",
      "Epoch 97/10000\n",
      "2/2 - 0s - loss: 0.0256 - accuracy: 0.5000 - mse: 0.0256\n",
      "Epoch 98/10000\n",
      "2/2 - 0s - loss: 0.0254 - accuracy: 0.5000 - mse: 0.0254\n",
      "Epoch 99/10000\n",
      "2/2 - 0s - loss: 0.0253 - accuracy: 0.5000 - mse: 0.0253\n",
      "Epoch 100/10000\n",
      "2/2 - 0s - loss: 0.0252 - accuracy: 0.5000 - mse: 0.0252\n",
      "Epoch 101/10000\n",
      "2/2 - 0s - loss: 0.0250 - accuracy: 0.5000 - mse: 0.0250\n",
      "Epoch 102/10000\n",
      "2/2 - 0s - loss: 0.0249 - accuracy: 0.5000 - mse: 0.0249\n",
      "Epoch 103/10000\n",
      "2/2 - 0s - loss: 0.0247 - accuracy: 0.5000 - mse: 0.0247\n",
      "Epoch 104/10000\n",
      "2/2 - 0s - loss: 0.0245 - accuracy: 0.5000 - mse: 0.0245\n",
      "Epoch 105/10000\n",
      "2/2 - 0s - loss: 0.0244 - accuracy: 0.5000 - mse: 0.0244\n",
      "Epoch 106/10000\n",
      "2/2 - 0s - loss: 0.0243 - accuracy: 0.5000 - mse: 0.0243\n",
      "Epoch 107/10000\n",
      "2/2 - 0s - loss: 0.0241 - accuracy: 0.5577 - mse: 0.0241\n",
      "Epoch 108/10000\n",
      "2/2 - 0s - loss: 0.0240 - accuracy: 0.5577 - mse: 0.0240\n",
      "Epoch 109/10000\n",
      "2/2 - 0s - loss: 0.0238 - accuracy: 0.5577 - mse: 0.0238\n",
      "Epoch 110/10000\n",
      "2/2 - 0s - loss: 0.0237 - accuracy: 0.5577 - mse: 0.0237\n",
      "Epoch 111/10000\n",
      "2/2 - 0s - loss: 0.0236 - accuracy: 0.5577 - mse: 0.0236\n",
      "Epoch 112/10000\n",
      "2/2 - 0s - loss: 0.0234 - accuracy: 0.5577 - mse: 0.0234\n",
      "Epoch 113/10000\n",
      "2/2 - 0s - loss: 0.0232 - accuracy: 0.5769 - mse: 0.0232\n",
      "Epoch 114/10000\n",
      "2/2 - 0s - loss: 0.0231 - accuracy: 0.5769 - mse: 0.0231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/10000\n",
      "2/2 - 0s - loss: 0.0230 - accuracy: 0.5769 - mse: 0.0230\n",
      "Epoch 116/10000\n",
      "2/2 - 0s - loss: 0.0228 - accuracy: 0.5769 - mse: 0.0228\n",
      "Epoch 117/10000\n",
      "2/2 - 0s - loss: 0.0227 - accuracy: 0.5769 - mse: 0.0227\n",
      "Epoch 118/10000\n",
      "2/2 - 0s - loss: 0.0225 - accuracy: 0.5769 - mse: 0.0225\n",
      "Epoch 119/10000\n",
      "2/2 - 0s - loss: 0.0224 - accuracy: 0.5769 - mse: 0.0224\n",
      "Epoch 120/10000\n",
      "2/2 - 0s - loss: 0.0222 - accuracy: 0.5769 - mse: 0.0222\n",
      "Epoch 121/10000\n",
      "2/2 - 0s - loss: 0.0221 - accuracy: 0.5769 - mse: 0.0221\n",
      "Epoch 122/10000\n",
      "2/2 - 0s - loss: 0.0219 - accuracy: 0.6154 - mse: 0.0219\n",
      "Epoch 123/10000\n",
      "2/2 - 0s - loss: 0.0218 - accuracy: 0.6154 - mse: 0.0218\n",
      "Epoch 124/10000\n",
      "2/2 - 0s - loss: 0.0217 - accuracy: 0.6154 - mse: 0.0217\n",
      "Epoch 125/10000\n",
      "2/2 - 0s - loss: 0.0215 - accuracy: 0.6346 - mse: 0.0215\n",
      "Epoch 126/10000\n",
      "2/2 - 0s - loss: 0.0214 - accuracy: 0.6538 - mse: 0.0214\n",
      "Epoch 127/10000\n",
      "2/2 - 0s - loss: 0.0212 - accuracy: 0.6346 - mse: 0.0212\n",
      "Epoch 128/10000\n",
      "2/2 - 0s - loss: 0.0211 - accuracy: 0.6538 - mse: 0.0211\n",
      "Epoch 129/10000\n",
      "2/2 - 0s - loss: 0.0209 - accuracy: 0.6731 - mse: 0.0209\n",
      "Epoch 130/10000\n",
      "2/2 - 0s - loss: 0.0208 - accuracy: 0.6923 - mse: 0.0208\n",
      "Epoch 131/10000\n",
      "2/2 - 0s - loss: 0.0206 - accuracy: 0.6923 - mse: 0.0206\n",
      "Epoch 132/10000\n",
      "2/2 - 0s - loss: 0.0204 - accuracy: 0.7308 - mse: 0.0204\n",
      "Epoch 133/10000\n",
      "2/2 - 0s - loss: 0.0203 - accuracy: 0.6923 - mse: 0.0203\n",
      "Epoch 134/10000\n",
      "2/2 - 0s - loss: 0.0202 - accuracy: 0.7308 - mse: 0.0202\n",
      "Epoch 135/10000\n",
      "2/2 - 0s - loss: 0.0200 - accuracy: 0.6923 - mse: 0.0200\n",
      "Epoch 136/10000\n",
      "2/2 - 0s - loss: 0.0199 - accuracy: 0.7115 - mse: 0.0199\n",
      "Epoch 137/10000\n",
      "2/2 - 0s - loss: 0.0197 - accuracy: 0.7115 - mse: 0.0197\n",
      "Epoch 138/10000\n",
      "2/2 - 0s - loss: 0.0195 - accuracy: 0.7308 - mse: 0.0195\n",
      "Epoch 139/10000\n",
      "2/2 - 0s - loss: 0.0194 - accuracy: 0.7115 - mse: 0.0194\n",
      "Epoch 140/10000\n",
      "2/2 - 0s - loss: 0.0193 - accuracy: 0.7308 - mse: 0.0193\n",
      "Epoch 141/10000\n",
      "2/2 - 0s - loss: 0.0191 - accuracy: 0.7308 - mse: 0.0191\n",
      "Epoch 142/10000\n",
      "2/2 - 0s - loss: 0.0190 - accuracy: 0.7308 - mse: 0.0190\n",
      "Epoch 143/10000\n",
      "2/2 - 0s - loss: 0.0188 - accuracy: 0.7308 - mse: 0.0188\n",
      "Epoch 144/10000\n",
      "2/2 - 0s - loss: 0.0187 - accuracy: 0.7308 - mse: 0.0187\n",
      "Epoch 145/10000\n",
      "2/2 - 0s - loss: 0.0185 - accuracy: 0.7692 - mse: 0.0185\n",
      "Epoch 146/10000\n",
      "2/2 - 0s - loss: 0.0184 - accuracy: 0.7885 - mse: 0.0184\n",
      "Epoch 147/10000\n",
      "2/2 - 0s - loss: 0.0182 - accuracy: 0.7692 - mse: 0.0182\n",
      "Epoch 148/10000\n",
      "2/2 - 0s - loss: 0.0181 - accuracy: 0.7692 - mse: 0.0181\n",
      "Epoch 149/10000\n",
      "2/2 - 0s - loss: 0.0179 - accuracy: 0.7692 - mse: 0.0179\n",
      "Epoch 150/10000\n",
      "2/2 - 0s - loss: 0.0178 - accuracy: 0.7885 - mse: 0.0178\n",
      "Epoch 151/10000\n",
      "2/2 - 0s - loss: 0.0177 - accuracy: 0.7885 - mse: 0.0177\n",
      "Epoch 152/10000\n",
      "2/2 - 0s - loss: 0.0175 - accuracy: 0.8077 - mse: 0.0175\n",
      "Epoch 153/10000\n",
      "2/2 - 0s - loss: 0.0173 - accuracy: 0.7692 - mse: 0.0173\n",
      "Epoch 154/10000\n",
      "2/2 - 0s - loss: 0.0172 - accuracy: 0.8269 - mse: 0.0172\n",
      "Epoch 155/10000\n",
      "2/2 - 0s - loss: 0.0171 - accuracy: 0.8269 - mse: 0.0171\n",
      "Epoch 156/10000\n",
      "2/2 - 0s - loss: 0.0169 - accuracy: 0.8269 - mse: 0.0169\n",
      "Epoch 157/10000\n",
      "2/2 - 0s - loss: 0.0168 - accuracy: 0.8269 - mse: 0.0168\n",
      "Epoch 158/10000\n",
      "2/2 - 0s - loss: 0.0166 - accuracy: 0.8077 - mse: 0.0166\n",
      "Epoch 159/10000\n",
      "2/2 - 0s - loss: 0.0165 - accuracy: 0.8269 - mse: 0.0165\n",
      "Epoch 160/10000\n",
      "2/2 - 0s - loss: 0.0164 - accuracy: 0.8269 - mse: 0.0164\n",
      "Epoch 161/10000\n",
      "2/2 - 0s - loss: 0.0162 - accuracy: 0.8269 - mse: 0.0162\n",
      "Epoch 162/10000\n",
      "2/2 - 0s - loss: 0.0160 - accuracy: 0.8269 - mse: 0.0160\n",
      "Epoch 163/10000\n",
      "2/2 - 0s - loss: 0.0159 - accuracy: 0.8077 - mse: 0.0159\n",
      "Epoch 164/10000\n",
      "2/2 - 0s - loss: 0.0158 - accuracy: 0.8269 - mse: 0.0158\n",
      "Epoch 165/10000\n",
      "2/2 - 0s - loss: 0.0156 - accuracy: 0.8269 - mse: 0.0156\n",
      "Epoch 166/10000\n",
      "2/2 - 0s - loss: 0.0155 - accuracy: 0.8269 - mse: 0.0155\n",
      "Epoch 167/10000\n",
      "2/2 - 0s - loss: 0.0153 - accuracy: 0.8269 - mse: 0.0153\n",
      "Epoch 168/10000\n",
      "2/2 - 0s - loss: 0.0152 - accuracy: 0.8269 - mse: 0.0152\n",
      "Epoch 169/10000\n",
      "2/2 - 0s - loss: 0.0150 - accuracy: 0.8269 - mse: 0.0150\n",
      "Epoch 170/10000\n",
      "2/2 - 0s - loss: 0.0149 - accuracy: 0.8269 - mse: 0.0149\n",
      "Epoch 171/10000\n",
      "2/2 - 0s - loss: 0.0147 - accuracy: 0.8269 - mse: 0.0147\n",
      "Epoch 172/10000\n",
      "2/2 - 0s - loss: 0.0146 - accuracy: 0.8269 - mse: 0.0146\n",
      "Epoch 173/10000\n",
      "2/2 - 0s - loss: 0.0144 - accuracy: 0.8269 - mse: 0.0144\n",
      "Epoch 174/10000\n",
      "2/2 - 0s - loss: 0.0143 - accuracy: 0.8269 - mse: 0.0143\n",
      "Epoch 175/10000\n",
      "2/2 - 0s - loss: 0.0142 - accuracy: 0.8269 - mse: 0.0142\n",
      "Epoch 176/10000\n",
      "2/2 - 0s - loss: 0.0141 - accuracy: 0.8269 - mse: 0.0141\n",
      "Epoch 177/10000\n",
      "2/2 - 0s - loss: 0.0139 - accuracy: 0.8269 - mse: 0.0139\n",
      "Epoch 178/10000\n",
      "2/2 - 0s - loss: 0.0138 - accuracy: 0.8269 - mse: 0.0138\n",
      "Epoch 179/10000\n",
      "2/2 - 0s - loss: 0.0136 - accuracy: 0.8269 - mse: 0.0136\n",
      "Epoch 180/10000\n",
      "2/2 - 0s - loss: 0.0134 - accuracy: 0.8269 - mse: 0.0134\n",
      "Epoch 181/10000\n",
      "2/2 - 0s - loss: 0.0133 - accuracy: 0.8269 - mse: 0.0133\n",
      "Epoch 182/10000\n",
      "2/2 - 0s - loss: 0.0132 - accuracy: 0.8269 - mse: 0.0132\n",
      "Epoch 183/10000\n",
      "2/2 - 0s - loss: 0.0131 - accuracy: 0.8269 - mse: 0.0131\n",
      "Epoch 184/10000\n",
      "2/2 - 0s - loss: 0.0129 - accuracy: 0.8462 - mse: 0.0129\n",
      "Epoch 185/10000\n",
      "2/2 - 0s - loss: 0.0128 - accuracy: 0.8269 - mse: 0.0128\n",
      "Epoch 186/10000\n",
      "2/2 - 0s - loss: 0.0126 - accuracy: 0.8462 - mse: 0.0126\n",
      "Epoch 187/10000\n",
      "2/2 - 0s - loss: 0.0125 - accuracy: 0.8462 - mse: 0.0125\n",
      "Epoch 188/10000\n",
      "2/2 - 0s - loss: 0.0124 - accuracy: 0.8462 - mse: 0.0124\n",
      "Epoch 189/10000\n",
      "2/2 - 0s - loss: 0.0122 - accuracy: 0.8269 - mse: 0.0122\n",
      "Epoch 190/10000\n",
      "2/2 - 0s - loss: 0.0121 - accuracy: 0.8462 - mse: 0.0121\n",
      "Epoch 191/10000\n",
      "2/2 - 0s - loss: 0.0120 - accuracy: 0.8462 - mse: 0.0120\n",
      "Epoch 192/10000\n",
      "2/2 - 0s - loss: 0.0118 - accuracy: 0.8462 - mse: 0.0118\n",
      "Epoch 193/10000\n",
      "2/2 - 0s - loss: 0.0117 - accuracy: 0.8654 - mse: 0.0117\n",
      "Epoch 194/10000\n",
      "2/2 - 0s - loss: 0.0115 - accuracy: 0.8654 - mse: 0.0115\n",
      "Epoch 195/10000\n",
      "2/2 - 0s - loss: 0.0114 - accuracy: 0.8654 - mse: 0.0114\n",
      "Epoch 196/10000\n",
      "2/2 - 0s - loss: 0.0113 - accuracy: 0.8846 - mse: 0.0113\n",
      "Epoch 197/10000\n",
      "2/2 - 0s - loss: 0.0111 - accuracy: 0.8846 - mse: 0.0111\n",
      "Epoch 198/10000\n",
      "2/2 - 0s - loss: 0.0110 - accuracy: 0.8846 - mse: 0.0110\n",
      "Epoch 199/10000\n",
      "2/2 - 0s - loss: 0.0109 - accuracy: 0.9231 - mse: 0.0109\n",
      "Epoch 200/10000\n",
      "2/2 - 0s - loss: 0.0107 - accuracy: 0.9231 - mse: 0.0107\n",
      "Epoch 201/10000\n",
      "2/2 - 0s - loss: 0.0105 - accuracy: 0.9231 - mse: 0.0105\n",
      "Epoch 202/10000\n",
      "2/2 - 0s - loss: 0.0104 - accuracy: 0.9231 - mse: 0.0104\n",
      "Epoch 203/10000\n",
      "2/2 - 0s - loss: 0.0103 - accuracy: 0.9231 - mse: 0.0103\n",
      "Epoch 204/10000\n",
      "2/2 - 0s - loss: 0.0101 - accuracy: 0.9615 - mse: 0.0101\n",
      "Epoch 205/10000\n",
      "2/2 - 0s - loss: 0.0100 - accuracy: 0.9423 - mse: 0.0100\n",
      "Epoch 206/10000\n",
      "2/2 - 0s - loss: 0.0099 - accuracy: 0.9423 - mse: 0.0099\n",
      "Epoch 207/10000\n",
      "2/2 - 0s - loss: 0.0097 - accuracy: 0.9423 - mse: 0.0097\n",
      "Epoch 208/10000\n",
      "2/2 - 0s - loss: 0.0096 - accuracy: 0.9808 - mse: 0.0096\n",
      "Epoch 209/10000\n",
      "2/2 - 0s - loss: 0.0095 - accuracy: 0.9423 - mse: 0.0095\n",
      "Epoch 210/10000\n",
      "2/2 - 0s - loss: 0.0093 - accuracy: 0.9808 - mse: 0.0093\n",
      "Epoch 211/10000\n",
      "2/2 - 0s - loss: 0.0092 - accuracy: 0.9808 - mse: 0.0092\n",
      "Epoch 212/10000\n",
      "2/2 - 0s - loss: 0.0091 - accuracy: 0.9808 - mse: 0.0091\n",
      "Epoch 213/10000\n",
      "2/2 - 0s - loss: 0.0090 - accuracy: 0.9808 - mse: 0.0090\n",
      "Epoch 214/10000\n",
      "2/2 - 0s - loss: 0.0088 - accuracy: 0.9808 - mse: 0.0088\n",
      "Epoch 215/10000\n",
      "2/2 - 0s - loss: 0.0087 - accuracy: 0.9808 - mse: 0.0087\n",
      "Epoch 216/10000\n",
      "2/2 - 0s - loss: 0.0086 - accuracy: 0.9808 - mse: 0.0086\n",
      "Epoch 217/10000\n",
      "2/2 - 0s - loss: 0.0084 - accuracy: 0.9808 - mse: 0.0084\n",
      "Epoch 218/10000\n",
      "2/2 - 0s - loss: 0.0083 - accuracy: 0.9808 - mse: 0.0083\n",
      "Epoch 219/10000\n",
      "2/2 - 0s - loss: 0.0082 - accuracy: 0.9808 - mse: 0.0082\n",
      "Epoch 220/10000\n",
      "2/2 - 0s - loss: 0.0081 - accuracy: 0.9808 - mse: 0.0081\n",
      "Epoch 221/10000\n",
      "2/2 - 0s - loss: 0.0080 - accuracy: 0.9808 - mse: 0.0080\n",
      "Epoch 222/10000\n",
      "2/2 - 0s - loss: 0.0079 - accuracy: 0.9808 - mse: 0.0079\n",
      "Epoch 223/10000\n",
      "2/2 - 0s - loss: 0.0078 - accuracy: 0.9808 - mse: 0.0078\n",
      "Epoch 224/10000\n",
      "2/2 - 0s - loss: 0.0076 - accuracy: 0.9808 - mse: 0.0076\n",
      "Epoch 225/10000\n",
      "2/2 - 0s - loss: 0.0076 - accuracy: 0.9808 - mse: 0.0076\n",
      "Epoch 226/10000\n",
      "2/2 - 0s - loss: 0.0074 - accuracy: 0.9808 - mse: 0.0074\n",
      "Epoch 227/10000\n",
      "2/2 - 0s - loss: 0.0073 - accuracy: 0.9808 - mse: 0.0073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 228/10000\n",
      "2/2 - 0s - loss: 0.0072 - accuracy: 0.9808 - mse: 0.0072\n",
      "Epoch 229/10000\n",
      "2/2 - 0s - loss: 0.0071 - accuracy: 0.9808 - mse: 0.0071\n",
      "Epoch 230/10000\n",
      "2/2 - 0s - loss: 0.0070 - accuracy: 0.9808 - mse: 0.0070\n",
      "Epoch 231/10000\n",
      "2/2 - 0s - loss: 0.0069 - accuracy: 0.9808 - mse: 0.0069\n",
      "Epoch 232/10000\n",
      "2/2 - 0s - loss: 0.0069 - accuracy: 0.9808 - mse: 0.0069\n",
      "Epoch 233/10000\n",
      "2/2 - 0s - loss: 0.0067 - accuracy: 0.9808 - mse: 0.0067\n",
      "Epoch 234/10000\n",
      "2/2 - 0s - loss: 0.0066 - accuracy: 0.9808 - mse: 0.0066\n",
      "Epoch 235/10000\n",
      "2/2 - 0s - loss: 0.0065 - accuracy: 0.9808 - mse: 0.0065\n",
      "Epoch 236/10000\n",
      "2/2 - 0s - loss: 0.0064 - accuracy: 0.9808 - mse: 0.0064\n",
      "Epoch 237/10000\n",
      "2/2 - 0s - loss: 0.0063 - accuracy: 0.9808 - mse: 0.0063\n",
      "Epoch 238/10000\n",
      "2/2 - 0s - loss: 0.0062 - accuracy: 0.9808 - mse: 0.0062\n",
      "Epoch 239/10000\n",
      "2/2 - 0s - loss: 0.0061 - accuracy: 0.9808 - mse: 0.0061\n",
      "Epoch 240/10000\n",
      "2/2 - 0s - loss: 0.0061 - accuracy: 0.9808 - mse: 0.0061\n",
      "Epoch 241/10000\n",
      "2/2 - 0s - loss: 0.0060 - accuracy: 0.9808 - mse: 0.0060\n",
      "Epoch 242/10000\n",
      "2/2 - 0s - loss: 0.0059 - accuracy: 0.9808 - mse: 0.0059\n",
      "Epoch 243/10000\n",
      "2/2 - 0s - loss: 0.0058 - accuracy: 0.9808 - mse: 0.0058\n",
      "Epoch 244/10000\n",
      "2/2 - 0s - loss: 0.0057 - accuracy: 0.9808 - mse: 0.0057\n",
      "Epoch 245/10000\n",
      "2/2 - 0s - loss: 0.0056 - accuracy: 0.9808 - mse: 0.0056\n",
      "Epoch 246/10000\n",
      "2/2 - 0s - loss: 0.0056 - accuracy: 0.9808 - mse: 0.0056\n",
      "Epoch 247/10000\n",
      "2/2 - 0s - loss: 0.0055 - accuracy: 0.9808 - mse: 0.0055\n",
      "Epoch 248/10000\n",
      "2/2 - 0s - loss: 0.0054 - accuracy: 0.9808 - mse: 0.0054\n",
      "Epoch 249/10000\n",
      "2/2 - 0s - loss: 0.0053 - accuracy: 0.9808 - mse: 0.0053\n",
      "Epoch 250/10000\n",
      "2/2 - 0s - loss: 0.0052 - accuracy: 0.9808 - mse: 0.0052\n",
      "Epoch 251/10000\n",
      "2/2 - 0s - loss: 0.0051 - accuracy: 0.9808 - mse: 0.0051\n",
      "Epoch 252/10000\n",
      "2/2 - 0s - loss: 0.0051 - accuracy: 1.0000 - mse: 0.0051\n",
      "Epoch 253/10000\n",
      "2/2 - 0s - loss: 0.0050 - accuracy: 0.9808 - mse: 0.0050\n",
      "Epoch 254/10000\n",
      "2/2 - 0s - loss: 0.0049 - accuracy: 1.0000 - mse: 0.0049\n",
      "Epoch 255/10000\n",
      "2/2 - 0s - loss: 0.0048 - accuracy: 1.0000 - mse: 0.0048\n",
      "Epoch 256/10000\n",
      "2/2 - 0s - loss: 0.0048 - accuracy: 1.0000 - mse: 0.0048\n",
      "Epoch 257/10000\n",
      "2/2 - 0s - loss: 0.0047 - accuracy: 1.0000 - mse: 0.0047\n",
      "Epoch 258/10000\n",
      "2/2 - 0s - loss: 0.0046 - accuracy: 1.0000 - mse: 0.0046\n",
      "Epoch 259/10000\n",
      "2/2 - 0s - loss: 0.0046 - accuracy: 1.0000 - mse: 0.0046\n",
      "Epoch 260/10000\n",
      "2/2 - 0s - loss: 0.0045 - accuracy: 1.0000 - mse: 0.0045\n",
      "Epoch 261/10000\n",
      "2/2 - 0s - loss: 0.0044 - accuracy: 1.0000 - mse: 0.0044\n",
      "Epoch 262/10000\n",
      "2/2 - 0s - loss: 0.0044 - accuracy: 1.0000 - mse: 0.0044\n",
      "Epoch 263/10000\n",
      "2/2 - 0s - loss: 0.0042 - accuracy: 1.0000 - mse: 0.0042\n",
      "Epoch 264/10000\n",
      "2/2 - 0s - loss: 0.0042 - accuracy: 1.0000 - mse: 0.0042\n",
      "Epoch 265/10000\n",
      "2/2 - 0s - loss: 0.0041 - accuracy: 1.0000 - mse: 0.0041\n",
      "Epoch 266/10000\n",
      "2/2 - 0s - loss: 0.0041 - accuracy: 1.0000 - mse: 0.0041\n",
      "Epoch 267/10000\n",
      "2/2 - 0s - loss: 0.0040 - accuracy: 1.0000 - mse: 0.0040\n",
      "Epoch 268/10000\n",
      "2/2 - 0s - loss: 0.0040 - accuracy: 1.0000 - mse: 0.0040\n",
      "Epoch 269/10000\n",
      "2/2 - 0s - loss: 0.0039 - accuracy: 1.0000 - mse: 0.0039\n",
      "Epoch 270/10000\n",
      "2/2 - 0s - loss: 0.0038 - accuracy: 1.0000 - mse: 0.0038\n",
      "Epoch 271/10000\n",
      "2/2 - 0s - loss: 0.0037 - accuracy: 1.0000 - mse: 0.0037\n",
      "Epoch 272/10000\n",
      "2/2 - 0s - loss: 0.0037 - accuracy: 1.0000 - mse: 0.0037\n",
      "Epoch 273/10000\n",
      "2/2 - 0s - loss: 0.0036 - accuracy: 1.0000 - mse: 0.0036\n",
      "Epoch 274/10000\n",
      "2/2 - 0s - loss: 0.0036 - accuracy: 1.0000 - mse: 0.0036\n",
      "Epoch 275/10000\n",
      "2/2 - 0s - loss: 0.0035 - accuracy: 1.0000 - mse: 0.0035\n",
      "Epoch 276/10000\n",
      "2/2 - 0s - loss: 0.0035 - accuracy: 1.0000 - mse: 0.0035\n",
      "Epoch 277/10000\n",
      "2/2 - 0s - loss: 0.0034 - accuracy: 1.0000 - mse: 0.0034\n",
      "Epoch 278/10000\n",
      "2/2 - 0s - loss: 0.0034 - accuracy: 1.0000 - mse: 0.0034\n",
      "Epoch 279/10000\n",
      "2/2 - 0s - loss: 0.0034 - accuracy: 1.0000 - mse: 0.0034\n",
      "Epoch 280/10000\n",
      "2/2 - 0s - loss: 0.0032 - accuracy: 1.0000 - mse: 0.0032\n",
      "Epoch 281/10000\n",
      "2/2 - 0s - loss: 0.0032 - accuracy: 1.0000 - mse: 0.0032\n",
      "Epoch 282/10000\n",
      "2/2 - 0s - loss: 0.0031 - accuracy: 1.0000 - mse: 0.0031\n",
      "Epoch 283/10000\n",
      "2/2 - 0s - loss: 0.0031 - accuracy: 1.0000 - mse: 0.0031\n",
      "Epoch 284/10000\n",
      "2/2 - 0s - loss: 0.0030 - accuracy: 1.0000 - mse: 0.0030\n",
      "Epoch 285/10000\n",
      "2/2 - 0s - loss: 0.0030 - accuracy: 1.0000 - mse: 0.0030\n",
      "Epoch 286/10000\n",
      "2/2 - 0s - loss: 0.0029 - accuracy: 1.0000 - mse: 0.0029\n",
      "Epoch 287/10000\n",
      "2/2 - 0s - loss: 0.0029 - accuracy: 1.0000 - mse: 0.0029\n",
      "Epoch 288/10000\n",
      "2/2 - 0s - loss: 0.0028 - accuracy: 1.0000 - mse: 0.0028\n",
      "Epoch 289/10000\n",
      "2/2 - 0s - loss: 0.0028 - accuracy: 1.0000 - mse: 0.0028\n",
      "Epoch 290/10000\n",
      "2/2 - 0s - loss: 0.0028 - accuracy: 1.0000 - mse: 0.0028\n",
      "Epoch 291/10000\n",
      "2/2 - 0s - loss: 0.0027 - accuracy: 1.0000 - mse: 0.0027\n",
      "Epoch 292/10000\n",
      "2/2 - 0s - loss: 0.0026 - accuracy: 1.0000 - mse: 0.0026\n",
      "Epoch 293/10000\n",
      "2/2 - 0s - loss: 0.0026 - accuracy: 1.0000 - mse: 0.0026\n",
      "Epoch 294/10000\n",
      "2/2 - 0s - loss: 0.0026 - accuracy: 1.0000 - mse: 0.0026\n",
      "Epoch 295/10000\n",
      "2/2 - 0s - loss: 0.0025 - accuracy: 1.0000 - mse: 0.0025\n",
      "Epoch 296/10000\n",
      "2/2 - 0s - loss: 0.0025 - accuracy: 1.0000 - mse: 0.0025\n",
      "Epoch 297/10000\n",
      "2/2 - 0s - loss: 0.0024 - accuracy: 1.0000 - mse: 0.0024\n",
      "Epoch 298/10000\n",
      "2/2 - 0s - loss: 0.0024 - accuracy: 1.0000 - mse: 0.0024\n",
      "Epoch 299/10000\n",
      "2/2 - 0s - loss: 0.0023 - accuracy: 1.0000 - mse: 0.0023\n",
      "Epoch 300/10000\n",
      "2/2 - 0s - loss: 0.0023 - accuracy: 1.0000 - mse: 0.0023\n",
      "Epoch 301/10000\n",
      "2/2 - 0s - loss: 0.0023 - accuracy: 1.0000 - mse: 0.0023\n",
      "Epoch 302/10000\n",
      "2/2 - 0s - loss: 0.0022 - accuracy: 1.0000 - mse: 0.0022\n",
      "Epoch 303/10000\n",
      "2/2 - 0s - loss: 0.0022 - accuracy: 1.0000 - mse: 0.0022\n",
      "Epoch 304/10000\n",
      "2/2 - 0s - loss: 0.0022 - accuracy: 1.0000 - mse: 0.0022\n",
      "Epoch 305/10000\n",
      "2/2 - 0s - loss: 0.0021 - accuracy: 1.0000 - mse: 0.0021\n",
      "Epoch 306/10000\n",
      "2/2 - 0s - loss: 0.0021 - accuracy: 1.0000 - mse: 0.0021\n",
      "Epoch 307/10000\n",
      "2/2 - 0s - loss: 0.0020 - accuracy: 1.0000 - mse: 0.0020\n",
      "Epoch 308/10000\n",
      "2/2 - 0s - loss: 0.0020 - accuracy: 1.0000 - mse: 0.0020\n",
      "Epoch 309/10000\n",
      "2/2 - 0s - loss: 0.0020 - accuracy: 1.0000 - mse: 0.0020\n",
      "Epoch 310/10000\n",
      "2/2 - 0s - loss: 0.0020 - accuracy: 1.0000 - mse: 0.0020\n",
      "Epoch 311/10000\n",
      "2/2 - 0s - loss: 0.0020 - accuracy: 1.0000 - mse: 0.0020\n",
      "Epoch 312/10000\n",
      "2/2 - 0s - loss: 0.0019 - accuracy: 1.0000 - mse: 0.0019\n",
      "Epoch 313/10000\n",
      "2/2 - 0s - loss: 0.0018 - accuracy: 1.0000 - mse: 0.0018\n",
      "Epoch 314/10000\n",
      "2/2 - 0s - loss: 0.0018 - accuracy: 1.0000 - mse: 0.0018\n",
      "Epoch 315/10000\n",
      "2/2 - 0s - loss: 0.0018 - accuracy: 1.0000 - mse: 0.0018\n",
      "Epoch 316/10000\n",
      "2/2 - 0s - loss: 0.0017 - accuracy: 1.0000 - mse: 0.0017\n",
      "Epoch 317/10000\n",
      "2/2 - 0s - loss: 0.0017 - accuracy: 1.0000 - mse: 0.0017\n",
      "Epoch 318/10000\n",
      "2/2 - 0s - loss: 0.0017 - accuracy: 1.0000 - mse: 0.0017\n",
      "Epoch 319/10000\n",
      "2/2 - 0s - loss: 0.0017 - accuracy: 1.0000 - mse: 0.0017\n",
      "Epoch 320/10000\n",
      "2/2 - 0s - loss: 0.0016 - accuracy: 1.0000 - mse: 0.0016\n",
      "Epoch 321/10000\n",
      "2/2 - 0s - loss: 0.0017 - accuracy: 1.0000 - mse: 0.0017\n",
      "Epoch 322/10000\n",
      "2/2 - 0s - loss: 0.0016 - accuracy: 1.0000 - mse: 0.0016\n",
      "Epoch 323/10000\n",
      "2/2 - 0s - loss: 0.0015 - accuracy: 1.0000 - mse: 0.0015\n",
      "Epoch 324/10000\n",
      "2/2 - 0s - loss: 0.0015 - accuracy: 1.0000 - mse: 0.0015\n",
      "Epoch 325/10000\n",
      "2/2 - 0s - loss: 0.0015 - accuracy: 1.0000 - mse: 0.0015\n",
      "Epoch 326/10000\n",
      "2/2 - 0s - loss: 0.0015 - accuracy: 1.0000 - mse: 0.0015\n",
      "Epoch 327/10000\n",
      "2/2 - 0s - loss: 0.0015 - accuracy: 1.0000 - mse: 0.0015\n",
      "Epoch 328/10000\n",
      "2/2 - 0s - loss: 0.0014 - accuracy: 1.0000 - mse: 0.0014\n",
      "Epoch 329/10000\n",
      "2/2 - 0s - loss: 0.0014 - accuracy: 1.0000 - mse: 0.0014\n",
      "Epoch 330/10000\n",
      "2/2 - 0s - loss: 0.0014 - accuracy: 1.0000 - mse: 0.0014\n",
      "Epoch 331/10000\n",
      "2/2 - 0s - loss: 0.0014 - accuracy: 1.0000 - mse: 0.0014\n",
      "Epoch 332/10000\n",
      "2/2 - 0s - loss: 0.0013 - accuracy: 1.0000 - mse: 0.0013\n",
      "Epoch 333/10000\n",
      "2/2 - 0s - loss: 0.0013 - accuracy: 1.0000 - mse: 0.0013\n",
      "Epoch 334/10000\n",
      "2/2 - 0s - loss: 0.0013 - accuracy: 1.0000 - mse: 0.0013\n",
      "Epoch 335/10000\n",
      "2/2 - 0s - loss: 0.0013 - accuracy: 1.0000 - mse: 0.0013\n",
      "Epoch 336/10000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000 - mse: 0.0012\n",
      "Epoch 337/10000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000 - mse: 0.0012\n",
      "Epoch 338/10000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000 - mse: 0.0012\n",
      "Epoch 339/10000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000 - mse: 0.0012\n",
      "Epoch 340/10000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000 - mse: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 341/10000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - mse: 0.0011\n",
      "Epoch 342/10000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - mse: 0.0011\n",
      "Epoch 343/10000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - mse: 0.0011\n",
      "Epoch 344/10000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - mse: 0.0011\n",
      "Epoch 345/10000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - mse: 0.0011\n",
      "Epoch 346/10000\n",
      "2/2 - 0s - loss: 0.0010 - accuracy: 1.0000 - mse: 0.0010\n",
      "Epoch 347/10000\n",
      "2/2 - 0s - loss: 0.0010 - accuracy: 1.0000 - mse: 0.0010\n",
      "Epoch 348/10000\n",
      "2/2 - 0s - loss: 0.0010 - accuracy: 1.0000 - mse: 0.0010\n",
      "Epoch 349/10000\n",
      "2/2 - 0s - loss: 9.7561e-04 - accuracy: 1.0000 - mse: 9.7561e-04\n",
      "Epoch 350/10000\n",
      "2/2 - 0s - loss: 9.5815e-04 - accuracy: 1.0000 - mse: 9.5815e-04\n",
      "Epoch 351/10000\n",
      "2/2 - 0s - loss: 9.3892e-04 - accuracy: 1.0000 - mse: 9.3892e-04\n",
      "Epoch 352/10000\n",
      "2/2 - 0s - loss: 9.2968e-04 - accuracy: 1.0000 - mse: 9.2968e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b83cf799d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = EarlyStopping(monitor='accuracy', \n",
    "                         patience=100,\n",
    "                         restore_best_weights=True)\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", \n",
    "              loss='mse', \n",
    "              metrics=['accuracy', 'mse'])\n",
    "model.fit(TRAINING_SET_2D, \n",
    "          TRAINING_SET_LABELS, \n",
    "          epochs=10000,\n",
    "          callbacks=[callback], \n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden_layer_1 (Dense)       (None, 26)                936       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 26)                702       \n",
      "=================================================================\n",
      "Total params: 1,638\n",
      "Trainable params: 1,638\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. evaluate the model on TEST_SET. What accuracy do you obtain? If the accuracy is less than 100%, which test images are misclassified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 998us/step - loss: 0.0070 - accuracy: 0.9231 - mse: 0.0070\n"
     ]
    }
   ],
   "source": [
    "model_eval = model.evaluate(TEST_SET_2D, TEST_SET_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy', 'mse']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What accuracy do you obtain?\n",
    "- We get above 80%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  If the accuracy is less than 100%, which test images are misclassified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(TEST_SET_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEST_SET_LABELS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.02634525e-01, 1.27422553e-03, 1.26684876e-03, 2.87163220e-02,\n",
       "        5.09845740e-05, 3.09824682e-04, 4.84121591e-03, 2.15470186e-03,\n",
       "        1.31802866e-04, 1.62616987e-02, 2.76833103e-04, 4.91300598e-03,\n",
       "        2.76513606e-01, 9.92253274e-02, 1.04628981e-03, 1.11520127e-03,\n",
       "        5.81060676e-03, 1.97920129e-02, 1.11513518e-05, 6.40692974e-07,\n",
       "        7.90454913e-04, 9.70839974e-05, 1.74788050e-02, 1.52693652e-02,\n",
       "        1.08305594e-05, 6.52201834e-06],\n",
       "       [1.42948665e-02, 5.36505938e-01, 5.58803044e-02, 2.82549746e-02,\n",
       "        3.50332223e-02, 2.61282586e-02, 3.14158015e-02, 6.29289262e-03,\n",
       "        5.41456044e-04, 2.03689057e-02, 1.12179659e-05, 1.10039460e-02,\n",
       "        6.70435082e-04, 7.42770266e-04, 3.24311815e-02, 5.72175793e-02,\n",
       "        2.76657497e-03, 5.60929291e-02, 6.15555085e-02, 2.37683525e-05,\n",
       "        2.10294835e-02, 5.06386932e-05, 5.94776066e-05, 5.53914229e-04,\n",
       "        4.29575266e-05, 1.03085383e-03],\n",
       "       [6.08127797e-03, 6.07232712e-02, 4.69324619e-01, 3.43168899e-02,\n",
       "        6.85864501e-03, 1.90358993e-03, 1.89538628e-01, 4.22546815e-04,\n",
       "        9.01939720e-03, 2.79338490e-02, 8.09132544e-05, 1.49456458e-02,\n",
       "        2.71366118e-03, 3.90660047e-04, 1.28880471e-01, 2.46395590e-03,\n",
       "        8.59590620e-03, 9.58931912e-03, 1.25041548e-02, 1.16878786e-04,\n",
       "        1.27769094e-02, 7.67635574e-05, 1.01789410e-04, 3.61448620e-04,\n",
       "        4.73636328e-06, 2.73952435e-04],\n",
       "       [1.82689801e-02, 8.91672969e-02, 7.49362186e-02, 4.42277104e-01,\n",
       "        4.58366354e-04, 1.21939543e-03, 3.52176577e-02, 3.97127384e-04,\n",
       "        1.25647977e-03, 5.88308880e-03, 4.60997308e-06, 9.60183609e-03,\n",
       "        2.71803443e-03, 3.24980682e-03, 2.38215446e-01, 4.25202912e-03,\n",
       "        2.19198596e-02, 6.92254491e-03, 5.92552766e-04, 3.00894658e-06,\n",
       "        4.22410183e-02, 3.55836411e-04, 4.72838234e-04, 2.37568616e-04,\n",
       "        1.34273068e-06, 1.29871885e-04],\n",
       "       [4.37150447e-04, 4.59153168e-02, 9.89746768e-03, 3.77385993e-04,\n",
       "        7.81114221e-01, 6.33658841e-02, 1.04818703e-03, 3.03078163e-03,\n",
       "        1.57371906e-04, 8.68865661e-03, 1.68217768e-04, 2.47464050e-02,\n",
       "        3.29291724e-05, 3.39188082e-05, 5.95245918e-04, 9.66712274e-03,\n",
       "        1.07696651e-04, 2.06627753e-02, 1.57877002e-02, 2.20799891e-04,\n",
       "        1.11793599e-03, 7.20350272e-06, 2.09317750e-05, 1.47595280e-03,\n",
       "        1.39033029e-04, 1.11836260e-02],\n",
       "       [7.37453299e-03, 6.86040223e-02, 5.85924415e-03, 2.01280764e-03,\n",
       "        9.08120424e-02, 4.79759306e-01, 1.60924974e-03, 1.18491929e-02,\n",
       "        1.47751169e-04, 3.15516931e-03, 1.20172475e-03, 5.55228256e-03,\n",
       "        8.47892952e-04, 4.83607611e-04, 1.01349794e-03, 2.07678497e-01,\n",
       "        1.19080569e-03, 7.78124109e-02, 6.48379885e-03, 2.35801702e-03,\n",
       "        1.84827636e-03, 3.59626662e-04, 6.35214499e-04, 1.29370987e-02,\n",
       "        2.26525636e-03, 6.14865683e-03],\n",
       "       [1.62985716e-02, 7.49563947e-02, 3.06219637e-01, 1.45559711e-02,\n",
       "        9.31171887e-03, 1.42379338e-03, 3.00301075e-01, 8.84652254e-04,\n",
       "        4.71394463e-03, 1.13301337e-01, 6.87373686e-05, 3.83928157e-02,\n",
       "        2.11038697e-03, 1.34209939e-03, 7.52910078e-02, 9.76561045e-04,\n",
       "        7.18165655e-03, 1.65344086e-02, 1.02313077e-02, 4.36600167e-05,\n",
       "        4.33029514e-03, 2.20242619e-05, 1.45375947e-04, 1.26619230e-03,\n",
       "        3.96692576e-06, 9.25480344e-05],\n",
       "       [1.31951291e-02, 6.29948266e-03, 1.57445684e-04, 7.45274243e-04,\n",
       "        2.04426306e-03, 5.13730664e-03, 5.59494074e-05, 8.12301099e-01,\n",
       "        2.44745820e-07, 3.74939595e-03, 1.08504109e-03, 9.38736089e-03,\n",
       "        6.47459179e-03, 6.06669560e-02, 6.73707618e-05, 2.03365982e-02,\n",
       "        4.58268449e-04, 2.21208874e-02, 1.82180403e-04, 2.21035725e-06,\n",
       "        1.55030154e-02, 6.05095003e-04, 1.10802297e-02, 7.03602377e-03,\n",
       "        1.28228602e-03, 2.62048361e-05],\n",
       "       [6.29128772e-05, 2.30764947e-03, 5.76465018e-03, 2.73611251e-04,\n",
       "        5.05660719e-04, 6.60572201e-04, 1.09037943e-02, 1.03186892e-06,\n",
       "        9.25185621e-01, 8.88243318e-03, 4.83774647e-06, 1.52893539e-04,\n",
       "        1.03950542e-05, 3.15091302e-06, 3.97894008e-04, 5.21891488e-05,\n",
       "        2.11648061e-04, 1.71636144e-04, 1.54812774e-03, 4.20944877e-02,\n",
       "        2.63495094e-05, 7.56150694e-05, 2.40756299e-06, 3.15792713e-04,\n",
       "        1.20329547e-04, 2.64249684e-04],\n",
       "       [9.03126493e-04, 4.70127258e-03, 6.33084401e-03, 9.49264853e-04,\n",
       "        9.02171526e-03, 5.48628205e-03, 1.23140635e-02, 1.02779723e-03,\n",
       "        5.76926768e-03, 8.85919154e-01, 2.34760623e-03, 8.14003497e-03,\n",
       "        5.77219820e-04, 3.22681532e-04, 3.61995510e-04, 6.08802831e-04,\n",
       "        2.67952564e-04, 4.53891698e-03, 1.44808283e-02, 5.96356625e-03,\n",
       "        4.61533054e-04, 2.81331915e-04, 2.09552600e-04, 2.16721687e-02,\n",
       "        4.64078644e-03, 2.70227436e-03],\n",
       "       [6.37125166e-04, 6.31690564e-05, 1.12580208e-04, 1.40170872e-04,\n",
       "        4.42005636e-04, 3.35553149e-03, 1.60077343e-05, 5.05983504e-03,\n",
       "        4.89729382e-06, 1.79840310e-03, 9.02296662e-01, 5.78759937e-03,\n",
       "        4.23733750e-03, 2.54228478e-04, 4.16419880e-06, 3.67787463e-04,\n",
       "        1.89164188e-04, 1.08280862e-02, 6.33459649e-06, 5.99917148e-05,\n",
       "        2.21418726e-04, 8.56422179e-04, 1.43640488e-02, 4.55211923e-02,\n",
       "        3.33222980e-03, 4.34425019e-05],\n",
       "       [1.92125363e-03, 9.56815481e-03, 2.73801554e-02, 1.13341426e-02,\n",
       "        3.27217802e-02, 5.11414139e-03, 2.87619559e-03, 1.00314720e-02,\n",
       "        8.80285341e-04, 2.58271340e-02, 4.63585230e-03, 7.77730167e-01,\n",
       "        2.76442780e-03, 3.53432610e-03, 4.50344058e-03, 1.51012908e-03,\n",
       "        1.57830759e-03, 1.58457030e-02, 1.57008960e-03, 4.62464486e-05,\n",
       "        3.03598102e-02, 2.61488487e-04, 5.44122886e-03, 1.38664823e-02,\n",
       "        2.41156988e-04, 8.45654774e-03],\n",
       "       [1.01058995e-02, 2.00513634e-04, 1.02837002e-04, 1.78394699e-03,\n",
       "        1.41209985e-05, 2.42506052e-04, 5.40679648e-05, 1.32426051e-02,\n",
       "        1.66874111e-06, 2.95755640e-03, 1.25275482e-03, 3.05411057e-03,\n",
       "        7.98527360e-01, 1.20024011e-01, 1.74969082e-05, 5.27430500e-04,\n",
       "        1.64997778e-04, 2.75408896e-03, 3.03722595e-06, 4.76311982e-07,\n",
       "        4.51872824e-03, 2.41809306e-04, 1.60234757e-02, 2.41437703e-02,\n",
       "        3.84487503e-05, 2.28568047e-06],\n",
       "       [2.08946150e-02, 1.32626819e-03, 7.02126636e-05, 2.35252501e-03,\n",
       "        3.41855848e-05, 3.54107731e-04, 5.72823556e-05, 4.30055298e-02,\n",
       "        6.24695758e-07, 2.76499521e-03, 1.10070949e-04, 4.59343335e-03,\n",
       "        2.28862073e-02, 8.41878176e-01, 6.55909171e-05, 2.11496395e-03,\n",
       "        6.39567093e-04, 3.00410856e-03, 4.11286010e-06, 7.50316588e-07,\n",
       "        5.19886753e-03, 6.84583385e-04, 2.34917682e-02, 2.43113264e-02,\n",
       "        1.51433167e-04, 4.69730685e-06],\n",
       "       [1.51254162e-02, 5.54071814e-02, 1.25032499e-01, 1.41797185e-01,\n",
       "        2.67883064e-04, 2.50657176e-04, 1.43789008e-01, 2.03615942e-04,\n",
       "        2.38661398e-03, 8.25902354e-03, 3.54111489e-06, 2.89575662e-03,\n",
       "        2.10874202e-03, 9.67172557e-04, 4.39760804e-01, 1.30462367e-03,\n",
       "        3.28416415e-02, 3.33863264e-03, 1.12305570e-03, 4.19877415e-06,\n",
       "        2.27765590e-02, 1.73429537e-04, 1.30613567e-04, 3.72847608e-05,\n",
       "        4.90101741e-07, 1.42353647e-05],\n",
       "       [3.62990983e-02, 7.01723173e-02, 2.61431257e-03, 8.43486842e-03,\n",
       "        1.02494890e-02, 1.78164035e-01, 1.04690890e-03, 9.31431446e-03,\n",
       "        3.55131669e-05, 7.84116564e-04, 2.31466969e-04, 1.93329481e-03,\n",
       "        7.89604965e-04, 1.10904232e-03, 1.72662409e-03, 5.32300472e-01,\n",
       "        5.65389125e-03, 1.26718491e-01, 8.60686763e-04, 1.82718795e-04,\n",
       "        2.77148630e-03, 6.91052177e-04, 1.00546970e-03, 4.06142697e-03,\n",
       "        1.29815086e-03, 1.55122834e-03],\n",
       "       [6.43421263e-02, 7.53868092e-03, 1.69437714e-02, 8.69661495e-02,\n",
       "        8.34510720e-05, 6.79019839e-04, 2.08595488e-02, 2.31390222e-04,\n",
       "        8.95420206e-04, 1.95364677e-03, 2.74587801e-04, 5.12073981e-03,\n",
       "        4.30764136e-04, 4.52358800e-04, 3.98285203e-02, 1.01124938e-03,\n",
       "        7.13248551e-01, 2.83352938e-02, 6.59732223e-06, 9.43677242e-06,\n",
       "        2.44225888e-03, 1.59824092e-03, 6.43094303e-03, 2.93829886e-04,\n",
       "        1.82492804e-05, 5.07287405e-06],\n",
       "       [7.02563003e-02, 1.35862827e-02, 1.13111991e-03, 4.05502878e-03,\n",
       "        2.99269403e-03, 9.70265865e-02, 5.93238685e-04, 8.64153448e-03,\n",
       "        2.09887367e-05, 7.66059791e-04, 7.32512912e-03, 7.51269097e-03,\n",
       "        3.02844419e-04, 4.16528899e-04, 3.89707508e-04, 8.33907723e-02,\n",
       "        2.57188715e-02, 6.47928178e-01, 4.02313854e-05, 6.27454647e-05,\n",
       "        5.15969179e-04, 6.70671114e-04, 1.08848121e-02, 1.17389318e-02,\n",
       "        3.80831771e-03, 2.23855081e-04],\n",
       "       [5.33307204e-04, 6.68148696e-02, 2.92672049e-02, 6.41878753e-04,\n",
       "        1.65576022e-02, 2.24913470e-03, 5.47742248e-02, 7.65125966e-04,\n",
       "        1.25289499e-03, 1.98102500e-02, 2.70847204e-06, 1.00184581e-03,\n",
       "        7.91152706e-05, 3.27688140e-05, 3.93798994e-03, 1.67008932e-03,\n",
       "        1.08977263e-04, 2.60185357e-03, 7.96527207e-01, 6.00315143e-05,\n",
       "        1.10144622e-03, 1.41799410e-06, 7.96202016e-07, 6.29642309e-05,\n",
       "        1.08522745e-05, 1.33520982e-04],\n",
       "       [9.73669303e-05, 4.23620641e-03, 1.41979940e-03, 2.15405540e-04,\n",
       "        3.03393987e-04, 2.41125133e-02, 9.62125196e-04, 6.97495398e-06,\n",
       "        4.83722165e-02, 2.22779182e-03, 9.18084188e-05, 6.23498418e-05,\n",
       "        2.72878988e-05, 6.78668084e-06, 8.87646747e-05, 1.22328254e-03,\n",
       "        6.01935608e-04, 8.43672606e-04, 3.04180285e-04, 8.94451797e-01,\n",
       "        3.36810845e-05, 2.16553872e-03, 2.42531696e-05, 5.78873884e-03,\n",
       "        1.13230133e-02, 1.00908161e-03],\n",
       "       [1.71532505e-03, 2.68086046e-02, 2.08225176e-02, 4.37747985e-02,\n",
       "        7.67459860e-04, 5.62711910e-04, 3.38739972e-03, 2.32463274e-02,\n",
       "        1.96127687e-04, 4.87527736e-02, 2.09313919e-04, 3.21647711e-02,\n",
       "        1.43161435e-02, 2.57036015e-02, 1.55908829e-02, 1.77738001e-03,\n",
       "        4.79359459e-03, 1.54258660e-03, 1.16946793e-03, 2.20581805e-05,\n",
       "        7.21159279e-01, 6.66742213e-03, 3.46199493e-03, 1.16279966e-03,\n",
       "        1.24629616e-04, 9.99946933e-05],\n",
       "       [6.54993171e-04, 8.62776476e-04, 1.24638609e-04, 1.55461887e-02,\n",
       "        5.59987893e-06, 4.52305307e-04, 1.67150556e-05, 1.62036938e-03,\n",
       "        1.07753713e-05, 4.62665717e-04, 5.64673857e-04, 2.99063773e-04,\n",
       "        3.04585585e-04, 4.15972713e-03, 4.24145052e-04, 1.03467784e-03,\n",
       "        1.39185917e-02, 3.00861400e-04, 5.88385717e-07, 8.20747882e-05,\n",
       "        1.72989797e-02, 9.12999928e-01, 2.60387100e-02, 8.77775135e-04,\n",
       "        1.93114299e-03, 7.37159371e-06],\n",
       "       [1.50917200e-02, 8.82940441e-02, 1.74527746e-02, 4.58554886e-02,\n",
       "        9.41622828e-04, 5.51030459e-03, 5.91081986e-03, 7.07076639e-02,\n",
       "        9.65841929e-04, 5.44907749e-02, 1.33169291e-03, 6.90148249e-02,\n",
       "        1.94552392e-02, 3.66755575e-02, 1.56836156e-02, 1.07598249e-02,\n",
       "        4.24473286e-02, 1.94530953e-02, 8.78944178e-04, 2.44097726e-04,\n",
       "        3.96887630e-01, 1.95063483e-02, 4.93645482e-02, 9.38053336e-03,\n",
       "        3.47802253e-03, 2.17708570e-04],\n",
       "       [1.57706765e-03, 9.64370847e-04, 4.91983701e-05, 4.89140453e-04,\n",
       "        3.29142727e-04, 3.85449384e-03, 2.25574368e-05, 5.21153538e-03,\n",
       "        1.64106041e-05, 1.37051865e-02, 2.55112443e-03, 1.87547021e-02,\n",
       "        5.27690630e-03, 4.08178084e-02, 7.94034258e-06, 1.80667778e-03,\n",
       "        1.35104819e-05, 7.13932654e-03, 1.24267928e-04, 4.17933152e-05,\n",
       "        3.65799235e-04, 1.23667225e-04, 2.44751060e-03, 8.73949885e-01,\n",
       "        9.59711149e-03, 1.07627939e-02],\n",
       "       [3.21614534e-05, 8.11442267e-04, 3.30174335e-05, 9.60967081e-05,\n",
       "        5.41103109e-05, 4.20950819e-03, 4.92179151e-06, 7.08805514e-04,\n",
       "        1.18758129e-04, 2.30325712e-03, 1.45129242e-03, 3.60214268e-04,\n",
       "        2.24851628e-05, 1.01200174e-04, 3.08324024e-06, 6.68649038e-04,\n",
       "        1.18806267e-04, 7.07067724e-04, 5.50513942e-05, 1.13674123e-02,\n",
       "        2.52252270e-04, 8.85493029e-03, 5.14526851e-04, 2.66278386e-02,\n",
       "        9.38939214e-01, 1.58391753e-03],\n",
       "       [5.82891480e-05, 1.32008782e-02, 7.43741461e-04, 2.41959890e-04,\n",
       "        1.31075144e-01, 4.91343476e-02, 1.05734696e-04, 2.73058860e-04,\n",
       "        2.52739468e-04, 1.71203092e-02, 5.68051328e-05, 1.11957872e-02,\n",
       "        1.04700011e-05, 1.69091636e-05, 5.38217282e-05, 3.94145818e-03,\n",
       "        5.29831323e-06, 5.89567842e-03, 8.53055622e-03, 5.22368297e-04,\n",
       "        2.24549978e-04, 4.55744157e-06, 3.76526646e-06, 5.87228546e-03,\n",
       "        1.00787543e-03, 7.50451684e-01]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If the accuracy is less than 100%, which test images are misclassified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_misclassified_img(pred):\n",
    "    n = len(pred)\n",
    "    if n == 0: return None\n",
    "    res = []\n",
    "    misclf_count = 0\n",
    "    for i in range(n):\n",
    "        # inspired from https://stackoverflow.com/questions/6193498/pythonic-way-to-find-maximum-value-and-its-index-in-a-list\n",
    "        idx, _ = max(enumerate(pred[i]), key=operator.itemgetter(1))\n",
    "        curr = chr(idx + ord('A'))\n",
    "        true_letter = chr(i + ord('A'))\n",
    "        if curr != true_letter:\n",
    "            prompt = 'Pred: ' + curr + ' True: ' + true_letter\n",
    "            print(prompt)\n",
    "            res += true_letter\n",
    "            misclf_count += 1\n",
    "    return [res, misclf_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: C True: G\n",
      "Pred: U True: W\n"
     ]
    }
   ],
   "source": [
    "misclassfication_orgin_model = show_misclassified_img(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test images are misclassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['G', 'W']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassfication_orgin_model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9230769230769231"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(26-misclassfication_orgin_model[1])/26 # accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9230769276618958"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_eval[1] # accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Use your trained model and chr() to identify the letters in MESSAGE. What does it say in English? (Note that there are no spaces between words.) Why do you suppose this was chosen as the message?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(MESSAGE_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(MESSAGE_2D[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_pred_arr = model.predict(MESSAGE_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(msg_pred_arr[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does it say in English?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_msg_pred(msg_pred):\n",
    "    res = \"\"\n",
    "    for letter_img in msg_pred:\n",
    "        idx, _ = max(enumerate(letter_img), key=operator.itemgetter(1))\n",
    "        letter_pred = chr(idx + ord('A'))\n",
    "        print(letter_pred, end='')\n",
    "        res += letter_pred\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UATCHJEOPARDYALEXTREBEKSFUNTVQUIZGAME"
     ]
    }
   ],
   "source": [
    "msg_pred = get_msg_pred(msg_pred_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do you suppose this was chosen as the message?\n",
    "WATCHJEOPARDYALEXTREBEKSFUNTVQUIZGAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the true message with predicted message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_with_true_message(msg_pred):\n",
    "    true_msg = \"WATCHJEOPARDYALEXTREBEKSFUNTVQUIZGAME\"\n",
    "    print('{:<7}{:<7}'.format(\"True\", \"Predict\"))\n",
    "    for true_letter, pred_letter in zip(true_msg, msg_pred):\n",
    "        if true_letter != pred_letter:\n",
    "            print('{:<7}{:<7}'.format(true_letter, pred_letter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True   Predict\n",
      "W      U      \n"
     ]
    }
   ],
   "source": [
    "compare_with_true_message(msg_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you completed Project 1, how does this model compare with the performance of your perceptron models? Were any letters misclassified?\n",
    "This model performs far better than project 1. And, yes there are still some letters that are misclassified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. All of the letters in MESSAGE were likely not decoded correctly, so lets try to improve the performance of the model by adding additional hidden layers. Add two additional hidden layers of the same size as your original hidden layer, then repeat experiments (5) and (7). Does the performance improve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 26)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_mul_layers = Sequential()\n",
    "model_with_mul_layers.add(Dense(26, \n",
    "                input_shape=(35,), \n",
    "                kernel_initializer='random_normal',\n",
    "                activation='relu',\n",
    "                name=\"hidden_layer_1\"))\n",
    "model_with_mul_layers.add(Dense(26, \n",
    "                input_shape=(35,), \n",
    "                activation='relu',\n",
    "                name=\"hidden_layer_2\"))\n",
    "model_with_mul_layers.add(Dense(26, \n",
    "                input_shape=(35,), \n",
    "                activation='relu',\n",
    "                name=\"hidden_layer_3\"))\n",
    "model_with_mul_layers.add(Dense(26, \n",
    "                input_shape=(35,), \n",
    "                activation=softmax, \n",
    "                name=\"output_layer\"))\n",
    "# model_with_mul_layers.add(Activation('softmax'))\n",
    "model_with_mul_layers.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000000\n",
      "2/2 - 0s - loss: 0.0370 - accuracy: 0.0385\n",
      "Epoch 2/1000000\n",
      "2/2 - 0s - loss: 0.0369 - accuracy: 0.0769\n",
      "Epoch 3/1000000\n",
      "2/2 - 0s - loss: 0.0369 - accuracy: 0.0769\n",
      "Epoch 4/1000000\n",
      "2/2 - 0s - loss: 0.0369 - accuracy: 0.0769\n",
      "Epoch 5/1000000\n",
      "2/2 - 0s - loss: 0.0368 - accuracy: 0.0769\n",
      "Epoch 6/1000000\n",
      "2/2 - 0s - loss: 0.0368 - accuracy: 0.0769\n",
      "Epoch 7/1000000\n",
      "2/2 - 0s - loss: 0.0367 - accuracy: 0.0962\n",
      "Epoch 8/1000000\n",
      "2/2 - 0s - loss: 0.0367 - accuracy: 0.1346\n",
      "Epoch 9/1000000\n",
      "2/2 - 0s - loss: 0.0367 - accuracy: 0.0962\n",
      "Epoch 10/1000000\n",
      "2/2 - 0s - loss: 0.0366 - accuracy: 0.1346\n",
      "Epoch 11/1000000\n",
      "2/2 - 0s - loss: 0.0365 - accuracy: 0.0962\n",
      "Epoch 12/1000000\n",
      "2/2 - 0s - loss: 0.0365 - accuracy: 0.1346\n",
      "Epoch 13/1000000\n",
      "2/2 - 0s - loss: 0.0364 - accuracy: 0.1346\n",
      "Epoch 14/1000000\n",
      "2/2 - 0s - loss: 0.0364 - accuracy: 0.1346\n",
      "Epoch 15/1000000\n",
      "2/2 - 0s - loss: 0.0363 - accuracy: 0.1346\n",
      "Epoch 16/1000000\n",
      "2/2 - 0s - loss: 0.0362 - accuracy: 0.1346\n",
      "Epoch 17/1000000\n",
      "2/2 - 0s - loss: 0.0361 - accuracy: 0.1346\n",
      "Epoch 18/1000000\n",
      "2/2 - 0s - loss: 0.0360 - accuracy: 0.1346\n",
      "Epoch 19/1000000\n",
      "2/2 - 0s - loss: 0.0359 - accuracy: 0.1346\n",
      "Epoch 20/1000000\n",
      "2/2 - 0s - loss: 0.0357 - accuracy: 0.1346\n",
      "Epoch 21/1000000\n",
      "2/2 - 0s - loss: 0.0356 - accuracy: 0.1346\n",
      "Epoch 22/1000000\n",
      "2/2 - 0s - loss: 0.0355 - accuracy: 0.1538\n",
      "Epoch 23/1000000\n",
      "2/2 - 0s - loss: 0.0354 - accuracy: 0.1538\n",
      "Epoch 24/1000000\n",
      "2/2 - 0s - loss: 0.0353 - accuracy: 0.1538\n",
      "Epoch 25/1000000\n",
      "2/2 - 0s - loss: 0.0352 - accuracy: 0.1538\n",
      "Epoch 26/1000000\n",
      "2/2 - 0s - loss: 0.0351 - accuracy: 0.1538\n",
      "Epoch 27/1000000\n",
      "2/2 - 0s - loss: 0.0350 - accuracy: 0.1538\n",
      "Epoch 28/1000000\n",
      "2/2 - 0s - loss: 0.0349 - accuracy: 0.1538\n",
      "Epoch 29/1000000\n",
      "2/2 - 0s - loss: 0.0348 - accuracy: 0.1538\n",
      "Epoch 30/1000000\n",
      "2/2 - 0s - loss: 0.0346 - accuracy: 0.1538\n",
      "Epoch 31/1000000\n",
      "2/2 - 0s - loss: 0.0345 - accuracy: 0.1538\n",
      "Epoch 32/1000000\n",
      "2/2 - 0s - loss: 0.0344 - accuracy: 0.1731\n",
      "Epoch 33/1000000\n",
      "2/2 - 0s - loss: 0.0343 - accuracy: 0.1731\n",
      "Epoch 34/1000000\n",
      "2/2 - 0s - loss: 0.0342 - accuracy: 0.1731\n",
      "Epoch 35/1000000\n",
      "2/2 - 0s - loss: 0.0340 - accuracy: 0.1731\n",
      "Epoch 36/1000000\n",
      "2/2 - 0s - loss: 0.0339 - accuracy: 0.1731\n",
      "Epoch 37/1000000\n",
      "2/2 - 0s - loss: 0.0337 - accuracy: 0.2308\n",
      "Epoch 38/1000000\n",
      "2/2 - 0s - loss: 0.0336 - accuracy: 0.2308\n",
      "Epoch 39/1000000\n",
      "2/2 - 0s - loss: 0.0334 - accuracy: 0.1731\n",
      "Epoch 40/1000000\n",
      "2/2 - 0s - loss: 0.0332 - accuracy: 0.2308\n",
      "Epoch 41/1000000\n",
      "2/2 - 0s - loss: 0.0331 - accuracy: 0.2308\n",
      "Epoch 42/1000000\n",
      "2/2 - 0s - loss: 0.0329 - accuracy: 0.2500\n",
      "Epoch 43/1000000\n",
      "2/2 - 0s - loss: 0.0328 - accuracy: 0.2500\n",
      "Epoch 44/1000000\n",
      "2/2 - 0s - loss: 0.0325 - accuracy: 0.2308\n",
      "Epoch 45/1000000\n",
      "2/2 - 0s - loss: 0.0323 - accuracy: 0.2500\n",
      "Epoch 46/1000000\n",
      "2/2 - 0s - loss: 0.0322 - accuracy: 0.2500\n",
      "Epoch 47/1000000\n",
      "2/2 - 0s - loss: 0.0320 - accuracy: 0.2692\n",
      "Epoch 48/1000000\n",
      "2/2 - 0s - loss: 0.0318 - accuracy: 0.2500\n",
      "Epoch 49/1000000\n",
      "2/2 - 0s - loss: 0.0316 - accuracy: 0.2692\n",
      "Epoch 50/1000000\n",
      "2/2 - 0s - loss: 0.0314 - accuracy: 0.2692\n",
      "Epoch 51/1000000\n",
      "2/2 - 0s - loss: 0.0313 - accuracy: 0.2692\n",
      "Epoch 52/1000000\n",
      "2/2 - 0s - loss: 0.0310 - accuracy: 0.3077\n",
      "Epoch 53/1000000\n",
      "2/2 - 0s - loss: 0.0308 - accuracy: 0.3077\n",
      "Epoch 54/1000000\n",
      "2/2 - 0s - loss: 0.0306 - accuracy: 0.3269\n",
      "Epoch 55/1000000\n",
      "2/2 - 0s - loss: 0.0304 - accuracy: 0.3269\n",
      "Epoch 56/1000000\n",
      "2/2 - 0s - loss: 0.0302 - accuracy: 0.3846\n",
      "Epoch 57/1000000\n",
      "2/2 - 0s - loss: 0.0300 - accuracy: 0.4231\n",
      "Epoch 58/1000000\n",
      "2/2 - 0s - loss: 0.0298 - accuracy: 0.4038\n",
      "Epoch 59/1000000\n",
      "2/2 - 0s - loss: 0.0297 - accuracy: 0.3846\n",
      "Epoch 60/1000000\n",
      "2/2 - 0s - loss: 0.0293 - accuracy: 0.4038\n",
      "Epoch 61/1000000\n",
      "2/2 - 0s - loss: 0.0291 - accuracy: 0.4423\n",
      "Epoch 62/1000000\n",
      "2/2 - 0s - loss: 0.0289 - accuracy: 0.4423\n",
      "Epoch 63/1000000\n",
      "2/2 - 0s - loss: 0.0287 - accuracy: 0.4808\n",
      "Epoch 64/1000000\n",
      "2/2 - 0s - loss: 0.0284 - accuracy: 0.4231\n",
      "Epoch 65/1000000\n",
      "2/2 - 0s - loss: 0.0282 - accuracy: 0.4808\n",
      "Epoch 66/1000000\n",
      "2/2 - 0s - loss: 0.0279 - accuracy: 0.4423\n",
      "Epoch 67/1000000\n",
      "2/2 - 0s - loss: 0.0276 - accuracy: 0.4615\n",
      "Epoch 68/1000000\n",
      "2/2 - 0s - loss: 0.0274 - accuracy: 0.5000\n",
      "Epoch 69/1000000\n",
      "2/2 - 0s - loss: 0.0271 - accuracy: 0.4423\n",
      "Epoch 70/1000000\n",
      "2/2 - 0s - loss: 0.0268 - accuracy: 0.4423\n",
      "Epoch 71/1000000\n",
      "2/2 - 0s - loss: 0.0266 - accuracy: 0.5000\n",
      "Epoch 72/1000000\n",
      "2/2 - 0s - loss: 0.0263 - accuracy: 0.4808\n",
      "Epoch 73/1000000\n",
      "2/2 - 0s - loss: 0.0261 - accuracy: 0.5192\n",
      "Epoch 74/1000000\n",
      "2/2 - 0s - loss: 0.0258 - accuracy: 0.5192\n",
      "Epoch 75/1000000\n",
      "2/2 - 0s - loss: 0.0254 - accuracy: 0.5577\n",
      "Epoch 76/1000000\n",
      "2/2 - 0s - loss: 0.0251 - accuracy: 0.5577\n",
      "Epoch 77/1000000\n",
      "2/2 - 0s - loss: 0.0248 - accuracy: 0.5769\n",
      "Epoch 78/1000000\n",
      "2/2 - 0s - loss: 0.0245 - accuracy: 0.6154\n",
      "Epoch 79/1000000\n",
      "2/2 - 0s - loss: 0.0242 - accuracy: 0.6346\n",
      "Epoch 80/1000000\n",
      "2/2 - 0s - loss: 0.0239 - accuracy: 0.6346\n",
      "Epoch 81/1000000\n",
      "2/2 - 0s - loss: 0.0235 - accuracy: 0.6538\n",
      "Epoch 82/1000000\n",
      "2/2 - 0s - loss: 0.0232 - accuracy: 0.6538\n",
      "Epoch 83/1000000\n",
      "2/2 - 0s - loss: 0.0230 - accuracy: 0.6538\n",
      "Epoch 84/1000000\n",
      "2/2 - 0s - loss: 0.0226 - accuracy: 0.6538\n",
      "Epoch 85/1000000\n",
      "2/2 - 0s - loss: 0.0222 - accuracy: 0.6538\n",
      "Epoch 86/1000000\n",
      "2/2 - 0s - loss: 0.0219 - accuracy: 0.6538\n",
      "Epoch 87/1000000\n",
      "2/2 - 0s - loss: 0.0215 - accuracy: 0.6538\n",
      "Epoch 88/1000000\n",
      "2/2 - 0s - loss: 0.0211 - accuracy: 0.6923\n",
      "Epoch 89/1000000\n",
      "2/2 - 0s - loss: 0.0209 - accuracy: 0.6923\n",
      "Epoch 90/1000000\n",
      "2/2 - 0s - loss: 0.0205 - accuracy: 0.6923\n",
      "Epoch 91/1000000\n",
      "2/2 - 0s - loss: 0.0201 - accuracy: 0.7115\n",
      "Epoch 92/1000000\n",
      "2/2 - 0s - loss: 0.0199 - accuracy: 0.7115\n",
      "Epoch 93/1000000\n",
      "2/2 - 0s - loss: 0.0195 - accuracy: 0.7115\n",
      "Epoch 94/1000000\n",
      "2/2 - 0s - loss: 0.0191 - accuracy: 0.7115\n",
      "Epoch 95/1000000\n",
      "2/2 - 0s - loss: 0.0188 - accuracy: 0.7115\n",
      "Epoch 96/1000000\n",
      "2/2 - 0s - loss: 0.0185 - accuracy: 0.7115\n",
      "Epoch 97/1000000\n",
      "2/2 - 0s - loss: 0.0181 - accuracy: 0.7308\n",
      "Epoch 98/1000000\n",
      "2/2 - 0s - loss: 0.0177 - accuracy: 0.7308\n",
      "Epoch 99/1000000\n",
      "2/2 - 0s - loss: 0.0175 - accuracy: 0.7308\n",
      "Epoch 100/1000000\n",
      "2/2 - 0s - loss: 0.0171 - accuracy: 0.7308\n",
      "Epoch 101/1000000\n",
      "2/2 - 0s - loss: 0.0166 - accuracy: 0.7308\n",
      "Epoch 102/1000000\n",
      "2/2 - 0s - loss: 0.0163 - accuracy: 0.7308\n",
      "Epoch 103/1000000\n",
      "2/2 - 0s - loss: 0.0159 - accuracy: 0.7500\n",
      "Epoch 104/1000000\n",
      "2/2 - 0s - loss: 0.0156 - accuracy: 0.7500\n",
      "Epoch 105/1000000\n",
      "2/2 - 0s - loss: 0.0152 - accuracy: 0.7308\n",
      "Epoch 106/1000000\n",
      "2/2 - 0s - loss: 0.0150 - accuracy: 0.7692\n",
      "Epoch 107/1000000\n",
      "2/2 - 0s - loss: 0.0146 - accuracy: 0.7885\n",
      "Epoch 108/1000000\n",
      "2/2 - 0s - loss: 0.0141 - accuracy: 0.7885\n",
      "Epoch 109/1000000\n",
      "2/2 - 0s - loss: 0.0139 - accuracy: 0.8077\n",
      "Epoch 110/1000000\n",
      "2/2 - 0s - loss: 0.0136 - accuracy: 0.8077\n",
      "Epoch 111/1000000\n",
      "2/2 - 0s - loss: 0.0132 - accuracy: 0.8077\n",
      "Epoch 112/1000000\n",
      "2/2 - 0s - loss: 0.0127 - accuracy: 0.8269\n",
      "Epoch 113/1000000\n",
      "2/2 - 0s - loss: 0.0124 - accuracy: 0.8654\n",
      "Epoch 114/1000000\n",
      "2/2 - 0s - loss: 0.0122 - accuracy: 0.8269\n",
      "Epoch 115/1000000\n",
      "2/2 - 0s - loss: 0.0118 - accuracy: 0.8654\n",
      "Epoch 116/1000000\n",
      "2/2 - 0s - loss: 0.0114 - accuracy: 0.8269\n",
      "Epoch 117/1000000\n",
      "2/2 - 0s - loss: 0.0111 - accuracy: 0.8654\n",
      "Epoch 118/1000000\n",
      "2/2 - 0s - loss: 0.0107 - accuracy: 0.8654\n",
      "Epoch 119/1000000\n",
      "2/2 - 0s - loss: 0.0104 - accuracy: 0.8654\n",
      "Epoch 120/1000000\n",
      "2/2 - 0s - loss: 0.0101 - accuracy: 0.8654\n",
      "Epoch 121/1000000\n",
      "2/2 - 0s - loss: 0.0098 - accuracy: 0.8846\n",
      "Epoch 122/1000000\n",
      "2/2 - 0s - loss: 0.0094 - accuracy: 0.8846\n",
      "Epoch 123/1000000\n",
      "2/2 - 0s - loss: 0.0091 - accuracy: 0.9038\n",
      "Epoch 124/1000000\n",
      "2/2 - 0s - loss: 0.0089 - accuracy: 0.8654\n",
      "Epoch 125/1000000\n",
      "2/2 - 0s - loss: 0.0087 - accuracy: 0.8846\n",
      "Epoch 126/1000000\n",
      "2/2 - 0s - loss: 0.0083 - accuracy: 0.9423\n",
      "Epoch 127/1000000\n",
      "2/2 - 0s - loss: 0.0080 - accuracy: 0.9423\n",
      "Epoch 128/1000000\n",
      "2/2 - 0s - loss: 0.0079 - accuracy: 0.9423\n",
      "Epoch 129/1000000\n",
      "2/2 - 0s - loss: 0.0076 - accuracy: 0.9423\n",
      "Epoch 130/1000000\n",
      "2/2 - 0s - loss: 0.0073 - accuracy: 0.9423\n",
      "Epoch 131/1000000\n",
      "2/2 - 0s - loss: 0.0071 - accuracy: 0.9423\n",
      "Epoch 132/1000000\n",
      "2/2 - 0s - loss: 0.0068 - accuracy: 0.9423\n",
      "Epoch 133/1000000\n",
      "2/2 - 0s - loss: 0.0068 - accuracy: 0.9423\n",
      "Epoch 134/1000000\n",
      "2/2 - 0s - loss: 0.0064 - accuracy: 0.9423\n",
      "Epoch 135/1000000\n",
      "2/2 - 0s - loss: 0.0063 - accuracy: 0.9423\n",
      "Epoch 136/1000000\n",
      "2/2 - 0s - loss: 0.0063 - accuracy: 0.9423\n",
      "Epoch 137/1000000\n",
      "2/2 - 0s - loss: 0.0060 - accuracy: 0.9423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138/1000000\n",
      "2/2 - 0s - loss: 0.0058 - accuracy: 0.9423\n",
      "Epoch 139/1000000\n",
      "2/2 - 0s - loss: 0.0057 - accuracy: 0.9423\n",
      "Epoch 140/1000000\n",
      "2/2 - 0s - loss: 0.0054 - accuracy: 0.9423\n",
      "Epoch 141/1000000\n",
      "2/2 - 0s - loss: 0.0053 - accuracy: 0.9423\n",
      "Epoch 142/1000000\n",
      "2/2 - 0s - loss: 0.0051 - accuracy: 0.9423\n",
      "Epoch 143/1000000\n",
      "2/2 - 0s - loss: 0.0050 - accuracy: 0.9423\n",
      "Epoch 144/1000000\n",
      "2/2 - 0s - loss: 0.0050 - accuracy: 0.9423\n",
      "Epoch 145/1000000\n",
      "2/2 - 0s - loss: 0.0048 - accuracy: 0.9615\n",
      "Epoch 146/1000000\n",
      "2/2 - 0s - loss: 0.0046 - accuracy: 0.9615\n",
      "Epoch 147/1000000\n",
      "2/2 - 0s - loss: 0.0044 - accuracy: 0.9615\n",
      "Epoch 148/1000000\n",
      "2/2 - 0s - loss: 0.0044 - accuracy: 0.9423\n",
      "Epoch 149/1000000\n",
      "2/2 - 0s - loss: 0.0045 - accuracy: 0.9615\n",
      "Epoch 150/1000000\n",
      "2/2 - 0s - loss: 0.0043 - accuracy: 0.9615\n",
      "Epoch 151/1000000\n",
      "2/2 - 0s - loss: 0.0040 - accuracy: 0.9615\n",
      "Epoch 152/1000000\n",
      "2/2 - 0s - loss: 0.0040 - accuracy: 0.9615\n",
      "Epoch 153/1000000\n",
      "2/2 - 0s - loss: 0.0038 - accuracy: 0.9615\n",
      "Epoch 154/1000000\n",
      "2/2 - 0s - loss: 0.0039 - accuracy: 0.9615\n",
      "Epoch 155/1000000\n",
      "2/2 - 0s - loss: 0.0038 - accuracy: 0.9615\n",
      "Epoch 156/1000000\n",
      "2/2 - 0s - loss: 0.0037 - accuracy: 0.9615\n",
      "Epoch 157/1000000\n",
      "2/2 - 0s - loss: 0.0035 - accuracy: 0.9615\n",
      "Epoch 158/1000000\n",
      "2/2 - 0s - loss: 0.0035 - accuracy: 0.9615\n",
      "Epoch 159/1000000\n",
      "2/2 - 0s - loss: 0.0034 - accuracy: 0.9615\n",
      "Epoch 160/1000000\n",
      "2/2 - 0s - loss: 0.0031 - accuracy: 0.9615\n",
      "Epoch 161/1000000\n",
      "2/2 - 0s - loss: 0.0029 - accuracy: 0.9615\n",
      "Epoch 162/1000000\n",
      "2/2 - 0s - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 163/1000000\n",
      "2/2 - 0s - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 164/1000000\n",
      "2/2 - 0s - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 165/1000000\n",
      "2/2 - 0s - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 166/1000000\n",
      "2/2 - 0s - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 167/1000000\n",
      "2/2 - 0s - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 168/1000000\n",
      "2/2 - 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 169/1000000\n",
      "2/2 - 0s - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 170/1000000\n",
      "2/2 - 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 171/1000000\n",
      "2/2 - 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 172/1000000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 173/1000000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 174/1000000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 175/1000000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 176/1000000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 177/1000000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 178/1000000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 179/1000000\n",
      "2/2 - 0s - loss: 8.8977e-04 - accuracy: 1.0000\n",
      "Epoch 180/1000000\n",
      "2/2 - 0s - loss: 8.6008e-04 - accuracy: 1.0000\n",
      "Epoch 181/1000000\n",
      "2/2 - 0s - loss: 8.0741e-04 - accuracy: 1.0000\n",
      "Epoch 182/1000000\n",
      "2/2 - 0s - loss: 7.4870e-04 - accuracy: 1.0000\n",
      "Epoch 183/1000000\n",
      "2/2 - 0s - loss: 7.1083e-04 - accuracy: 1.0000\n",
      "Epoch 184/1000000\n",
      "2/2 - 0s - loss: 7.0187e-04 - accuracy: 1.0000\n",
      "Epoch 185/1000000\n",
      "2/2 - 0s - loss: 7.0637e-04 - accuracy: 1.0000\n",
      "Epoch 186/1000000\n",
      "2/2 - 0s - loss: 6.8324e-04 - accuracy: 1.0000\n",
      "Epoch 187/1000000\n",
      "2/2 - 0s - loss: 5.9471e-04 - accuracy: 1.0000\n",
      "Epoch 188/1000000\n",
      "2/2 - 0s - loss: 5.5667e-04 - accuracy: 1.0000\n",
      "Epoch 189/1000000\n",
      "2/2 - 0s - loss: 5.2602e-04 - accuracy: 1.0000\n",
      "Epoch 190/1000000\n",
      "2/2 - 0s - loss: 5.1293e-04 - accuracy: 1.0000\n",
      "Epoch 191/1000000\n",
      "2/2 - 0s - loss: 5.5974e-04 - accuracy: 1.0000\n",
      "Epoch 192/1000000\n",
      "2/2 - 0s - loss: 5.2030e-04 - accuracy: 1.0000\n",
      "Epoch 193/1000000\n",
      "2/2 - 0s - loss: 4.3066e-04 - accuracy: 1.0000\n",
      "Epoch 194/1000000\n",
      "2/2 - 0s - loss: 4.6121e-04 - accuracy: 1.0000\n",
      "Epoch 195/1000000\n",
      "2/2 - 0s - loss: 4.4216e-04 - accuracy: 1.0000\n",
      "Epoch 196/1000000\n",
      "2/2 - 0s - loss: 3.4682e-04 - accuracy: 1.0000\n",
      "Epoch 197/1000000\n",
      "2/2 - 0s - loss: 3.4722e-04 - accuracy: 1.0000\n",
      "Epoch 198/1000000\n",
      "2/2 - 0s - loss: 3.4607e-04 - accuracy: 1.0000\n",
      "Epoch 199/1000000\n",
      "2/2 - 0s - loss: 3.1831e-04 - accuracy: 1.0000\n",
      "Epoch 200/1000000\n",
      "2/2 - 0s - loss: 2.8813e-04 - accuracy: 1.0000\n",
      "Epoch 201/1000000\n",
      "2/2 - 0s - loss: 2.9222e-04 - accuracy: 1.0000\n",
      "Epoch 202/1000000\n",
      "2/2 - 0s - loss: 3.5003e-04 - accuracy: 1.0000\n",
      "Epoch 203/1000000\n",
      "2/2 - 0s - loss: 2.7558e-04 - accuracy: 1.0000\n",
      "Epoch 204/1000000\n",
      "2/2 - 0s - loss: 2.4567e-04 - accuracy: 1.0000\n",
      "Epoch 205/1000000\n",
      "2/2 - 0s - loss: 2.3153e-04 - accuracy: 1.0000\n",
      "Epoch 206/1000000\n",
      "2/2 - 0s - loss: 2.0333e-04 - accuracy: 1.0000\n",
      "Epoch 207/1000000\n",
      "2/2 - 0s - loss: 1.9721e-04 - accuracy: 1.0000\n",
      "Epoch 208/1000000\n",
      "2/2 - 0s - loss: 1.8443e-04 - accuracy: 1.0000\n",
      "Epoch 209/1000000\n",
      "2/2 - 0s - loss: 1.8081e-04 - accuracy: 1.0000\n",
      "Epoch 210/1000000\n",
      "2/2 - 0s - loss: 1.8006e-04 - accuracy: 1.0000\n",
      "Epoch 211/1000000\n",
      "2/2 - 0s - loss: 1.7633e-04 - accuracy: 1.0000\n",
      "Epoch 212/1000000\n",
      "2/2 - 0s - loss: 1.4924e-04 - accuracy: 1.0000\n",
      "Epoch 213/1000000\n",
      "2/2 - 0s - loss: 1.4098e-04 - accuracy: 1.0000\n",
      "Epoch 214/1000000\n",
      "2/2 - 0s - loss: 1.6938e-04 - accuracy: 1.0000\n",
      "Epoch 215/1000000\n",
      "2/2 - 0s - loss: 1.7939e-04 - accuracy: 1.0000\n",
      "Epoch 216/1000000\n",
      "2/2 - 0s - loss: 1.1893e-04 - accuracy: 1.0000\n",
      "Epoch 217/1000000\n",
      "2/2 - 0s - loss: 1.2187e-04 - accuracy: 1.0000\n",
      "Epoch 218/1000000\n",
      "2/2 - 0s - loss: 1.4191e-04 - accuracy: 1.0000\n",
      "Epoch 219/1000000\n",
      "2/2 - 0s - loss: 9.4406e-05 - accuracy: 1.0000\n",
      "Epoch 220/1000000\n",
      "2/2 - 0s - loss: 8.8195e-05 - accuracy: 1.0000\n",
      "Epoch 221/1000000\n",
      "2/2 - 0s - loss: 8.5087e-05 - accuracy: 1.0000\n",
      "Epoch 222/1000000\n",
      "2/2 - 0s - loss: 7.6131e-05 - accuracy: 1.0000\n",
      "Epoch 223/1000000\n",
      "2/2 - 0s - loss: 8.2056e-05 - accuracy: 1.0000\n",
      "Epoch 224/1000000\n",
      "2/2 - 0s - loss: 9.0943e-05 - accuracy: 1.0000\n",
      "Epoch 225/1000000\n",
      "2/2 - 0s - loss: 7.6651e-05 - accuracy: 1.0000\n",
      "Epoch 226/1000000\n",
      "2/2 - 0s - loss: 6.5489e-05 - accuracy: 1.0000\n",
      "Epoch 227/1000000\n",
      "2/2 - 0s - loss: 5.9034e-05 - accuracy: 1.0000\n",
      "Epoch 228/1000000\n",
      "2/2 - 0s - loss: 6.2117e-05 - accuracy: 1.0000\n",
      "Epoch 229/1000000\n",
      "2/2 - 0s - loss: 8.0537e-05 - accuracy: 1.0000\n",
      "Epoch 230/1000000\n",
      "2/2 - 0s - loss: 4.9145e-05 - accuracy: 1.0000\n",
      "Epoch 231/1000000\n",
      "2/2 - 0s - loss: 4.6625e-05 - accuracy: 1.0000\n",
      "Epoch 232/1000000\n",
      "2/2 - 0s - loss: 4.5628e-05 - accuracy: 1.0000\n",
      "Epoch 233/1000000\n",
      "2/2 - 0s - loss: 4.0937e-05 - accuracy: 1.0000\n",
      "Epoch 234/1000000\n",
      "2/2 - 0s - loss: 4.2849e-05 - accuracy: 1.0000\n",
      "Epoch 235/1000000\n",
      "2/2 - 0s - loss: 4.3250e-05 - accuracy: 1.0000\n",
      "Epoch 236/1000000\n",
      "2/2 - 0s - loss: 3.9178e-05 - accuracy: 1.0000\n",
      "Epoch 237/1000000\n",
      "2/2 - 0s - loss: 4.0529e-05 - accuracy: 1.0000\n",
      "Epoch 238/1000000\n",
      "2/2 - 0s - loss: 3.2280e-05 - accuracy: 1.0000\n",
      "Epoch 239/1000000\n",
      "2/2 - 0s - loss: 2.8577e-05 - accuracy: 1.0000\n",
      "Epoch 240/1000000\n",
      "2/2 - 0s - loss: 3.0046e-05 - accuracy: 1.0000\n",
      "Epoch 241/1000000\n",
      "2/2 - 0s - loss: 2.7990e-05 - accuracy: 1.0000\n",
      "Epoch 242/1000000\n",
      "2/2 - 0s - loss: 3.1462e-05 - accuracy: 1.0000\n",
      "Epoch 243/1000000\n",
      "2/2 - 0s - loss: 4.0103e-05 - accuracy: 1.0000\n",
      "Epoch 244/1000000\n",
      "2/2 - 0s - loss: 2.1478e-05 - accuracy: 1.0000\n",
      "Epoch 245/1000000\n",
      "2/2 - 0s - loss: 2.0124e-05 - accuracy: 1.0000\n",
      "Epoch 246/1000000\n",
      "2/2 - 0s - loss: 1.8422e-05 - accuracy: 1.0000\n",
      "Epoch 247/1000000\n",
      "2/2 - 0s - loss: 1.7214e-05 - accuracy: 1.0000\n",
      "Epoch 248/1000000\n",
      "2/2 - 0s - loss: 1.6108e-05 - accuracy: 1.0000\n",
      "Epoch 249/1000000\n",
      "2/2 - 0s - loss: 1.6560e-05 - accuracy: 1.0000\n",
      "Epoch 250/1000000\n",
      "2/2 - 0s - loss: 1.6408e-05 - accuracy: 1.0000\n",
      "Epoch 251/1000000\n",
      "2/2 - 0s - loss: 1.3592e-05 - accuracy: 1.0000\n",
      "Epoch 252/1000000\n",
      "2/2 - 0s - loss: 1.2432e-05 - accuracy: 1.0000\n",
      "Epoch 253/1000000\n",
      "2/2 - 0s - loss: 1.3674e-05 - accuracy: 1.0000\n",
      "Epoch 254/1000000\n",
      "2/2 - 0s - loss: 1.2246e-05 - accuracy: 1.0000\n",
      "Epoch 255/1000000\n",
      "2/2 - 0s - loss: 1.0963e-05 - accuracy: 1.0000\n",
      "Epoch 256/1000000\n",
      "2/2 - 0s - loss: 1.1298e-05 - accuracy: 1.0000\n",
      "Epoch 257/1000000\n",
      "2/2 - 0s - loss: 1.1269e-05 - accuracy: 1.0000\n",
      "Epoch 258/1000000\n",
      "2/2 - 0s - loss: 1.0672e-05 - accuracy: 1.0000\n",
      "Epoch 259/1000000\n",
      "2/2 - 0s - loss: 9.6891e-06 - accuracy: 1.0000\n",
      "Epoch 260/1000000\n",
      "2/2 - 0s - loss: 7.4002e-06 - accuracy: 1.0000\n",
      "Epoch 261/1000000\n",
      "2/2 - 0s - loss: 7.6274e-06 - accuracy: 1.0000\n",
      "Epoch 262/1000000\n",
      "2/2 - 0s - loss: 6.9697e-06 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b83e708460>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = EarlyStopping(monitor='accuracy', \n",
    "                         patience=100,\n",
    "                         restore_best_weights=True)\n",
    "\n",
    "model_with_mul_layers.compile(optimizer=\"rmsprop\", \n",
    "              loss='mse', \n",
    "              metrics=['accuracy'])\n",
    "model_with_mul_layers.fit(TRAINING_SET_2D, \n",
    "          TRAINING_SET_LABELS, \n",
    "          epochs=1000000,\n",
    "          callbacks=[callback], \n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden_layer_1 (Dense)       (None, 26)                936       \n",
      "_________________________________________________________________\n",
      "hidden_layer_2 (Dense)       (None, 26)                702       \n",
      "_________________________________________________________________\n",
      "hidden_layer_3 (Dense)       (None, 26)                702       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 26)                702       \n",
      "=================================================================\n",
      "Total params: 3,042\n",
      "Trainable params: 3,042\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_with_mul_layers.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 995us/step - loss: 0.0063 - accuracy: 0.8846\n"
     ]
    }
   ],
   "source": [
    "model_with_mul_layers_eval = model_with_mul_layers.evaluate(TEST_SET_2D, TEST_SET_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_mul_layers_pred = model_with_mul_layers.predict(TEST_SET_2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show misclassified images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: N True: A\n",
      "Pred: C True: G\n",
      "Pred: J True: W\n"
     ]
    }
   ],
   "source": [
    "misclassfication_mul_layers_model = show_misclassified_img(model_with_mul_layers_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'G', 'W']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassfication_mul_layers_model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8846153846153846"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(26-misclassfication_mul_layers_model[1])/26 # accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8846153616905212"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_mul_layers_eval[1] # accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the predicted message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_pred_mul_layers = model_with_mul_layers.predict(MESSAGE_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UATCHJEOPARDYNLCXTREBEKSFUNTVQUIZGAMZ"
     ]
    }
   ],
   "source": [
    "msg_pred_mult_layer_res = get_msg_pred(msg_pred_mul_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the true message with predicted message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True   Predict\n",
      "W      U      \n",
      "A      N      \n",
      "E      C      \n",
      "E      Z      \n"
     ]
    }
   ],
   "source": [
    "compare_with_true_message(msg_pred_mult_layer_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does the performance improve?\n",
    "Yes, the performance does improve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Repeat experiment (8), adding additional layers until the message is decoded correctly. What results do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 26)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = Sequential()\n",
    "final_model.add(Dense(26, \n",
    "                input_shape=(35,), \n",
    "                kernel_initializer='random_normal',\n",
    "                name=\"hidden_layer_1\"))\n",
    "final_model.add(Dense(26, \n",
    "                input_shape=(35,), \n",
    "                activation='relu', \n",
    "                name=\"hidden_layer_2\"))\n",
    "final_model.add(Dense(26, \n",
    "                input_shape=(35,),\n",
    "                activation='relu',\n",
    "                name=\"hidden_layer_3\"))\n",
    "final_model.add(Dense(26, \n",
    "                input_shape=(35,),\n",
    "                activation='relu',\n",
    "                name=\"hidden_layer_4\"))\n",
    "final_model.add(Dense(26, \n",
    "                input_shape=(35,),\n",
    "                activation='relu',\n",
    "                name=\"hidden_layer_5\"))\n",
    "final_model.add(Dense(26, \n",
    "                input_shape=(35,),\n",
    "                activation='relu',\n",
    "                name=\"hidden_layer_6\"))\n",
    "final_model.add(Dense(26, \n",
    "                input_shape=(35,), \n",
    "                activation=softmax, \n",
    "                name=\"output_layer\"))\n",
    "# final_model.add(Activation('softmax'))\n",
    "final_model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2/2 - 0s - loss: 0.0370 - accuracy: 0.0577\n",
      "Epoch 2/1000\n",
      "2/2 - 0s - loss: 0.0370 - accuracy: 0.0385\n",
      "Epoch 3/1000\n",
      "2/2 - 0s - loss: 0.0369 - accuracy: 0.0769\n",
      "Epoch 4/1000\n",
      "2/2 - 0s - loss: 0.0369 - accuracy: 0.0577\n",
      "Epoch 5/1000\n",
      "2/2 - 0s - loss: 0.0369 - accuracy: 0.0769\n",
      "Epoch 6/1000\n",
      "2/2 - 0s - loss: 0.0369 - accuracy: 0.1154\n",
      "Epoch 7/1000\n",
      "2/2 - 0s - loss: 0.0369 - accuracy: 0.0385\n",
      "Epoch 8/1000\n",
      "2/2 - 0s - loss: 0.0368 - accuracy: 0.0385\n",
      "Epoch 9/1000\n",
      "2/2 - 0s - loss: 0.0368 - accuracy: 0.0769\n",
      "Epoch 10/1000\n",
      "2/2 - 0s - loss: 0.0367 - accuracy: 0.0385\n",
      "Epoch 11/1000\n",
      "2/2 - 0s - loss: 0.0367 - accuracy: 0.0769\n",
      "Epoch 12/1000\n",
      "2/2 - 0s - loss: 0.0366 - accuracy: 0.0577\n",
      "Epoch 13/1000\n",
      "2/2 - 0s - loss: 0.0366 - accuracy: 0.0385\n",
      "Epoch 14/1000\n",
      "2/2 - 0s - loss: 0.0365 - accuracy: 0.0385\n",
      "Epoch 15/1000\n",
      "2/2 - 0s - loss: 0.0364 - accuracy: 0.0769\n",
      "Epoch 16/1000\n",
      "2/2 - 0s - loss: 0.0362 - accuracy: 0.0385\n",
      "Epoch 17/1000\n",
      "2/2 - 0s - loss: 0.0360 - accuracy: 0.0385\n",
      "Epoch 18/1000\n",
      "2/2 - 0s - loss: 0.0358 - accuracy: 0.0385\n",
      "Epoch 19/1000\n",
      "2/2 - 0s - loss: 0.0356 - accuracy: 0.0577\n",
      "Epoch 20/1000\n",
      "2/2 - 0s - loss: 0.0355 - accuracy: 0.1154\n",
      "Epoch 21/1000\n",
      "2/2 - 0s - loss: 0.0353 - accuracy: 0.1154\n",
      "Epoch 22/1000\n",
      "2/2 - 0s - loss: 0.0351 - accuracy: 0.1538\n",
      "Epoch 23/1000\n",
      "2/2 - 0s - loss: 0.0350 - accuracy: 0.1538\n",
      "Epoch 24/1000\n",
      "2/2 - 0s - loss: 0.0348 - accuracy: 0.1923\n",
      "Epoch 25/1000\n",
      "2/2 - 0s - loss: 0.0348 - accuracy: 0.1923\n",
      "Epoch 26/1000\n",
      "2/2 - 0s - loss: 0.0346 - accuracy: 0.1923\n",
      "Epoch 27/1000\n",
      "2/2 - 0s - loss: 0.0344 - accuracy: 0.2115\n",
      "Epoch 28/1000\n",
      "2/2 - 0s - loss: 0.0342 - accuracy: 0.1923\n",
      "Epoch 29/1000\n",
      "2/2 - 0s - loss: 0.0340 - accuracy: 0.2115\n",
      "Epoch 30/1000\n",
      "2/2 - 0s - loss: 0.0338 - accuracy: 0.1923\n",
      "Epoch 31/1000\n",
      "2/2 - 0s - loss: 0.0336 - accuracy: 0.2115\n",
      "Epoch 32/1000\n",
      "2/2 - 0s - loss: 0.0332 - accuracy: 0.2115\n",
      "Epoch 33/1000\n",
      "2/2 - 0s - loss: 0.0330 - accuracy: 0.2115\n",
      "Epoch 34/1000\n",
      "2/2 - 0s - loss: 0.0327 - accuracy: 0.2115\n",
      "Epoch 35/1000\n",
      "2/2 - 0s - loss: 0.0324 - accuracy: 0.2115\n",
      "Epoch 36/1000\n",
      "2/2 - 0s - loss: 0.0323 - accuracy: 0.2500\n",
      "Epoch 37/1000\n",
      "2/2 - 0s - loss: 0.0319 - accuracy: 0.2500\n",
      "Epoch 38/1000\n",
      "2/2 - 0s - loss: 0.0316 - accuracy: 0.2500\n",
      "Epoch 39/1000\n",
      "2/2 - 0s - loss: 0.0313 - accuracy: 0.2500\n",
      "Epoch 40/1000\n",
      "2/2 - 0s - loss: 0.0312 - accuracy: 0.2692\n",
      "Epoch 41/1000\n",
      "2/2 - 0s - loss: 0.0310 - accuracy: 0.2500\n",
      "Epoch 42/1000\n",
      "2/2 - 0s - loss: 0.0307 - accuracy: 0.2885\n",
      "Epoch 43/1000\n",
      "2/2 - 0s - loss: 0.0304 - accuracy: 0.2885\n",
      "Epoch 44/1000\n",
      "2/2 - 0s - loss: 0.0301 - accuracy: 0.3077\n",
      "Epoch 45/1000\n",
      "2/2 - 0s - loss: 0.0299 - accuracy: 0.3462\n",
      "Epoch 46/1000\n",
      "2/2 - 0s - loss: 0.0298 - accuracy: 0.3462\n",
      "Epoch 47/1000\n",
      "2/2 - 0s - loss: 0.0295 - accuracy: 0.3462\n",
      "Epoch 48/1000\n",
      "2/2 - 0s - loss: 0.0292 - accuracy: 0.3462\n",
      "Epoch 49/1000\n",
      "2/2 - 0s - loss: 0.0289 - accuracy: 0.3462\n",
      "Epoch 50/1000\n",
      "2/2 - 0s - loss: 0.0286 - accuracy: 0.3462\n",
      "Epoch 51/1000\n",
      "2/2 - 0s - loss: 0.0283 - accuracy: 0.3462\n",
      "Epoch 52/1000\n",
      "2/2 - 0s - loss: 0.0279 - accuracy: 0.3462\n",
      "Epoch 53/1000\n",
      "2/2 - 0s - loss: 0.0278 - accuracy: 0.3462\n",
      "Epoch 54/1000\n",
      "2/2 - 0s - loss: 0.0276 - accuracy: 0.3462\n",
      "Epoch 55/1000\n",
      "2/2 - 0s - loss: 0.0273 - accuracy: 0.3462\n",
      "Epoch 56/1000\n",
      "2/2 - 0s - loss: 0.0268 - accuracy: 0.3462\n",
      "Epoch 57/1000\n",
      "2/2 - 0s - loss: 0.0266 - accuracy: 0.3654\n",
      "Epoch 58/1000\n",
      "2/2 - 0s - loss: 0.0263 - accuracy: 0.4038\n",
      "Epoch 59/1000\n",
      "2/2 - 0s - loss: 0.0259 - accuracy: 0.3462\n",
      "Epoch 60/1000\n",
      "2/2 - 0s - loss: 0.0256 - accuracy: 0.3462\n",
      "Epoch 61/1000\n",
      "2/2 - 0s - loss: 0.0255 - accuracy: 0.3654\n",
      "Epoch 62/1000\n",
      "2/2 - 0s - loss: 0.0249 - accuracy: 0.3654\n",
      "Epoch 63/1000\n",
      "2/2 - 0s - loss: 0.0247 - accuracy: 0.4231\n",
      "Epoch 64/1000\n",
      "2/2 - 0s - loss: 0.0243 - accuracy: 0.4231\n",
      "Epoch 65/1000\n",
      "2/2 - 0s - loss: 0.0241 - accuracy: 0.4423\n",
      "Epoch 66/1000\n",
      "2/2 - 0s - loss: 0.0241 - accuracy: 0.5385\n",
      "Epoch 67/1000\n",
      "2/2 - 0s - loss: 0.0233 - accuracy: 0.5385\n",
      "Epoch 68/1000\n",
      "2/2 - 0s - loss: 0.0230 - accuracy: 0.5385\n",
      "Epoch 69/1000\n",
      "2/2 - 0s - loss: 0.0228 - accuracy: 0.5192\n",
      "Epoch 70/1000\n",
      "2/2 - 0s - loss: 0.0223 - accuracy: 0.5192\n",
      "Epoch 71/1000\n",
      "2/2 - 0s - loss: 0.0221 - accuracy: 0.5577\n",
      "Epoch 72/1000\n",
      "2/2 - 0s - loss: 0.0218 - accuracy: 0.5769\n",
      "Epoch 73/1000\n",
      "2/2 - 0s - loss: 0.0211 - accuracy: 0.5769\n",
      "Epoch 74/1000\n",
      "2/2 - 0s - loss: 0.0209 - accuracy: 0.6154\n",
      "Epoch 75/1000\n",
      "2/2 - 0s - loss: 0.0205 - accuracy: 0.5962\n",
      "Epoch 76/1000\n",
      "2/2 - 0s - loss: 0.0203 - accuracy: 0.6346\n",
      "Epoch 77/1000\n",
      "2/2 - 0s - loss: 0.0201 - accuracy: 0.6346\n",
      "Epoch 78/1000\n",
      "2/2 - 0s - loss: 0.0200 - accuracy: 0.6346\n",
      "Epoch 79/1000\n",
      "2/2 - 0s - loss: 0.0197 - accuracy: 0.6346\n",
      "Epoch 80/1000\n",
      "2/2 - 0s - loss: 0.0189 - accuracy: 0.6346\n",
      "Epoch 81/1000\n",
      "2/2 - 0s - loss: 0.0186 - accuracy: 0.6346\n",
      "Epoch 82/1000\n",
      "2/2 - 0s - loss: 0.0181 - accuracy: 0.6731\n",
      "Epoch 83/1000\n",
      "2/2 - 0s - loss: 0.0182 - accuracy: 0.6538\n",
      "Epoch 84/1000\n",
      "2/2 - 0s - loss: 0.0175 - accuracy: 0.6538\n",
      "Epoch 85/1000\n",
      "2/2 - 0s - loss: 0.0174 - accuracy: 0.6346\n",
      "Epoch 86/1000\n",
      "2/2 - 0s - loss: 0.0169 - accuracy: 0.6538\n",
      "Epoch 87/1000\n",
      "2/2 - 0s - loss: 0.0166 - accuracy: 0.6923\n",
      "Epoch 88/1000\n",
      "2/2 - 0s - loss: 0.0165 - accuracy: 0.7115\n",
      "Epoch 89/1000\n",
      "2/2 - 0s - loss: 0.0160 - accuracy: 0.6538\n",
      "Epoch 90/1000\n",
      "2/2 - 0s - loss: 0.0158 - accuracy: 0.7115\n",
      "Epoch 91/1000\n",
      "2/2 - 0s - loss: 0.0158 - accuracy: 0.6923\n",
      "Epoch 92/1000\n",
      "2/2 - 0s - loss: 0.0154 - accuracy: 0.7115\n",
      "Epoch 93/1000\n",
      "2/2 - 0s - loss: 0.0148 - accuracy: 0.7115\n",
      "Epoch 94/1000\n",
      "2/2 - 0s - loss: 0.0146 - accuracy: 0.6923\n",
      "Epoch 95/1000\n",
      "2/2 - 0s - loss: 0.0143 - accuracy: 0.7692\n",
      "Epoch 96/1000\n",
      "2/2 - 0s - loss: 0.0146 - accuracy: 0.7500\n",
      "Epoch 97/1000\n",
      "2/2 - 0s - loss: 0.0137 - accuracy: 0.7500\n",
      "Epoch 98/1000\n",
      "2/2 - 0s - loss: 0.0134 - accuracy: 0.7692\n",
      "Epoch 99/1000\n",
      "2/2 - 0s - loss: 0.0138 - accuracy: 0.7308\n",
      "Epoch 100/1000\n",
      "2/2 - 0s - loss: 0.0137 - accuracy: 0.7885\n",
      "Epoch 101/1000\n",
      "2/2 - 0s - loss: 0.0128 - accuracy: 0.7885\n",
      "Epoch 102/1000\n",
      "2/2 - 0s - loss: 0.0127 - accuracy: 0.7692\n",
      "Epoch 103/1000\n",
      "2/2 - 0s - loss: 0.0125 - accuracy: 0.7692\n",
      "Epoch 104/1000\n",
      "2/2 - 0s - loss: 0.0121 - accuracy: 0.8077\n",
      "Epoch 105/1000\n",
      "2/2 - 0s - loss: 0.0115 - accuracy: 0.8269\n",
      "Epoch 106/1000\n",
      "2/2 - 0s - loss: 0.0117 - accuracy: 0.8077\n",
      "Epoch 107/1000\n",
      "2/2 - 0s - loss: 0.0120 - accuracy: 0.7885\n",
      "Epoch 108/1000\n",
      "2/2 - 0s - loss: 0.0113 - accuracy: 0.8269\n",
      "Epoch 109/1000\n",
      "2/2 - 0s - loss: 0.0111 - accuracy: 0.8077\n",
      "Epoch 110/1000\n",
      "2/2 - 0s - loss: 0.0107 - accuracy: 0.7885\n",
      "Epoch 111/1000\n",
      "2/2 - 0s - loss: 0.0101 - accuracy: 0.8462\n",
      "Epoch 112/1000\n",
      "2/2 - 0s - loss: 0.0104 - accuracy: 0.8462\n",
      "Epoch 113/1000\n",
      "2/2 - 0s - loss: 0.0098 - accuracy: 0.8462\n",
      "Epoch 114/1000\n",
      "2/2 - 0s - loss: 0.0096 - accuracy: 0.8462\n",
      "Epoch 115/1000\n",
      "2/2 - 0s - loss: 0.0099 - accuracy: 0.8077\n",
      "Epoch 116/1000\n",
      "2/2 - 0s - loss: 0.0094 - accuracy: 0.8654\n",
      "Epoch 117/1000\n",
      "2/2 - 0s - loss: 0.0088 - accuracy: 0.8654\n",
      "Epoch 118/1000\n",
      "2/2 - 0s - loss: 0.0092 - accuracy: 0.8654\n",
      "Epoch 119/1000\n",
      "2/2 - 0s - loss: 0.0085 - accuracy: 0.9038\n",
      "Epoch 120/1000\n",
      "2/2 - 0s - loss: 0.0095 - accuracy: 0.9038\n",
      "Epoch 121/1000\n",
      "2/2 - 0s - loss: 0.0081 - accuracy: 0.9038\n",
      "Epoch 122/1000\n",
      "2/2 - 0s - loss: 0.0076 - accuracy: 0.9038\n",
      "Epoch 123/1000\n",
      "2/2 - 0s - loss: 0.0078 - accuracy: 0.9038\n",
      "Epoch 124/1000\n",
      "2/2 - 0s - loss: 0.0075 - accuracy: 0.9038\n",
      "Epoch 125/1000\n",
      "2/2 - 0s - loss: 0.0071 - accuracy: 0.9038\n",
      "Epoch 126/1000\n",
      "2/2 - 0s - loss: 0.0079 - accuracy: 0.9038\n",
      "Epoch 127/1000\n",
      "2/2 - 0s - loss: 0.0073 - accuracy: 0.9038\n",
      "Epoch 128/1000\n",
      "2/2 - 0s - loss: 0.0072 - accuracy: 0.9038\n",
      "Epoch 129/1000\n",
      "2/2 - 0s - loss: 0.0065 - accuracy: 0.9038\n",
      "Epoch 130/1000\n",
      "2/2 - 0s - loss: 0.0064 - accuracy: 0.9038\n",
      "Epoch 131/1000\n",
      "2/2 - 0s - loss: 0.0062 - accuracy: 0.9038\n",
      "Epoch 132/1000\n",
      "2/2 - 0s - loss: 0.0059 - accuracy: 0.9038\n",
      "Epoch 133/1000\n",
      "2/2 - 0s - loss: 0.0059 - accuracy: 0.9038\n",
      "Epoch 134/1000\n",
      "2/2 - 0s - loss: 0.0057 - accuracy: 0.9038\n",
      "Epoch 135/1000\n",
      "2/2 - 0s - loss: 0.0059 - accuracy: 0.9423\n",
      "Epoch 136/1000\n",
      "2/2 - 0s - loss: 0.0058 - accuracy: 0.9038\n",
      "Epoch 137/1000\n",
      "2/2 - 0s - loss: 0.0054 - accuracy: 0.9423\n",
      "Epoch 138/1000\n",
      "2/2 - 0s - loss: 0.0052 - accuracy: 0.9423\n",
      "Epoch 139/1000\n",
      "2/2 - 0s - loss: 0.0050 - accuracy: 0.9423\n",
      "Epoch 140/1000\n",
      "2/2 - 0s - loss: 0.0048 - accuracy: 0.9423\n",
      "Epoch 141/1000\n",
      "2/2 - 0s - loss: 0.0060 - accuracy: 0.9423\n",
      "Epoch 142/1000\n",
      "2/2 - 0s - loss: 0.0061 - accuracy: 0.9423\n",
      "Epoch 143/1000\n",
      "2/2 - 0s - loss: 0.0047 - accuracy: 0.9423\n",
      "Epoch 144/1000\n",
      "2/2 - 0s - loss: 0.0043 - accuracy: 0.9423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/1000\n",
      "2/2 - 0s - loss: 0.0045 - accuracy: 0.9615\n",
      "Epoch 146/1000\n",
      "2/2 - 0s - loss: 0.0045 - accuracy: 0.9423\n",
      "Epoch 147/1000\n",
      "2/2 - 0s - loss: 0.0041 - accuracy: 0.9615\n",
      "Epoch 148/1000\n",
      "2/2 - 0s - loss: 0.0038 - accuracy: 0.9615\n",
      "Epoch 149/1000\n",
      "2/2 - 0s - loss: 0.0036 - accuracy: 0.9615\n",
      "Epoch 150/1000\n",
      "2/2 - 0s - loss: 0.0036 - accuracy: 0.9615\n",
      "Epoch 151/1000\n",
      "2/2 - 0s - loss: 0.0036 - accuracy: 0.9615\n",
      "Epoch 152/1000\n",
      "2/2 - 0s - loss: 0.0040 - accuracy: 0.9615\n",
      "Epoch 153/1000\n",
      "2/2 - 0s - loss: 0.0041 - accuracy: 0.9423\n",
      "Epoch 154/1000\n",
      "2/2 - 0s - loss: 0.0039 - accuracy: 0.9615\n",
      "Epoch 155/1000\n",
      "2/2 - 0s - loss: 0.0029 - accuracy: 0.9615\n",
      "Epoch 156/1000\n",
      "2/2 - 0s - loss: 0.0028 - accuracy: 0.9615\n",
      "Epoch 157/1000\n",
      "2/2 - 0s - loss: 0.0025 - accuracy: 0.9808\n",
      "Epoch 158/1000\n",
      "2/2 - 0s - loss: 0.0027 - accuracy: 0.9808\n",
      "Epoch 159/1000\n",
      "2/2 - 0s - loss: 0.0025 - accuracy: 0.9808\n",
      "Epoch 160/1000\n",
      "2/2 - 0s - loss: 0.0023 - accuracy: 0.9808\n",
      "Epoch 161/1000\n",
      "2/2 - 0s - loss: 0.0023 - accuracy: 0.9808\n",
      "Epoch 162/1000\n",
      "2/2 - 0s - loss: 0.0021 - accuracy: 0.9808\n",
      "Epoch 163/1000\n",
      "2/2 - 0s - loss: 0.0023 - accuracy: 0.9808\n",
      "Epoch 164/1000\n",
      "2/2 - 0s - loss: 0.0020 - accuracy: 0.9808\n",
      "Epoch 165/1000\n",
      "2/2 - 0s - loss: 0.0019 - accuracy: 0.9808\n",
      "Epoch 166/1000\n",
      "2/2 - 0s - loss: 0.0016 - accuracy: 0.9808\n",
      "Epoch 167/1000\n",
      "2/2 - 0s - loss: 0.0016 - accuracy: 0.9808\n",
      "Epoch 168/1000\n",
      "2/2 - 0s - loss: 0.0022 - accuracy: 0.9808\n",
      "Epoch 169/1000\n",
      "2/2 - 0s - loss: 0.0028 - accuracy: 0.9615\n",
      "Epoch 170/1000\n",
      "2/2 - 0s - loss: 0.0020 - accuracy: 0.9808\n",
      "Epoch 171/1000\n",
      "2/2 - 0s - loss: 0.0015 - accuracy: 0.9808\n",
      "Epoch 172/1000\n",
      "2/2 - 0s - loss: 0.0014 - accuracy: 0.9808\n",
      "Epoch 173/1000\n",
      "2/2 - 0s - loss: 0.0014 - accuracy: 0.9808\n",
      "Epoch 174/1000\n",
      "2/2 - 0s - loss: 0.0013 - accuracy: 0.9808\n",
      "Epoch 175/1000\n",
      "2/2 - 0s - loss: 0.0013 - accuracy: 0.9808\n",
      "Epoch 176/1000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 0.9808\n",
      "Epoch 177/1000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 0.9808\n",
      "Epoch 178/1000\n",
      "2/2 - 0s - loss: 0.0013 - accuracy: 0.9808\n",
      "Epoch 179/1000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 0.9808\n",
      "Epoch 180/1000\n",
      "2/2 - 0s - loss: 0.0013 - accuracy: 0.9808\n",
      "Epoch 181/1000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 0.9808\n",
      "Epoch 182/1000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 0.9808\n",
      "Epoch 183/1000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 0.9808\n",
      "Epoch 184/1000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 0.9808\n",
      "Epoch 185/1000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 0.9808\n",
      "Epoch 186/1000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 0.9808\n",
      "Epoch 187/1000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 0.9808\n",
      "Epoch 188/1000\n",
      "2/2 - 0s - loss: 0.0036 - accuracy: 0.9423\n",
      "Epoch 189/1000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 0.9808\n",
      "Epoch 190/1000\n",
      "2/2 - 0s - loss: 0.0010 - accuracy: 0.9808\n",
      "Epoch 191/1000\n",
      "2/2 - 0s - loss: 0.0010 - accuracy: 0.9808\n",
      "Epoch 192/1000\n",
      "2/2 - 0s - loss: 0.0010 - accuracy: 0.9808\n",
      "Epoch 193/1000\n",
      "2/2 - 0s - loss: 9.8970e-04 - accuracy: 0.9808\n",
      "Epoch 194/1000\n",
      "2/2 - 0s - loss: 9.8093e-04 - accuracy: 0.9808\n",
      "Epoch 195/1000\n",
      "2/2 - 0s - loss: 9.7464e-04 - accuracy: 0.9808\n",
      "Epoch 196/1000\n",
      "2/2 - 0s - loss: 9.6364e-04 - accuracy: 0.9808\n",
      "Epoch 197/1000\n",
      "2/2 - 0s - loss: 9.6678e-04 - accuracy: 0.9808\n",
      "Epoch 198/1000\n",
      "2/2 - 0s - loss: 9.8707e-04 - accuracy: 0.9808\n",
      "Epoch 199/1000\n",
      "2/2 - 0s - loss: 9.5522e-04 - accuracy: 0.9808\n",
      "Epoch 200/1000\n",
      "2/2 - 0s - loss: 9.4544e-04 - accuracy: 0.9808\n",
      "Epoch 201/1000\n",
      "2/2 - 0s - loss: 9.5420e-04 - accuracy: 0.9808\n",
      "Epoch 202/1000\n",
      "2/2 - 0s - loss: 9.7044e-04 - accuracy: 0.9808\n",
      "Epoch 203/1000\n",
      "2/2 - 0s - loss: 9.8239e-04 - accuracy: 0.9808\n",
      "Epoch 204/1000\n",
      "2/2 - 0s - loss: 9.2858e-04 - accuracy: 0.9808\n",
      "Epoch 205/1000\n",
      "2/2 - 0s - loss: 9.6510e-04 - accuracy: 0.9808\n",
      "Epoch 206/1000\n",
      "2/2 - 0s - loss: 9.3896e-04 - accuracy: 0.9808\n",
      "Epoch 207/1000\n",
      "2/2 - 0s - loss: 9.1990e-04 - accuracy: 0.9808\n",
      "Epoch 208/1000\n",
      "2/2 - 0s - loss: 9.5686e-04 - accuracy: 0.9808\n",
      "Epoch 209/1000\n",
      "2/2 - 0s - loss: 9.1148e-04 - accuracy: 0.9808\n",
      "Epoch 210/1000\n",
      "2/2 - 0s - loss: 9.3987e-04 - accuracy: 0.9808\n",
      "Epoch 211/1000\n",
      "2/2 - 0s - loss: 9.9471e-04 - accuracy: 0.9808\n",
      "Epoch 212/1000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 0.9808\n",
      "Epoch 213/1000\n",
      "2/2 - 0s - loss: 0.0023 - accuracy: 0.9615\n",
      "Epoch 214/1000\n",
      "2/2 - 0s - loss: 9.5711e-04 - accuracy: 0.9808\n",
      "Epoch 215/1000\n",
      "2/2 - 0s - loss: 9.1437e-04 - accuracy: 0.9808\n",
      "Epoch 216/1000\n",
      "2/2 - 0s - loss: 8.9261e-04 - accuracy: 0.9808\n",
      "Epoch 217/1000\n",
      "2/2 - 0s - loss: 8.9443e-04 - accuracy: 0.9808\n",
      "Epoch 218/1000\n",
      "2/2 - 0s - loss: 8.9146e-04 - accuracy: 0.9808\n",
      "Epoch 219/1000\n",
      "2/2 - 0s - loss: 9.1433e-04 - accuracy: 0.9808\n",
      "Epoch 220/1000\n",
      "2/2 - 0s - loss: 9.1954e-04 - accuracy: 0.9808\n",
      "Epoch 221/1000\n",
      "2/2 - 0s - loss: 9.4797e-04 - accuracy: 0.9808\n",
      "Epoch 222/1000\n",
      "2/2 - 0s - loss: 8.8464e-04 - accuracy: 0.9808\n",
      "Epoch 223/1000\n",
      "2/2 - 0s - loss: 9.5063e-04 - accuracy: 0.9808\n",
      "Epoch 224/1000\n",
      "2/2 - 0s - loss: 9.1854e-04 - accuracy: 0.9808\n",
      "Epoch 225/1000\n",
      "2/2 - 0s - loss: 8.7373e-04 - accuracy: 0.9808\n",
      "Epoch 226/1000\n",
      "2/2 - 0s - loss: 8.7377e-04 - accuracy: 0.9808\n",
      "Epoch 227/1000\n",
      "2/2 - 0s - loss: 8.9099e-04 - accuracy: 0.9808\n",
      "Epoch 228/1000\n",
      "2/2 - 0s - loss: 9.0675e-04 - accuracy: 0.9808\n",
      "Epoch 229/1000\n",
      "2/2 - 0s - loss: 9.1198e-04 - accuracy: 0.9808\n",
      "Epoch 230/1000\n",
      "2/2 - 0s - loss: 0.0038 - accuracy: 0.9231\n",
      "Epoch 231/1000\n",
      "2/2 - 0s - loss: 0.0016 - accuracy: 0.9615\n",
      "Epoch 232/1000\n",
      "2/2 - 0s - loss: 9.6060e-04 - accuracy: 0.9808\n",
      "Epoch 233/1000\n",
      "2/2 - 0s - loss: 9.2524e-04 - accuracy: 0.9808\n",
      "Epoch 234/1000\n",
      "2/2 - 0s - loss: 8.9344e-04 - accuracy: 0.9808\n",
      "Epoch 235/1000\n",
      "2/2 - 0s - loss: 8.8135e-04 - accuracy: 0.9808\n",
      "Epoch 236/1000\n",
      "2/2 - 0s - loss: 8.7594e-04 - accuracy: 0.9808\n",
      "Epoch 237/1000\n",
      "2/2 - 0s - loss: 8.7149e-04 - accuracy: 0.9808\n",
      "Epoch 238/1000\n",
      "2/2 - 0s - loss: 8.6931e-04 - accuracy: 0.9808\n",
      "Epoch 239/1000\n",
      "2/2 - 0s - loss: 8.6737e-04 - accuracy: 0.9808\n",
      "Epoch 240/1000\n",
      "2/2 - 0s - loss: 8.6398e-04 - accuracy: 0.9808\n",
      "Epoch 241/1000\n",
      "2/2 - 0s - loss: 8.6141e-04 - accuracy: 0.9808\n",
      "Epoch 242/1000\n",
      "2/2 - 0s - loss: 8.6085e-04 - accuracy: 0.9808\n",
      "Epoch 243/1000\n",
      "2/2 - 0s - loss: 8.5849e-04 - accuracy: 0.9808\n",
      "Epoch 244/1000\n",
      "2/2 - 0s - loss: 8.5886e-04 - accuracy: 0.9808\n",
      "Epoch 245/1000\n",
      "2/2 - 0s - loss: 8.6332e-04 - accuracy: 0.9808\n",
      "Epoch 246/1000\n",
      "2/2 - 0s - loss: 8.5660e-04 - accuracy: 0.9808\n",
      "Epoch 247/1000\n",
      "2/2 - 0s - loss: 8.6724e-04 - accuracy: 0.9808\n",
      "Epoch 248/1000\n",
      "2/2 - 0s - loss: 9.3954e-04 - accuracy: 0.9808\n",
      "Epoch 249/1000\n",
      "2/2 - 0s - loss: 8.9919e-04 - accuracy: 0.9808\n",
      "Epoch 250/1000\n",
      "2/2 - 0s - loss: 9.5847e-04 - accuracy: 0.9808\n",
      "Epoch 251/1000\n",
      "2/2 - 0s - loss: 8.9829e-04 - accuracy: 0.9808\n",
      "Epoch 252/1000\n",
      "2/2 - 0s - loss: 8.8638e-04 - accuracy: 0.9808\n",
      "Epoch 253/1000\n",
      "2/2 - 0s - loss: 8.6200e-04 - accuracy: 0.9808\n",
      "Epoch 254/1000\n",
      "2/2 - 0s - loss: 8.6286e-04 - accuracy: 0.9808\n",
      "Epoch 255/1000\n",
      "2/2 - 0s - loss: 8.8613e-04 - accuracy: 0.9808\n",
      "Epoch 256/1000\n",
      "2/2 - 0s - loss: 9.0513e-04 - accuracy: 0.9808\n",
      "Epoch 257/1000\n",
      "2/2 - 0s - loss: 0.0010 - accuracy: 0.9808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b83fc41a90>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = EarlyStopping(monitor='accuracy', \n",
    "                         patience=100,\n",
    "                         restore_best_weights=True)\n",
    "\n",
    "final_model.compile(optimizer=\"rmsprop\", \n",
    "              loss='mse', \n",
    "              metrics=['accuracy'])\n",
    "final_model.fit(TRAINING_SET_2D, \n",
    "          TRAINING_SET_LABELS, \n",
    "          epochs=1000,\n",
    "          callbacks=[callback], \n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden_layer_1 (Dense)       (None, 26)                936       \n",
      "_________________________________________________________________\n",
      "hidden_layer_2 (Dense)       (None, 26)                702       \n",
      "_________________________________________________________________\n",
      "hidden_layer_3 (Dense)       (None, 26)                702       \n",
      "_________________________________________________________________\n",
      "hidden_layer_4 (Dense)       (None, 26)                702       \n",
      "_________________________________________________________________\n",
      "hidden_layer_5 (Dense)       (None, 26)                702       \n",
      "_________________________________________________________________\n",
      "hidden_layer_6 (Dense)       (None, 26)                702       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 26)                702       \n",
      "=================================================================\n",
      "Total params: 5,148\n",
      "Trainable params: 5,148\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0090 - accuracy: 0.8462\n"
     ]
    }
   ],
   "source": [
    "final_model_eval = final_model.evaluate(TEST_SET_2D, TEST_SET_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_pred = final_model.predict(TEST_SET_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: M True: A\n",
      "Pred: Y True: D\n",
      "Pred: S True: G\n",
      "Pred: K True: W\n"
     ]
    }
   ],
   "source": [
    "misclassfication_final_model = show_misclassified_img(final_model_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'D', 'G', 'W']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassfication_final_model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8461538553237915"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model_eval[1] # accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the predicted message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_final_model = final_model.predict(MESSAGE_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YBLCHJEORRRKRMLEXTRESEKSFUNTVQUIZGAME"
     ]
    }
   ],
   "source": [
    "msg_final_model_res = get_msg_pred(msg_final_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the true message with predicted message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True   Predict\n",
      "W      Y      \n",
      "A      B      \n",
      "T      L      \n",
      "P      R      \n",
      "A      R      \n",
      "D      K      \n",
      "Y      R      \n",
      "A      M      \n",
      "B      S      \n"
     ]
    }
   ],
   "source": [
    "compare_with_true_message(msg_final_model_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does the performance improve?\n",
    "No, the performance doesn't improve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What results do you observe?\n",
    "When we add more additional layers to the network, the performance gets worse than the previous two models. The network seems to perform worse than the second model, which contains 2 additional dense layers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
