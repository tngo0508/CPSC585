{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Project5_585_v2_imp6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RMG4eiI3p_6"
      },
      "source": [
        "# THOMAS NGO\n",
        "# TEVIN VU\n",
        "# PROJECT 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sk-3QTgujV19",
        "outputId": "6298cd58-07a7-4a5e-e459-456c72b0a269"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "def get_available_devices():\n",
        "    local_device_protos = device_lib.list_local_devices()\n",
        "    return [x.name for x in local_device_protos]\n",
        "\n",
        "print(get_available_devices())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/device:CPU:0', '/device:GPU:0']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOtzbA2MZI5y"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras import models\n",
        "from keras.activations import relu, sigmoid, tanh, softmax\n",
        "from keras.layers import Dense, LeakyReLU, BatchNormalization, Dropout, Activation, ReLU\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.regularizers import l1, l2, l1_l2\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from sklearn.preprocessing import minmax_scale, StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GekuWHAF3wVo"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcCRgfycFKOS"
      },
      "source": [
        "### 1. Use plt.imshow() to verify that the image data has been loaded correctly and that the corresponding labels are correct."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAeRD4JnEEFm"
      },
      "source": [
        "datasets = np.load('emnist_letters.npz')\n",
        "train_images, train_labels  = datasets['train_images'], datasets['train_labels']\n",
        "test_images, test_labels = datasets['test_images'], datasets['test_labels']\n",
        "validate_images, validate_labels = datasets['validate_images'], datasets['validate_labels']\n",
        "dataset_shape = datasets['train_images'].shape"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "49VUcW70kKO3",
        "outputId": "bf549bd5-0661-4e27-d0a9-1eb52d74325e"
      },
      "source": [
        "plt.imshow(train_images[5435].reshape(28,28))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8aa7c15710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzKnXulhwljj",
        "outputId": "b34fe7a8-df7e-43d6-9ab7-b8f0b3356a48"
      },
      "source": [
        "print(chr(np.argmax(train_labels[5435]) - 1 + ord('A')))\n",
        "# print(chr(np.argmax(datasets['train_labels'][0]) - 1 + ord('A')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "JIr4CwfulLqR",
        "outputId": "2faabc75-1b45-49bb-8464-2e47ab381dd5"
      },
      "source": [
        "plt.imshow(train_images[1].reshape(28,28))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8aa76facd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYbvYUJ7Fyc-",
        "outputId": "dffd12cc-e1fb-4204-f932-fd8280ca22b5"
      },
      "source": [
        "print(train_labels.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(104000, 27)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZQGJ2tmllb4",
        "outputId": "8a10020a-1849-4987-a91e-18ed41e92672"
      },
      "source": [
        "print(chr(np.argmax(train_labels[1]) - 1 + ord('A')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "G\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "osJvTcMx5M_-",
        "outputId": "daf38f57-65b2-4355-f021-ebd7ce28bb7e"
      },
      "source": [
        "plt.imshow(validate_images[1].reshape(28,28))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8aa7672dd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqm5g2eM5SEE",
        "outputId": "dda4547c-eacb-4021-e0c4-52e80aac4fc3"
      },
      "source": [
        "print(chr(np.argmax(validate_labels[1]) - 1 + ord('A')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "L\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqqgwuZw7WCP",
        "outputId": "5b052ab4-ed73-43d4-8634-87d282c11d6b"
      },
      "source": [
        "print(validate_labels.shape)\n",
        "print(validate_images.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20800, 27)\n",
            "(20800, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDGcWkkt1FPZ"
      },
      "source": [
        "### 2. Begin by applying the network architecture from Chollet’s MNIST notebook to the EMNIST Letters data. What accuracy do you achieve? How does this compare with the accuracy for MNIST?. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox7eKoGh1Hzh",
        "outputId": "448d8dc9-208d-4ec5-c3da-dcb1377a16f2"
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(104000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cg7_CAATRH_N",
        "outputId": "fdb70336-aba6-44f7-84da-28380bcfe70b"
      },
      "source": [
        "test_images.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20800, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIKrb1J41SjU",
        "outputId": "f2a51006-2470-4491-bccd-f5f356f3764e"
      },
      "source": [
        "len(train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "104000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAdE6gWM1ZLL",
        "outputId": "23c5f9f7-50e5-4592-edd8-233fe3fd64db"
      },
      "source": [
        "test_labels.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20800, 27)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G613PF531p_Z",
        "outputId": "62b5ed69-7335-4db1-897b-42d7c02cdc49"
      },
      "source": [
        "len(test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20800"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTk8EI6M1t4v",
        "outputId": "64902f7c-ea8f-4451-f942-5ce33a1357dd"
      },
      "source": [
        "test_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwW9TjubakTz"
      },
      "source": [
        "network = models.Sequential()\n",
        "network.add(Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "network.add(Dense(27, activation='softmax'))"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBtOA1ZxbA6F",
        "outputId": "5cfca720-04be-4fec-f19b-beba11dce598"
      },
      "source": [
        "network.compile(optimizer='rmsprop',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "# model.fit(train_images, train_labels, epochs=5, batch_size=128, validation_split=0.1)\n",
        "network.fit(train_images, train_labels, epochs=5, batch_size=128, validation_data=(validate_images,validate_labels))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "813/813 [==============================] - 3s 3ms/step - loss: 1.0710 - accuracy: 0.6928 - val_loss: 0.4862 - val_accuracy: 0.8533\n",
            "Epoch 2/5\n",
            "813/813 [==============================] - 3s 3ms/step - loss: 0.3961 - accuracy: 0.8766 - val_loss: 0.3677 - val_accuracy: 0.8866\n",
            "Epoch 3/5\n",
            "813/813 [==============================] - 3s 3ms/step - loss: 0.3083 - accuracy: 0.9002 - val_loss: 0.3382 - val_accuracy: 0.8958\n",
            "Epoch 4/5\n",
            "813/813 [==============================] - 3s 3ms/step - loss: 0.2604 - accuracy: 0.9160 - val_loss: 0.3327 - val_accuracy: 0.8996\n",
            "Epoch 5/5\n",
            "813/813 [==============================] - 3s 3ms/step - loss: 0.2270 - accuracy: 0.9245 - val_loss: 0.3368 - val_accuracy: 0.8970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdd6125ac10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdjZO9zxb1qV",
        "outputId": "41f1c0f1-fca6-4110-802e-fca61821a086"
      },
      "source": [
        "test_lost, test_acc = network.evaluate(test_images, test_labels) #run this"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "650/650 [==============================] - 1s 2ms/step - loss: 0.3433 - accuracy: 0.8962\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOO1VZYBb-kB",
        "outputId": "2c29f88b-278f-46fd-d374-734b8ffda2e6"
      },
      "source": [
        "print('Test Accuracy: ', test_acc) #run this\n",
        "orginal_model_acc = test_acc"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy:  0.8962019085884094\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBTgozH9aZ8H"
      },
      "source": [
        "### 3. Keeping the same number of layers in the network (i.e. an MLP with a single hidden layer), modify the architecture to improve the accuracy. You will need to decide on an appropriate number of neurons in the hidden layer. Keep in mind that:\n",
        "- There are 27 classes rather than 10, so you will need a larger hidden layer than the MNIST network.\n",
        "- In addition to having more classes, EMNIST Letters mixes upper- and lowercase letters within each class, so even with enough neurons in the hidden layer, your accuracy is likely to be lower.  See the details in the EMNIST paper for the kind of performance you might reasonably expect.\n",
        "- The Keras fit() method can take a validation_data parameter in order to evaluate metrics on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAKl1iRl15jq"
      },
      "source": [
        "#run this\n",
        "model = models.Sequential()\n",
        "model.add(Dense(10000, activation='relu', input_shape=(28*28,)))\n",
        "model.add(Dense(27, activation='softmax'))"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1R3odEj5vgo",
        "outputId": "0b01ad2f-d3ec-4cc7-ba4b-a9e1d8ac888d"
      },
      "source": [
        "#run this\n",
        "model.compile(optimizer='rmsprop',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "# model.fit(train_images, train_labels, epochs=5, batch_size=128, validation_split=0.1)\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=128, validation_data=(validate_images,validate_labels))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "813/813 [==============================] - 6s 7ms/step - loss: 0.9680 - accuracy: 0.7282 - val_loss: 0.4303 - val_accuracy: 0.8732\n",
            "Epoch 2/5\n",
            "813/813 [==============================] - 5s 6ms/step - loss: 0.3168 - accuracy: 0.8991 - val_loss: 0.3652 - val_accuracy: 0.8950\n",
            "Epoch 3/5\n",
            "813/813 [==============================] - 5s 6ms/step - loss: 0.2497 - accuracy: 0.9201 - val_loss: 0.4033 - val_accuracy: 0.8955\n",
            "Epoch 4/5\n",
            "813/813 [==============================] - 5s 7ms/step - loss: 0.2119 - accuracy: 0.9324 - val_loss: 0.3775 - val_accuracy: 0.9024\n",
            "Epoch 5/5\n",
            "813/813 [==============================] - 5s 6ms/step - loss: 0.1903 - accuracy: 0.9383 - val_loss: 0.4274 - val_accuracy: 0.9017\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdd5db30850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itKGkPel6_vH",
        "outputId": "7f93c981-2a96-4193-a87e-18a7e394e24a"
      },
      "source": [
        "test_lost, test_acc = model.evaluate(test_images, test_labels) #run this"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "650/650 [==============================] - 1s 2ms/step - loss: 0.4350 - accuracy: 0.9012\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRG6LOF-_0TK"
      },
      "source": [
        "What accuracy do you achieve?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xc8U4e_e_qFp",
        "outputId": "7a531bd3-dd6b-40cc-dc09-78b0036f7c71"
      },
      "source": [
        "print('Test Accuracy: ', test_acc) #run this\n",
        "modified_org_model_acc = test_acc"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy:  0.9012019038200378\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b-KErYr_7gU"
      },
      "source": [
        "How does this compare with the accuracy for MNIST? \n",
        "- This accuracy is greater than MNIST a little bit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ADwxPMkP5Sc"
      },
      "source": [
        "### 4. Once you have settled on the size of the hidden layer, use the techniques you learned in Chapters 3 and 4 of the textbook to obtain the highest accuracy you can on the validation set. These might include:\n",
        "\n",
        "  - Preprocessing\n",
        "  - Weight initialization\n",
        "  - Choice of activation function\n",
        "  - Optimizer\n",
        "  - Batch Normalization\n",
        "  - Regularization\n",
        "  - Data augmentation\n",
        "  - Dropout\n",
        "  - Early Stopping\n",
        "\n",
        "You may find the slides for Chapter 3 helpful, particularly the presentation “Neural Network Training [Initialization, Preprocessing, Mini-Batching, Tuning, and Other Black Art].”"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCoFUvN9_yJc"
      },
      "source": [
        "# Preprocessing data input(run this)\n",
        "\n",
        "# using sklearn min-max scaler\n",
        "# train_images = minmax_scale(train_images)\n",
        "# test_images = minmax_scale(test_images)\n",
        "\n",
        "# using sklearn standard scaler\n",
        "X_scaler = StandardScaler().fit(train_images)\n",
        "train_images = X_scaler.transform(train_images)\n",
        "Y_scaler = StandardScaler().fit(test_images)\n",
        "test_images = Y_scaler.transform(test_images)\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQdLn9p30rfd"
      },
      "source": [
        "# define model with batch normalization\n",
        "def define_model(func_name='relu', \n",
        "                 kernel_initializer='glorot_normal', \n",
        "                 batch_size=128,\n",
        "                 epochs=5,\n",
        "                 optimizer='rmsprop'):\n",
        "  # build model\n",
        "  model = models.Sequential()\n",
        "  model.add(Dense(1000,\n",
        "                  kernel_initializer=kernel_initializer,\n",
        "                  use_bias=False))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(func_name))\n",
        "  model.add(Dense(27, activation='softmax'))\n",
        "  # compile mode\n",
        "  model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYFWk7rx-xBN",
        "outputId": "da5ca27a-2e4e-466d-e501-dc7267f8e40f"
      },
      "source": [
        "# create params dictionary for gridsearch\n",
        "func_names = ['relu', 'tanh', 'sigmoid']\n",
        "optimizers = ['rmsprop', 'sgd', 'adam', 'adadelta', 'adagrad']\n",
        "kernel_initializers= ['glorot_uniform', 'glorot_normal']\n",
        "batch_sizes = [128, 256, 512]\n",
        "parmam_grid = dict(optimizer=optimizers, \n",
        "                   func_name=func_names, \n",
        "                   batch_size=batch_sizes, \n",
        "                   kernel_initializer=kernel_initializers)\n",
        "print(parmam_grid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'optimizer': ['rmsprop', 'sgd', 'adam', 'adadelta', 'adagrad'], 'func_name': ['relu', 'tanh', 'sigmoid'], 'batch_size': [128, 256, 512], 'kernel_initializer': ['glorot_uniform', 'glorot_normal']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgGg7rF-F1v4",
        "outputId": "6f34bdb3-b462-46d6-e795-3c9b5aadcb24"
      },
      "source": [
        "# create model\n",
        "model = KerasClassifier(build_fn=define_model)\n",
        "\n",
        "# perform gridsearch\n",
        "grid = GridSearchCV(estimator=model, param_grid=parmam_grid, verbose=1)\n",
        "grid_res = grid.fit(train_images, train_labels)\n",
        "\n",
        "print(f'Best accuracy: {grid_res.best_score_} using {grid_res.best_params_}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "650/650 [==============================] - 2s 3ms/step - loss: 0.9447 - accuracy: 0.7242\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.8476\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 0.9350 - accuracy: 0.7276\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.4793 - accuracy: 0.8552\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 0.9423 - accuracy: 0.7272\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.8526\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 0.9379 - accuracy: 0.7290\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.4701 - accuracy: 0.8508\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 0.9337 - accuracy: 0.7284\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.4781 - accuracy: 0.8577\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 1.8977 - accuracy: 0.4943\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.0181 - accuracy: 0.7134\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 1.9223 - accuracy: 0.4897\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.0207 - accuracy: 0.7152\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 1.9065 - accuracy: 0.4895\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.0322 - accuracy: 0.7077\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 1.9308 - accuracy: 0.4839\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.0193 - accuracy: 0.7125\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 1.8960 - accuracy: 0.4893\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.0302 - accuracy: 0.7134\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 0.9871 - accuracy: 0.7140\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.4997 - accuracy: 0.8540\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 0.9770 - accuracy: 0.7163\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.4830 - accuracy: 0.8529\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 0.9860 - accuracy: 0.7173\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.5144 - accuracy: 0.8432\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 0.9704 - accuracy: 0.7221\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 0.4878 - accuracy: 0.8537\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 0.9727 - accuracy: 0.7201\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.4952 - accuracy: 0.8525\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.5626 - accuracy: 0.0488\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 3.1504 - accuracy: 0.1234\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.5675 - accuracy: 0.0492\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 3.1634 - accuracy: 0.1294\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.6760 - accuracy: 0.0417\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 3.2579 - accuracy: 0.1048\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.6323 - accuracy: 0.0534\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 3.2431 - accuracy: 0.1023\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.6031 - accuracy: 0.0559\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 3.1862 - accuracy: 0.1091\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 2.5731 - accuracy: 0.3113\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.4605 - accuracy: 0.6167\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 2.5978 - accuracy: 0.3105\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.4312 - accuracy: 0.6234\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 2.5346 - accuracy: 0.3205\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.4758 - accuracy: 0.6096\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 2.5812 - accuracy: 0.3184\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.4551 - accuracy: 0.6176\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 2.5373 - accuracy: 0.3205\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.4403 - accuracy: 0.6184\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 0.9343 - accuracy: 0.7249\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.4807 - accuracy: 0.8550\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 0.9352 - accuracy: 0.7265\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.4613 - accuracy: 0.8573\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 0.9353 - accuracy: 0.7277\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.4870 - accuracy: 0.8541\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 0.9468 - accuracy: 0.7255\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.4758 - accuracy: 0.8551\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 0.9360 - accuracy: 0.7272\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.4914 - accuracy: 0.8519\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 1.9074 - accuracy: 0.4823\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.0253 - accuracy: 0.7118\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 1.8884 - accuracy: 0.4895\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.0048 - accuracy: 0.7150\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 1.9105 - accuracy: 0.4896\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 1.0287 - accuracy: 0.7108\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 1.9005 - accuracy: 0.4930\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.0168 - accuracy: 0.7160\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 1.9104 - accuracy: 0.4832\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 1.0391 - accuracy: 0.7111\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 0.9776 - accuracy: 0.7155\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.4986 - accuracy: 0.8491\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 0.9839 - accuracy: 0.7122\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.5010 - accuracy: 0.8542\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 0.9887 - accuracy: 0.7160\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.5248 - accuracy: 0.8419\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 0.9733 - accuracy: 0.7165\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 0.4982 - accuracy: 0.8496\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 0.9701 - accuracy: 0.7184\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.4924 - accuracy: 0.8517\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.6321 - accuracy: 0.0480\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 3.2156 - accuracy: 0.1127\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.6091 - accuracy: 0.0405\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 3.2257 - accuracy: 0.1044\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.5964 - accuracy: 0.0717\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 3.2068 - accuracy: 0.1383\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.5439 - accuracy: 0.0545\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 3.1545 - accuracy: 0.1139\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.5731 - accuracy: 0.0613\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 3.1639 - accuracy: 0.1247\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 2.5098 - accuracy: 0.3253\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.4288 - accuracy: 0.6197\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 2.5775 - accuracy: 0.3088\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.4451 - accuracy: 0.6217\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 2.5432 - accuracy: 0.3240\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.4514 - accuracy: 0.6152\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 2.5213 - accuracy: 0.3244\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.4379 - accuracy: 0.6226\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 2.5295 - accuracy: 0.3254\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.4474 - accuracy: 0.6199\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.1489 - accuracy: 0.6673\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.6686 - accuracy: 0.7996\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.1611 - accuracy: 0.6625\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.6664 - accuracy: 0.8041\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.1528 - accuracy: 0.6697\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.6823 - accuracy: 0.8004\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.1478 - accuracy: 0.6673\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.6669 - accuracy: 0.8038\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.1527 - accuracy: 0.6684\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.6778 - accuracy: 0.7979\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 1.8451 - accuracy: 0.4916\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.1026 - accuracy: 0.6850\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 1.8424 - accuracy: 0.4878\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.1036 - accuracy: 0.6842\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 1.8356 - accuracy: 0.4927\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.1230 - accuracy: 0.6776\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 1.8522 - accuracy: 0.4881\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.1071 - accuracy: 0.6831\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 1.8253 - accuracy: 0.4939\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.1182 - accuracy: 0.6815\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.1589 - accuracy: 0.6667\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.6747 - accuracy: 0.8031\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.1669 - accuracy: 0.6630\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.6927 - accuracy: 0.7923\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.1582 - accuracy: 0.6671\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.7107 - accuracy: 0.7937\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.1589 - accuracy: 0.6676\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.6873 - accuracy: 0.8002\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.1600 - accuracy: 0.6653\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.7065 - accuracy: 0.7948\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.5402 - accuracy: 0.0489\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 3.0561 - accuracy: 0.1407\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.3927 - accuracy: 0.0713\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 2.9318 - accuracy: 0.1723\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.4433 - accuracy: 0.0593\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 2.9906 - accuracy: 0.1469\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.4242 - accuracy: 0.0759\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 2.9478 - accuracy: 0.1722\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.4461 - accuracy: 0.0689\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 3.0100 - accuracy: 0.1612\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 2.3699 - accuracy: 0.3488\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.3863 - accuracy: 0.6138\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 2.3632 - accuracy: 0.3535\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.3782 - accuracy: 0.6154\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 2.3812 - accuracy: 0.3451\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.4092 - accuracy: 0.6069\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 2.3575 - accuracy: 0.3492\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.3901 - accuracy: 0.6125\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 2.3358 - accuracy: 0.3585\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.3922 - accuracy: 0.6098\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.1531 - accuracy: 0.6647\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.6701 - accuracy: 0.8026\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.1690 - accuracy: 0.6617\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.6667 - accuracy: 0.8017\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.1563 - accuracy: 0.6681\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.6980 - accuracy: 0.7936\n",
            "650/650 [==============================] - 3s 3ms/step - loss: 1.1558 - accuracy: 0.6668\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.6761 - accuracy: 0.7979\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.1611 - accuracy: 0.6669\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.6798 - accuracy: 0.7999\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 1.8173 - accuracy: 0.4957\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.1123 - accuracy: 0.6799\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 1.8231 - accuracy: 0.4965\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 1.1015 - accuracy: 0.6829\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 1.8388 - accuracy: 0.4928\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.1172 - accuracy: 0.6781\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 1.8154 - accuracy: 0.4975\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.1085 - accuracy: 0.6843\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.8222 - accuracy: 0.4960\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.1172 - accuracy: 0.6799\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.1652 - accuracy: 0.6645\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.6956 - accuracy: 0.7921\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.1781 - accuracy: 0.6607\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 0.6698 - accuracy: 0.8044\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.1708 - accuracy: 0.6652\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 0.7007 - accuracy: 0.7946\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.1642 - accuracy: 0.6657\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 0.6764 - accuracy: 0.8036\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.1600 - accuracy: 0.6657\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.7044 - accuracy: 0.7928\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.3839 - accuracy: 0.0711\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 2.9131 - accuracy: 0.1731\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.4744 - accuracy: 0.0581\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 2.9804 - accuracy: 0.1620\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.4261 - accuracy: 0.0533\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 2.9537 - accuracy: 0.1521\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.4916 - accuracy: 0.0581\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 3.0212 - accuracy: 0.1560\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.3912 - accuracy: 0.0663\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 2.9275 - accuracy: 0.1786\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 2.3862 - accuracy: 0.3427\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 1.3871 - accuracy: 0.6093\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 2.4004 - accuracy: 0.3399\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.4091 - accuracy: 0.6061\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 2.3672 - accuracy: 0.3507\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.4016 - accuracy: 0.6079\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 2.3783 - accuracy: 0.3475\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.3838 - accuracy: 0.6125\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 2.4104 - accuracy: 0.3403\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.4053 - accuracy: 0.6115\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.3466 - accuracy: 0.6146\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.0312 - accuracy: 0.6935\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.3439 - accuracy: 0.6138\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.9527 - accuracy: 0.7175\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.3505 - accuracy: 0.6125\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.0163 - accuracy: 0.7016\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.3525 - accuracy: 0.6099\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.9652 - accuracy: 0.7181\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.3345 - accuracy: 0.6159\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.0095 - accuracy: 0.6981\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 2.6689 - accuracy: 0.3412\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 1.7062 - accuracy: 0.5948\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 2.6523 - accuracy: 0.3438\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.6818 - accuracy: 0.6015\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 2.6524 - accuracy: 0.3343\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.7036 - accuracy: 0.5884\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 2.6746 - accuracy: 0.3355\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 1.7063 - accuracy: 0.5906\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 2.6436 - accuracy: 0.3384\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 1.7070 - accuracy: 0.5865\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.3537 - accuracy: 0.6145\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.9644 - accuracy: 0.7187\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.3677 - accuracy: 0.6100\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.9871 - accuracy: 0.7084\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.3472 - accuracy: 0.6143\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 0.9693 - accuracy: 0.7181\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.3514 - accuracy: 0.6146\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.9749 - accuracy: 0.7169\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.3585 - accuracy: 0.6155\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 0.9874 - accuracy: 0.7137\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.4835 - accuracy: 0.0482\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 3.2534 - accuracy: 0.0690\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.4427 - accuracy: 0.0584\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 3.2371 - accuracy: 0.0941\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.5054 - accuracy: 0.0298\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 3.2675 - accuracy: 0.0706\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.4748 - accuracy: 0.0361\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 3.2544 - accuracy: 0.0661\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.4457 - accuracy: 0.0403\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 3.2270 - accuracy: 0.0640\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.0707 - accuracy: 0.1784\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 2.4276 - accuracy: 0.4828\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.1045 - accuracy: 0.1757\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 2.4349 - accuracy: 0.4666\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.0543 - accuracy: 0.1832\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 2.4160 - accuracy: 0.4698\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.0763 - accuracy: 0.1991\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 2.4348 - accuracy: 0.4744\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.0463 - accuracy: 0.1953\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 2.4304 - accuracy: 0.4802\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.3454 - accuracy: 0.6133\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.0069 - accuracy: 0.7042\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.3493 - accuracy: 0.6119\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.9601 - accuracy: 0.7189\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.3393 - accuracy: 0.6159\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.9888 - accuracy: 0.7119\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.3332 - accuracy: 0.6165\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.0041 - accuracy: 0.7073\n",
            "650/650 [==============================] - 3s 3ms/step - loss: 1.3488 - accuracy: 0.6136\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 0.9956 - accuracy: 0.7080\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 2.6734 - accuracy: 0.3402\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.7060 - accuracy: 0.5850\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 2.6510 - accuracy: 0.3425\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.7018 - accuracy: 0.5972\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 2.6489 - accuracy: 0.3440\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 1.7254 - accuracy: 0.5809\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 2.6576 - accuracy: 0.3413\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.7009 - accuracy: 0.5967\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 2.6408 - accuracy: 0.3514\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 1.7065 - accuracy: 0.5946\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.3519 - accuracy: 0.6175\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 0.9576 - accuracy: 0.7249\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.3509 - accuracy: 0.6178\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 0.9668 - accuracy: 0.7179\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.3530 - accuracy: 0.6153\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 0.9977 - accuracy: 0.7065\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.3570 - accuracy: 0.6171\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.9622 - accuracy: 0.7211\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 1.3463 - accuracy: 0.6177\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.9759 - accuracy: 0.7160\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.5709 - accuracy: 0.0363\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 3.2978 - accuracy: 0.0522\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.3986 - accuracy: 0.0355\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 3.2026 - accuracy: 0.0777\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.4203 - accuracy: 0.0485\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 3.2165 - accuracy: 0.1000\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.4922 - accuracy: 0.0500\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 3.2669 - accuracy: 0.0698\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.4618 - accuracy: 0.0465\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 3.2437 - accuracy: 0.0893\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.0662 - accuracy: 0.1919\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 2.4241 - accuracy: 0.4776\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.0475 - accuracy: 0.1969\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 2.3943 - accuracy: 0.4939\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.0754 - accuracy: 0.1912\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 2.4276 - accuracy: 0.4760\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.0873 - accuracy: 0.1802\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 2.4458 - accuracy: 0.4772\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 3.0780 - accuracy: 0.2002\n",
            "163/163 [==============================] - 1s 3ms/step - loss: 2.4365 - accuracy: 0.4780\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 0.9929 - accuracy: 0.7140\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.8485\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 0.9817 - accuracy: 0.7155\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.4870 - accuracy: 0.8535\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 0.9888 - accuracy: 0.7178\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.8473\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 0.9924 - accuracy: 0.7167\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.8411\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 0.9938 - accuracy: 0.7107\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.5032 - accuracy: 0.8462\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.2333 - accuracy: 0.4077\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.2211 - accuracy: 0.6681\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.3156 - accuracy: 0.3854\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.2299 - accuracy: 0.6656\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.2400 - accuracy: 0.4036\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.2328 - accuracy: 0.6588\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.2816 - accuracy: 0.3981\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.2234 - accuracy: 0.6661\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.2686 - accuracy: 0.3939\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.2349 - accuracy: 0.6624\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 1.0491 - accuracy: 0.7008\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.8450\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 1.0634 - accuracy: 0.6944\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.8457\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 1.0499 - accuracy: 0.6975\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.5477 - accuracy: 0.8389\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 1.0528 - accuracy: 0.7012\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.8458\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 1.0457 - accuracy: 0.7017\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.5374 - accuracy: 0.8417\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.6335 - accuracy: 0.0379\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.3517 - accuracy: 0.0694\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.6001 - accuracy: 0.0434\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.3301 - accuracy: 0.0788\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.7370 - accuracy: 0.0231\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.4650 - accuracy: 0.0470\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.6206 - accuracy: 0.0448\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.3462 - accuracy: 0.0651\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.5914 - accuracy: 0.0423\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.3235 - accuracy: 0.0724\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.9941 - accuracy: 0.2069\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.8289 - accuracy: 0.5380\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.8699 - accuracy: 0.2352\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.7777 - accuracy: 0.5532\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 2.9297 - accuracy: 0.2161\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.7992 - accuracy: 0.5414\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.8871 - accuracy: 0.2298\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.8065 - accuracy: 0.5377\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.8909 - accuracy: 0.2280\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.7968 - accuracy: 0.5406\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 0.9911 - accuracy: 0.7132\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.4955 - accuracy: 0.8500\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 1.0067 - accuracy: 0.7122\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.5031 - accuracy: 0.8501\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 0.9791 - accuracy: 0.7174\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.8464\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 0.9980 - accuracy: 0.7123\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.4971 - accuracy: 0.8488\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 1.0036 - accuracy: 0.7104\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.8501\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 2.2673 - accuracy: 0.4020\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.2318 - accuracy: 0.6605\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.2936 - accuracy: 0.3921\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.2233 - accuracy: 0.6684\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.2506 - accuracy: 0.3979\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.2357 - accuracy: 0.6604\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.2541 - accuracy: 0.4079\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.2082 - accuracy: 0.6705\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.2770 - accuracy: 0.3936\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.2249 - accuracy: 0.6661\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 1.0504 - accuracy: 0.7005\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.8453\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 1.0507 - accuracy: 0.6991\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.8463\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 1.0436 - accuracy: 0.7015\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.5306 - accuracy: 0.8411\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 1.0416 - accuracy: 0.7010\n",
            "82/82 [==============================] - 1s 3ms/step - loss: 0.5158 - accuracy: 0.8478\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 1.0493 - accuracy: 0.7005\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.8444\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.7077 - accuracy: 0.0404\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.4236 - accuracy: 0.0590\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.6672 - accuracy: 0.0288\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.3905 - accuracy: 0.0542\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.6786 - accuracy: 0.0473\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.3989 - accuracy: 0.0940\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.6508 - accuracy: 0.0299\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.3665 - accuracy: 0.0622\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.6579 - accuracy: 0.0518\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.3810 - accuracy: 0.0752\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.9127 - accuracy: 0.2254\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.7818 - accuracy: 0.5448\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.8716 - accuracy: 0.2295\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.7749 - accuracy: 0.5534\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 2.8168 - accuracy: 0.2469\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.7695 - accuracy: 0.5456\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.8748 - accuracy: 0.2320\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.7705 - accuracy: 0.5530\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.9759 - accuracy: 0.2076\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.8321 - accuracy: 0.5360\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 1.1949 - accuracy: 0.6566\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.7184 - accuracy: 0.7884\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 1.1959 - accuracy: 0.6557\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.7133 - accuracy: 0.7905\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 1.1743 - accuracy: 0.6608\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.7242 - accuracy: 0.7850\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 1.1874 - accuracy: 0.6590\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.7162 - accuracy: 0.7951\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 1.1844 - accuracy: 0.6587\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.7387 - accuracy: 0.7865\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.1256 - accuracy: 0.4155\n",
            "82/82 [==============================] - 1s 3ms/step - loss: 1.2332 - accuracy: 0.6524\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.1347 - accuracy: 0.4119\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.2324 - accuracy: 0.6513\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.1273 - accuracy: 0.4185\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.2481 - accuracy: 0.6432\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.1157 - accuracy: 0.4150\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.2382 - accuracy: 0.6500\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.1237 - accuracy: 0.4212\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.2430 - accuracy: 0.6505\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 1.2051 - accuracy: 0.6522\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.7408 - accuracy: 0.7833\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 1.2053 - accuracy: 0.6568\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.7340 - accuracy: 0.7856\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 1.2025 - accuracy: 0.6553\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.7516 - accuracy: 0.7782\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 1.2114 - accuracy: 0.6505\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.7434 - accuracy: 0.7876\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 1.2086 - accuracy: 0.6529\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.7600 - accuracy: 0.7824\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.5366 - accuracy: 0.0409\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.2282 - accuracy: 0.0928\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.5604 - accuracy: 0.0472\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.2458 - accuracy: 0.0990\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.4276 - accuracy: 0.0626\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.1310 - accuracy: 0.1308\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.5406 - accuracy: 0.0569\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.2198 - accuracy: 0.1033\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.4776 - accuracy: 0.0429\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.1741 - accuracy: 0.0938\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.7855 - accuracy: 0.2336\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.6687 - accuracy: 0.5407\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.6784 - accuracy: 0.2577\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.6428 - accuracy: 0.5544\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.6887 - accuracy: 0.2594\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.6667 - accuracy: 0.5471\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 2.7055 - accuracy: 0.2555\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.6611 - accuracy: 0.5523\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.7226 - accuracy: 0.2550\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.6595 - accuracy: 0.5529\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 1.1904 - accuracy: 0.6568\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.7163 - accuracy: 0.7913\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 1.1949 - accuracy: 0.6560\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.6986 - accuracy: 0.7948\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 1.1875 - accuracy: 0.6586\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7816\n",
            "325/325 [==============================] - 2s 4ms/step - loss: 1.1938 - accuracy: 0.6555\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.7143 - accuracy: 0.7919\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 1.1808 - accuracy: 0.6585\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.7226 - accuracy: 0.7915\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.1655 - accuracy: 0.4038\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.2350 - accuracy: 0.6478\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 2.1513 - accuracy: 0.4086\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.2363 - accuracy: 0.6485\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.1043 - accuracy: 0.4214\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.2453 - accuracy: 0.6462\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.1146 - accuracy: 0.4188\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.2413 - accuracy: 0.6508\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.1275 - accuracy: 0.4171\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.2471 - accuracy: 0.6483\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 1.2027 - accuracy: 0.6558\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.7245 - accuracy: 0.7904\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 1.2104 - accuracy: 0.6539\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7835\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 1.2008 - accuracy: 0.6549\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.7586 - accuracy: 0.7770\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 1.2056 - accuracy: 0.6550\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.7312 - accuracy: 0.7911\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 1.2095 - accuracy: 0.6563\n",
            "82/82 [==============================] - 1s 3ms/step - loss: 0.7326 - accuracy: 0.7903\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.4593 - accuracy: 0.0644\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.1577 - accuracy: 0.1147\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.4328 - accuracy: 0.0512\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.1323 - accuracy: 0.1098\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.6299 - accuracy: 0.0471\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.3127 - accuracy: 0.0896\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.4786 - accuracy: 0.0523\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.1620 - accuracy: 0.1000\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.5855 - accuracy: 0.0470\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.2758 - accuracy: 0.0965\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.7347 - accuracy: 0.2476\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.6464 - accuracy: 0.5545\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.8034 - accuracy: 0.2369\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.6541 - accuracy: 0.5541\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.7869 - accuracy: 0.2463\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.6759 - accuracy: 0.5473\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.7650 - accuracy: 0.2406\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.6658 - accuracy: 0.5475\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.7463 - accuracy: 0.2424\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.6671 - accuracy: 0.5481\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 1.3961 - accuracy: 0.6025\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.0464 - accuracy: 0.6864\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 1.4082 - accuracy: 0.6013\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.0090 - accuracy: 0.7025\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 1.3979 - accuracy: 0.6093\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.0179 - accuracy: 0.7066\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 1.4037 - accuracy: 0.6015\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.0143 - accuracy: 0.6984\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 1.4025 - accuracy: 0.6049\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.0089 - accuracy: 0.7082\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.9365 - accuracy: 0.2492\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.1053 - accuracy: 0.5416\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.9539 - accuracy: 0.2416\n",
            "82/82 [==============================] - 1s 3ms/step - loss: 2.1072 - accuracy: 0.5465\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.8924 - accuracy: 0.2698\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.1055 - accuracy: 0.5346\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.9279 - accuracy: 0.2540\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.1098 - accuracy: 0.5285\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.9511 - accuracy: 0.2289\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.1378 - accuracy: 0.5341\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 1.4487 - accuracy: 0.5941\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.0005 - accuracy: 0.7064\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 1.4345 - accuracy: 0.6032\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.9768 - accuracy: 0.7169\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 1.4265 - accuracy: 0.6023\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.0113 - accuracy: 0.7043\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 1.4508 - accuracy: 0.5972\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.9970 - accuracy: 0.7080\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 1.4381 - accuracy: 0.6022\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.0087 - accuracy: 0.7074\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 3.5473 - accuracy: 0.0399\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.4031 - accuracy: 0.0444\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.5164 - accuracy: 0.0386\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.3772 - accuracy: 0.0432\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.6124 - accuracy: 0.0242\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.4530 - accuracy: 0.0281\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.5313 - accuracy: 0.0048\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.3896 - accuracy: 0.0112\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.4067 - accuracy: 0.0367\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.2798 - accuracy: 0.0443\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.2363 - accuracy: 0.1246\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.7660 - accuracy: 0.3724\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.1465 - accuracy: 0.1431\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.7375 - accuracy: 0.3661\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.2479 - accuracy: 0.0952\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.8003 - accuracy: 0.3453\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.2428 - accuracy: 0.1129\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.7983 - accuracy: 0.3568\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 3.2223 - accuracy: 0.1217\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.7745 - accuracy: 0.3620\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 1.4087 - accuracy: 0.6042\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.7044\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 1.4102 - accuracy: 0.6027\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.9730 - accuracy: 0.7175\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 1.3972 - accuracy: 0.6062\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.0358 - accuracy: 0.6920\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 1.3917 - accuracy: 0.6040\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.0049 - accuracy: 0.7081\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 1.4019 - accuracy: 0.6039\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.0028 - accuracy: 0.7113\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.9090 - accuracy: 0.2669\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.1015 - accuracy: 0.5392\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.8973 - accuracy: 0.2614\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.0923 - accuracy: 0.5494\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 2.9020 - accuracy: 0.2535\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.1025 - accuracy: 0.5375\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.9354 - accuracy: 0.2382\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.1196 - accuracy: 0.5340\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 2.9506 - accuracy: 0.2391\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.1337 - accuracy: 0.5451\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 1.4275 - accuracy: 0.6051\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.9929 - accuracy: 0.7096\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 1.4346 - accuracy: 0.5970\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.9832 - accuracy: 0.7108\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 1.4306 - accuracy: 0.6021\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.0064 - accuracy: 0.7063\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 1.4353 - accuracy: 0.6030\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.9962 - accuracy: 0.7124\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 1.4414 - accuracy: 0.6001\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.0035 - accuracy: 0.7076\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.5785 - accuracy: 0.0422\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.4153 - accuracy: 0.0445\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.5158 - accuracy: 0.0366\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.3667 - accuracy: 0.0413\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.5506 - accuracy: 0.0424\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.4154 - accuracy: 0.0454\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.5080 - accuracy: 0.0462\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.3647 - accuracy: 0.0620\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.5361 - accuracy: 0.0366\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.3954 - accuracy: 0.0473\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.2035 - accuracy: 0.1095\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.7595 - accuracy: 0.3522\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.1675 - accuracy: 0.1175\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.7558 - accuracy: 0.3623\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.2415 - accuracy: 0.1051\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.7764 - accuracy: 0.3596\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.2028 - accuracy: 0.1176\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.7651 - accuracy: 0.3580\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.2462 - accuracy: 0.1000\n",
            "82/82 [==============================] - 1s 3ms/step - loss: 2.8153 - accuracy: 0.3459\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.0856 - accuracy: 0.6898\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5550 - accuracy: 0.8332\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.0836 - accuracy: 0.6912\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.5630 - accuracy: 0.8279\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.0658 - accuracy: 0.6993\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5742 - accuracy: 0.8259\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.0851 - accuracy: 0.6916\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5336 - accuracy: 0.8352\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.0778 - accuracy: 0.6932\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5737 - accuracy: 0.8291\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 2.6218 - accuracy: 0.3049\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.5076 - accuracy: 0.6062\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 2.6869 - accuracy: 0.2883\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.5177 - accuracy: 0.6040\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 2.6142 - accuracy: 0.3043\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.5190 - accuracy: 0.6047\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 2.6194 - accuracy: 0.3004\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.5081 - accuracy: 0.6062\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 2.6459 - accuracy: 0.2995\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.5119 - accuracy: 0.6079\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.1808 - accuracy: 0.6689\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.5636 - accuracy: 0.8375\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 1.1805 - accuracy: 0.6643\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.5476 - accuracy: 0.8377\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 1.1701 - accuracy: 0.6684\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.5653 - accuracy: 0.8291\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 1.1703 - accuracy: 0.6690\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.5523 - accuracy: 0.8301\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.1840 - accuracy: 0.6646\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.5633 - accuracy: 0.8357\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.6846 - accuracy: 0.0388\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.5102 - accuracy: 0.0503\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 3.6544 - accuracy: 0.0424\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.4890 - accuracy: 0.0572\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 3.7178 - accuracy: 0.0470\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.5407 - accuracy: 0.0587\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.6824 - accuracy: 0.0309\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.5038 - accuracy: 0.0412\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 3.5606 - accuracy: 0.0542\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.4054 - accuracy: 0.0690\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.1866 - accuracy: 0.1352\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.2547 - accuracy: 0.4222\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 3.1859 - accuracy: 0.1463\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.2443 - accuracy: 0.4365\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 3.2218 - accuracy: 0.1473\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.2753 - accuracy: 0.4227\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 3.2277 - accuracy: 0.1271\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.3150 - accuracy: 0.4039\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.1345 - accuracy: 0.1480\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.2598 - accuracy: 0.4246\n",
            "163/163 [==============================] - 2s 5ms/step - loss: 1.0861 - accuracy: 0.6896\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5961 - accuracy: 0.8202\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.0925 - accuracy: 0.6896\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.5501 - accuracy: 0.8335\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.0722 - accuracy: 0.6951\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.5690 - accuracy: 0.8266\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.1080 - accuracy: 0.6888\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.5564 - accuracy: 0.8291\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.0873 - accuracy: 0.6903\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.5685 - accuracy: 0.8311\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 2.6608 - accuracy: 0.2885\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.5042 - accuracy: 0.6062\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 2.6441 - accuracy: 0.2914\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.5016 - accuracy: 0.6099\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 2.6100 - accuracy: 0.3068\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.5253 - accuracy: 0.6025\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 2.6082 - accuracy: 0.3011\n",
            "41/41 [==============================] - 1s 3ms/step - loss: 1.5146 - accuracy: 0.6012\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 2.6372 - accuracy: 0.2981\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.5348 - accuracy: 0.6006\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.1710 - accuracy: 0.6660\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.5551 - accuracy: 0.8362\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.1783 - accuracy: 0.6696\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.5503 - accuracy: 0.8328\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.1418 - accuracy: 0.6762\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.5732 - accuracy: 0.8314\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.1622 - accuracy: 0.6723\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.5529 - accuracy: 0.8349\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.1690 - accuracy: 0.6705\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.5576 - accuracy: 0.8340\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.5322 - accuracy: 0.0548\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.3551 - accuracy: 0.0751\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.6374 - accuracy: 0.0381\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.4659 - accuracy: 0.0547\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.5470 - accuracy: 0.0562\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.4009 - accuracy: 0.0721\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 3.6243 - accuracy: 0.0413\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.4496 - accuracy: 0.0605\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 3.6374 - accuracy: 0.0402\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.4681 - accuracy: 0.0518\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 3.1825 - accuracy: 0.1403\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.2577 - accuracy: 0.4225\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 3.2350 - accuracy: 0.1350\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.2808 - accuracy: 0.4198\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 3.2597 - accuracy: 0.1245\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.2913 - accuracy: 0.4214\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 3.1752 - accuracy: 0.1282\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.2685 - accuracy: 0.4156\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.1800 - accuracy: 0.1281\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.2715 - accuracy: 0.4140\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.2686 - accuracy: 0.6364\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.7883 - accuracy: 0.7710\n",
            "163/163 [==============================] - 2s 5ms/step - loss: 1.2585 - accuracy: 0.6399\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.7968 - accuracy: 0.7645\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.2624 - accuracy: 0.6379\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.7996 - accuracy: 0.7629\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.2652 - accuracy: 0.6367\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.8108 - accuracy: 0.7619\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.2588 - accuracy: 0.6376\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.8248 - accuracy: 0.7564\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 2.4289 - accuracy: 0.3356\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.4340 - accuracy: 0.6004\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 2.5071 - accuracy: 0.3172\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.4362 - accuracy: 0.6050\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 2.4521 - accuracy: 0.3272\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.4581 - accuracy: 0.5957\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 2.4417 - accuracy: 0.3322\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.4376 - accuracy: 0.5999\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 2.5161 - accuracy: 0.3090\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.4527 - accuracy: 0.6024\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.2839 - accuracy: 0.6322\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.7893 - accuracy: 0.7703\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.2890 - accuracy: 0.6298\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.7924 - accuracy: 0.7704\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.2948 - accuracy: 0.6337\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.7977 - accuracy: 0.7720\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.2825 - accuracy: 0.6342\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.7937 - accuracy: 0.7722\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.2766 - accuracy: 0.6373\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.8012 - accuracy: 0.7713\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.6019 - accuracy: 0.0394\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.3986 - accuracy: 0.0648\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.5538 - accuracy: 0.0412\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.3750 - accuracy: 0.0650\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.6897 - accuracy: 0.0282\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.4827 - accuracy: 0.0446\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.6229 - accuracy: 0.0334\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.4268 - accuracy: 0.0563\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.5763 - accuracy: 0.0388\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.3843 - accuracy: 0.0615\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 2.9830 - accuracy: 0.1845\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.0046 - accuracy: 0.4675\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 2.9675 - accuracy: 0.1790\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.0191 - accuracy: 0.4668\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.0592 - accuracy: 0.1637\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.0674 - accuracy: 0.4522\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 3.0560 - accuracy: 0.1548\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.0666 - accuracy: 0.4473\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.0661 - accuracy: 0.1658\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.0659 - accuracy: 0.4466\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.2500 - accuracy: 0.6419\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.8228 - accuracy: 0.7519\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.2639 - accuracy: 0.6373\n",
            "41/41 [==============================] - 1s 4ms/step - loss: 0.7815 - accuracy: 0.7670\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.2623 - accuracy: 0.6369\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.8307 - accuracy: 0.7593\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.2549 - accuracy: 0.6367\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.8129 - accuracy: 0.7611\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.2613 - accuracy: 0.6357\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.8169 - accuracy: 0.7637\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 2.4985 - accuracy: 0.3260\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.4439 - accuracy: 0.5963\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 2.4873 - accuracy: 0.3136\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.4399 - accuracy: 0.6040\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 2.4852 - accuracy: 0.3166\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.4652 - accuracy: 0.5932\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 2.4331 - accuracy: 0.3304\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.4372 - accuracy: 0.6036\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 2.4486 - accuracy: 0.3239\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.4533 - accuracy: 0.5973\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.2796 - accuracy: 0.6319\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.7794 - accuracy: 0.7786\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.2930 - accuracy: 0.6300\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.7799 - accuracy: 0.7755\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.2901 - accuracy: 0.6307\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.7972 - accuracy: 0.7706\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.2908 - accuracy: 0.6286\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.8042 - accuracy: 0.7693\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.2901 - accuracy: 0.6345\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.7975 - accuracy: 0.7725\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.5550 - accuracy: 0.0396\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.3859 - accuracy: 0.0606\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 3.5846 - accuracy: 0.0431\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.3959 - accuracy: 0.0684\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.4847 - accuracy: 0.0537\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.2986 - accuracy: 0.0820\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.5277 - accuracy: 0.0423\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.3409 - accuracy: 0.0654\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.6034 - accuracy: 0.0425\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.4265 - accuracy: 0.0573\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.0849 - accuracy: 0.1573\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.0675 - accuracy: 0.4499\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.0468 - accuracy: 0.1559\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.0437 - accuracy: 0.4566\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.1097 - accuracy: 0.1595\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.0876 - accuracy: 0.4493\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 3.1065 - accuracy: 0.1509\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.0496 - accuracy: 0.4563\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.0087 - accuracy: 0.1700\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.0440 - accuracy: 0.4511\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.5054 - accuracy: 0.5828\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.0303 - accuracy: 0.6957\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.5131 - accuracy: 0.5809\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.0299 - accuracy: 0.6961\n",
            "163/163 [==============================] - 2s 5ms/step - loss: 1.5017 - accuracy: 0.5836\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.0774 - accuracy: 0.6840\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.5174 - accuracy: 0.5809\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.0400 - accuracy: 0.6923\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.5065 - accuracy: 0.5820\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.0558 - accuracy: 0.6948\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 3.0859 - accuracy: 0.1820\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.5212 - accuracy: 0.4535\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.0801 - accuracy: 0.1849\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.5140 - accuracy: 0.4712\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.1406 - accuracy: 0.1640\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.5425 - accuracy: 0.4451\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 3.0851 - accuracy: 0.1669\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.5382 - accuracy: 0.4438\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.1103 - accuracy: 0.1663\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.5510 - accuracy: 0.4367\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.5764 - accuracy: 0.5697\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.0150 - accuracy: 0.7073\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.5624 - accuracy: 0.5741\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.0020 - accuracy: 0.7098\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.5664 - accuracy: 0.5724\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.0304 - accuracy: 0.6971\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.5851 - accuracy: 0.5691\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.0136 - accuracy: 0.7102\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.5629 - accuracy: 0.5727\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.0289 - accuracy: 0.7007\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.5208 - accuracy: 0.0383\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.4413 - accuracy: 0.0427\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.6038 - accuracy: 0.0310\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.5209 - accuracy: 0.0349\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.6610 - accuracy: 0.0434\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.5732 - accuracy: 0.0451\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.5203 - accuracy: 0.0307\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.4401 - accuracy: 0.0320\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.4912 - accuracy: 0.0322\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.4173 - accuracy: 0.0391\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.2926 - accuracy: 0.0870\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.0014 - accuracy: 0.2340\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.3210 - accuracy: 0.0866\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.0106 - accuracy: 0.2268\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.2805 - accuracy: 0.0658\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.0012 - accuracy: 0.2363\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.3425 - accuracy: 0.0596\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.0174 - accuracy: 0.2206\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.3399 - accuracy: 0.0614\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.0226 - accuracy: 0.2257\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.5030 - accuracy: 0.5864\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.0563 - accuracy: 0.6888\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.5047 - accuracy: 0.5816\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.1204 - accuracy: 0.6625\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.5174 - accuracy: 0.5812\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.0773 - accuracy: 0.6824\n",
            "163/163 [==============================] - 2s 5ms/step - loss: 1.5157 - accuracy: 0.5815\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.0298 - accuracy: 0.7002\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.5027 - accuracy: 0.5819\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.0602 - accuracy: 0.6851\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 3.1120 - accuracy: 0.1598\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.5445 - accuracy: 0.4498\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.1027 - accuracy: 0.1713\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.5115 - accuracy: 0.4683\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.1142 - accuracy: 0.1742\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.5340 - accuracy: 0.4746\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 3.1462 - accuracy: 0.1544\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.5583 - accuracy: 0.4678\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.1195 - accuracy: 0.1691\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.5496 - accuracy: 0.4384\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.5877 - accuracy: 0.5651\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.0122 - accuracy: 0.7078\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.5764 - accuracy: 0.5719\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.0035 - accuracy: 0.7056\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.5675 - accuracy: 0.5757\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.0356 - accuracy: 0.6937\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.5645 - accuracy: 0.5759\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.0059 - accuracy: 0.7128\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 1.5936 - accuracy: 0.5630\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.0315 - accuracy: 0.7014\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.4609 - accuracy: 0.0397\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.3827 - accuracy: 0.0474\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.5718 - accuracy: 0.0415\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.4878 - accuracy: 0.0483\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.5658 - accuracy: 0.0400\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.4798 - accuracy: 0.0429\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.4724 - accuracy: 0.0330\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.4049 - accuracy: 0.0371\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.4534 - accuracy: 0.0515\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.3843 - accuracy: 0.0582\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.2613 - accuracy: 0.0928\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.9702 - accuracy: 0.2594\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.2956 - accuracy: 0.0787\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.0089 - accuracy: 0.2186\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 3.3390 - accuracy: 0.0729\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.0192 - accuracy: 0.2030\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.3151 - accuracy: 0.0683\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.0220 - accuracy: 0.2118\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 3.3090 - accuracy: 0.0640\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.0282 - accuracy: 0.2084\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 450 out of 450 | elapsed: 17.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "813/813 [==============================] - 3s 3ms/step - loss: 0.8941 - accuracy: 0.7384\n",
            "Best accuracy: 0.8546826958656311 using {'batch_size': 128, 'func_name': 'relu', 'kernel_initializer': 'glorot_normal', 'optimizer': 'rmsprop'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OBSOVkBjV2n",
        "outputId": "08205e8a-76de-4aac-f3a0-17356f8fd665"
      },
      "source": [
        "print(f'Best accuracy: {grid_res.best_score_} using {grid_res.best_params_}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best accuracy: 0.8546826958656311 using {'batch_size': 128, 'func_name': 'relu', 'kernel_initializer': 'glorot_normal', 'optimizer': 'rmsprop'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZZ7Hw7djV2p"
      },
      "source": [
        "# define model with dropout\n",
        "def define_model_2(func_name='relu', \n",
        "                   kernel_initializer='glorot_normal', \n",
        "                   batch_size=128,\n",
        "                   epochs=100,\n",
        "                   dropout_rate=0.5,\n",
        "                   optimizer='rmsprop'):\n",
        "    # build model\n",
        "    model = models.Sequential()\n",
        "    model.add(Dense(1000,\n",
        "                    activation=func_name,\n",
        "                    kernel_initializer=kernel_initializer,\n",
        "                    use_bias=True))\n",
        "    model.add(Dense(27, activation='softmax'))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    # compile model\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOfJfTQTjV2p",
        "outputId": "8fb2c441-a792-416d-e328-f842f38abf3d"
      },
      "source": [
        "# create params dictionary for gridsearch\n",
        "func_names = ['relu', 'tanh', 'sigmoid']\n",
        "optimizers = ['rmsprop', 'sgd', 'adam', 'adadelta', 'adagrad']\n",
        "kernel_initializers= ['glorot_uniform', 'glorot_normal']\n",
        "batch_sizes = [128, 256, 512]\n",
        "dropout_rates = [0.2, 0.5]\n",
        "parmam_grid = dict(optimizer=optimizers, \n",
        "                   func_name=func_names, \n",
        "                   batch_size=batch_sizes,\n",
        "                   dropout_rate=dropout_rates,\n",
        "                   kernel_initializer=kernel_initializers)\n",
        "print(parmam_grid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'optimizer': ['rmsprop', 'sgd', 'adam', 'adadelta', 'adagrad'], 'func_name': ['relu', 'tanh', 'sigmoid'], 'batch_size': [128, 256, 512], 'dropout_rate': [0.2, 0.5], 'kernel_initializer': ['glorot_uniform', 'glorot_normal']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SC0p-3qtjV2p",
        "outputId": "77a4fda0-538b-49a5-f984-d21665b287e9"
      },
      "source": [
        "# create model\n",
        "model = KerasClassifier(build_fn=define_model_2)\n",
        "\n",
        "# perform gridsearch\n",
        "grid = GridSearchCV(estimator=model, param_grid=parmam_grid, verbose=1)\n",
        "grid_res = grid.fit(train_images, train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "650/650 [==============================] - 2s 2ms/step - loss: 3.9792 - accuracy: 0.5888\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.5964 - accuracy: 0.8341\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 3.9438 - accuracy: 0.5891\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.6268 - accuracy: 0.8225\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 3.9499 - accuracy: 0.5905\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.6183 - accuracy: 0.8255\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 3.9459 - accuracy: 0.5906\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.5767 - accuracy: 0.8339\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 3.9338 - accuracy: 0.5933\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.5882 - accuracy: 0.8340\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.7132 - accuracy: 0.3857\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.1079 - accuracy: 0.6905\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.7922 - accuracy: 0.3775\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.1065 - accuracy: 0.6888\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.7365 - accuracy: 0.3869\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.1199 - accuracy: 0.6844\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.7756 - accuracy: 0.3748\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.1098 - accuracy: 0.6859\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.7568 - accuracy: 0.3807\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.1264 - accuracy: 0.6834\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 3.9370 - accuracy: 0.5849\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.5892 - accuracy: 0.8270\n",
            "650/650 [==============================] - 2s 2ms/step - loss: nan - accuracy: 0.4841\n",
            "163/163 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 3.9526 - accuracy: 0.5872\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.8213\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 3.9774 - accuracy: 0.5860\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.5633 - accuracy: 0.8331\n",
            "650/650 [==============================] - 2s 2ms/step - loss: nan - accuracy: 0.5782\n",
            "163/163 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.9316 - accuracy: 0.0305\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.2853 - accuracy: 0.0691\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.8536 - accuracy: 0.0517\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.1889 - accuracy: 0.1178\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.8576 - accuracy: 0.0508\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.2264 - accuracy: 0.1044\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.9124 - accuracy: 0.0392\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.1915 - accuracy: 0.1044\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.8442 - accuracy: 0.0563\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.1524 - accuracy: 0.1187\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.2279 - accuracy: 0.2354\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.6211 - accuracy: 0.5782\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.1994 - accuracy: 0.2368\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.6058 - accuracy: 0.5888\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.2325 - accuracy: 0.2281\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.6620 - accuracy: 0.5641\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.1698 - accuracy: 0.2534\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.5960 - accuracy: 0.5873\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.1950 - accuracy: 0.2405\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.6280 - accuracy: 0.5836\n",
            "650/650 [==============================] - 2s 2ms/step - loss: nan - accuracy: 0.5879\n",
            "163/163 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 3.9171 - accuracy: 0.5939\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.6129 - accuracy: 0.8267\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 3.8799 - accuracy: 0.5908\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.6122 - accuracy: 0.8311\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 3.9716 - accuracy: 0.5883\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.5944 - accuracy: 0.8300\n",
            "650/650 [==============================] - 2s 2ms/step - loss: nan - accuracy: 0.5558\n",
            "163/163 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.7169 - accuracy: 0.3810\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.1136 - accuracy: 0.6841\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.7325 - accuracy: 0.3885\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.0939 - accuracy: 0.6934\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.7580 - accuracy: 0.3860\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.1269 - accuracy: 0.6812\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.7176 - accuracy: 0.3832\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.0978 - accuracy: 0.6916\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.7104 - accuracy: 0.3794\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.1136 - accuracy: 0.6880\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.0135 - accuracy: 0.5820\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.8365\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 3.9894 - accuracy: 0.5822\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.8362\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 3.9414 - accuracy: 0.5883\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.6132 - accuracy: 0.8204\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 3.9941 - accuracy: 0.5803\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.5698 - accuracy: 0.8330\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 3.9666 - accuracy: 0.5864\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.6218 - accuracy: 0.8227\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.9349 - accuracy: 0.0533\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.2425 - accuracy: 0.1189\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.8301 - accuracy: 0.0521\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.1911 - accuracy: 0.1150\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.8463 - accuracy: 0.0402\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.2522 - accuracy: 0.0963\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.8996 - accuracy: 0.0554\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.2427 - accuracy: 0.1111\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.8705 - accuracy: 0.0432\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.1905 - accuracy: 0.1074\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.2600 - accuracy: 0.2363\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.6309 - accuracy: 0.5813\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.1903 - accuracy: 0.2509\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 1.6118 - accuracy: 0.5813\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.1757 - accuracy: 0.2433\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.6283 - accuracy: 0.5725\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.2670 - accuracy: 0.2403\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.6181 - accuracy: 0.5797\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.2334 - accuracy: 0.2426\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.6240 - accuracy: 0.5825\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.0544 - accuracy: 0.5586\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.6094 - accuracy: 0.8185\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.0186 - accuracy: 0.5630\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.6134 - accuracy: 0.8195\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 3.9830 - accuracy: 0.5613\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.6096 - accuracy: 0.8167\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.0504 - accuracy: 0.5591\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.5948 - accuracy: 0.8241\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.0380 - accuracy: 0.5620\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.6147 - accuracy: 0.8213\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.6896 - accuracy: 0.3898\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.1786 - accuracy: 0.6621\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.6449 - accuracy: 0.3909\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.1665 - accuracy: 0.6664\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.6515 - accuracy: 0.3991\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.1823 - accuracy: 0.6621\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.6378 - accuracy: 0.3957\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.1702 - accuracy: 0.6702\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.6416 - accuracy: 0.3960\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.1702 - accuracy: 0.6645\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.0462 - accuracy: 0.5570\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.6273 - accuracy: 0.8155\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.0596 - accuracy: 0.5588\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.6274 - accuracy: 0.8133\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.0215 - accuracy: 0.5560\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.6265 - accuracy: 0.8157\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.0488 - accuracy: 0.5553\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.8202\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.1131 - accuracy: 0.5546\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.8130\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.7270 - accuracy: 0.0622\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 2.9646 - accuracy: 0.1700\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.8747 - accuracy: 0.0422\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.0779 - accuracy: 0.1340\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.8189 - accuracy: 0.0650\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.0017 - accuracy: 0.1547\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.7552 - accuracy: 0.0638\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 2.9666 - accuracy: 0.1641\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.6354 - accuracy: 0.0697\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 2.8924 - accuracy: 0.1692\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.1024 - accuracy: 0.2694\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.5129 - accuracy: 0.5862\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.1312 - accuracy: 0.2624\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.4984 - accuracy: 0.5933\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.1027 - accuracy: 0.2756\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.5153 - accuracy: 0.5828\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.0926 - accuracy: 0.2675\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.5091 - accuracy: 0.5817\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.0567 - accuracy: 0.2717\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.5163 - accuracy: 0.5799\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.0348 - accuracy: 0.5611\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.6053 - accuracy: 0.8168\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 3.9977 - accuracy: 0.5622\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.5925 - accuracy: 0.8219\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.0369 - accuracy: 0.5578\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.6180 - accuracy: 0.8159\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 3.9929 - accuracy: 0.5614\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.6061 - accuracy: 0.8206\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.0594 - accuracy: 0.5592\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.5998 - accuracy: 0.8235\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.6329 - accuracy: 0.3936\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.1687 - accuracy: 0.6662\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.6529 - accuracy: 0.4029\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.1636 - accuracy: 0.6628\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.6894 - accuracy: 0.3927\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.1897 - accuracy: 0.6594\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.6764 - accuracy: 0.3926\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.1706 - accuracy: 0.6646\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.6312 - accuracy: 0.3950\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.1810 - accuracy: 0.6612\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.0746 - accuracy: 0.5543\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.6216 - accuracy: 0.8126\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.1010 - accuracy: 0.5516\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.6082 - accuracy: 0.8179\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.0488 - accuracy: 0.5588\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.6545 - accuracy: 0.8038\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 3.9753 - accuracy: 0.5631\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.6066 - accuracy: 0.8217\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.1030 - accuracy: 0.5535\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.6303 - accuracy: 0.8139\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.7512 - accuracy: 0.0586\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.0201 - accuracy: 0.1458\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.7718 - accuracy: 0.0624\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 2.9859 - accuracy: 0.1679\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.8308 - accuracy: 0.0479\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.0152 - accuracy: 0.1420\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.8115 - accuracy: 0.0627\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.0172 - accuracy: 0.1639\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.8147 - accuracy: 0.0613\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.0093 - accuracy: 0.1524\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.1087 - accuracy: 0.2627\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.5136 - accuracy: 0.5835\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.0690 - accuracy: 0.2724\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.4888 - accuracy: 0.5937\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.1137 - accuracy: 0.2720\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.5129 - accuracy: 0.5863\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.0856 - accuracy: 0.2672\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.5103 - accuracy: 0.5840\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.0450 - accuracy: 0.2701\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.5195 - accuracy: 0.5809\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.1702 - accuracy: 0.5297\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7187 - accuracy: 0.7875\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.1550 - accuracy: 0.5332\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7505 - accuracy: 0.7792\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.0997 - accuracy: 0.5334\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7506 - accuracy: 0.7767\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.1252 - accuracy: 0.5314\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7335 - accuracy: 0.7827\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.0891 - accuracy: 0.5350\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7539 - accuracy: 0.7763\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.2855 - accuracy: 0.2642\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.8842 - accuracy: 0.5666\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.3398 - accuracy: 0.2489\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.8894 - accuracy: 0.5751\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.2907 - accuracy: 0.2660\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.8858 - accuracy: 0.5592\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.3506 - accuracy: 0.2531\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.9012 - accuracy: 0.5699\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.3276 - accuracy: 0.2579\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.8983 - accuracy: 0.5562\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.1690 - accuracy: 0.5271\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7582 - accuracy: 0.7811\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.1857 - accuracy: 0.5276\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7531 - accuracy: 0.7789\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.1132 - accuracy: 0.5289\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7725 - accuracy: 0.7743\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.1335 - accuracy: 0.5265\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7710 - accuracy: 0.7730\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.1729 - accuracy: 0.5284\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7627 - accuracy: 0.7816\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.7222 - accuracy: 0.0425\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.2223 - accuracy: 0.0811\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.8066 - accuracy: 0.0506\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.2296 - accuracy: 0.0971\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.7950 - accuracy: 0.0374\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.2558 - accuracy: 0.0587\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.8242 - accuracy: 0.0384\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.3057 - accuracy: 0.0564\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.8238 - accuracy: 0.0402\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.3128 - accuracy: 0.0450\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.4594 - accuracy: 0.1629\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 2.6075 - accuracy: 0.4325\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.5702 - accuracy: 0.1474\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 2.6126 - accuracy: 0.4517\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.5216 - accuracy: 0.1603\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 2.6114 - accuracy: 0.4475\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.5300 - accuracy: 0.1417\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 2.6269 - accuracy: 0.4292\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.5424 - accuracy: 0.1467\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 2.6152 - accuracy: 0.4377\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.1169 - accuracy: 0.5313\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7437 - accuracy: 0.7821\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.1077 - accuracy: 0.5341\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7579 - accuracy: 0.7758\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.0954 - accuracy: 0.5336\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7581 - accuracy: 0.7772\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.0823 - accuracy: 0.5356\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7524 - accuracy: 0.7781\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.1162 - accuracy: 0.5346\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7822 - accuracy: 0.7675\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.2628 - accuracy: 0.2682\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.8844 - accuracy: 0.5678\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.3135 - accuracy: 0.2506\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.8938 - accuracy: 0.5646\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.3018 - accuracy: 0.2573\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.8978 - accuracy: 0.5564\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.2947 - accuracy: 0.2665\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.8839 - accuracy: 0.5692\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.3360 - accuracy: 0.2519\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.9000 - accuracy: 0.5659\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.1431 - accuracy: 0.5297\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7852 - accuracy: 0.7683\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.1464 - accuracy: 0.5269\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7650 - accuracy: 0.7771\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.1479 - accuracy: 0.5332\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7970 - accuracy: 0.7649\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.1637 - accuracy: 0.5278\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7624 - accuracy: 0.7763\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 4.0581 - accuracy: 0.5313\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7645 - accuracy: 0.7768\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.7743 - accuracy: 0.0454\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.2294 - accuracy: 0.0743\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.8641 - accuracy: 0.0416\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.3028 - accuracy: 0.0408\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.8109 - accuracy: 0.0378\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.3095 - accuracy: 0.0506\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.8038 - accuracy: 0.0413\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 3.2394 - accuracy: 0.0647\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.8712 - accuracy: 0.0412\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.2860 - accuracy: 0.0650\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.6199 - accuracy: 0.1349\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 2.6493 - accuracy: 0.4265\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.5874 - accuracy: 0.1236\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 2.6657 - accuracy: 0.4086\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.5773 - accuracy: 0.1214\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 2.6521 - accuracy: 0.4231\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.6025 - accuracy: 0.1290\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 2.6415 - accuracy: 0.4377\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 5.5616 - accuracy: 0.1451\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 2.6266 - accuracy: 0.4280\n",
            "650/650 [==============================] - 2s 2ms/step - loss: nan - accuracy: 0.3732\n",
            "163/163 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.4559 - accuracy: 0.3764\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7166 - accuracy: 0.8038\n",
            "650/650 [==============================] - 2s 2ms/step - loss: nan - accuracy: 0.3597\n",
            "163/163 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.5407 - accuracy: 0.3744\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7957 - accuracy: 0.7781\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 8.3918 - accuracy: 0.3843\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7517 - accuracy: 0.7942\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.9451 - accuracy: 0.2363\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.3198 - accuracy: 0.6369\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.0247 - accuracy: 0.2306\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.3203 - accuracy: 0.6432\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.9635 - accuracy: 0.2310\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.3455 - accuracy: 0.6312\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.9571 - accuracy: 0.2379\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.3241 - accuracy: 0.6407\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.9072 - accuracy: 0.2379\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.3203 - accuracy: 0.6429\n",
            "650/650 [==============================] - 2s 2ms/step - loss: nan - accuracy: 0.2577\n",
            "163/163 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.5246 - accuracy: 0.3703\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7838 - accuracy: 0.7845\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.4954 - accuracy: 0.3734\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7596 - accuracy: 0.7851\n",
            "650/650 [==============================] - 2s 2ms/step - loss: nan - accuracy: 0.3724\n",
            "163/163 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "650/650 [==============================] - 2s 2ms/step - loss: nan - accuracy: 0.3754\n",
            "163/163 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.4973 - accuracy: 0.0449\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.2998 - accuracy: 0.0862\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.4210 - accuracy: 0.0504\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.2901 - accuracy: 0.0982\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.4782 - accuracy: 0.0393\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.3071 - accuracy: 0.0866\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.4369 - accuracy: 0.0432\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.2717 - accuracy: 0.0787\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.5140 - accuracy: 0.0370\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.3231 - accuracy: 0.0692\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.1749 - accuracy: 0.1370\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.9472 - accuracy: 0.5000\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.1707 - accuracy: 0.1375\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.9382 - accuracy: 0.5148\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.1806 - accuracy: 0.1444\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.9464 - accuracy: 0.5192\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.2663 - accuracy: 0.1320\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.9612 - accuracy: 0.5091\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.1910 - accuracy: 0.1401\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.9577 - accuracy: 0.5063\n",
            "650/650 [==============================] - 2s 2ms/step - loss: nan - accuracy: 0.3504\n",
            "163/163 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "650/650 [==============================] - 2s 2ms/step - loss: nan - accuracy: 0.3600\n",
            "163/163 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.4839 - accuracy: 0.3782\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.8253 - accuracy: 0.7821\n",
            "650/650 [==============================] - 2s 2ms/step - loss: nan - accuracy: 0.3444\n",
            "163/163 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.4682 - accuracy: 0.3789\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7686 - accuracy: 0.7890\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.9684 - accuracy: 0.2343\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.3267 - accuracy: 0.6396\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.0102 - accuracy: 0.2268\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.3195 - accuracy: 0.6462\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.9819 - accuracy: 0.2336\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.3484 - accuracy: 0.6260\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.9435 - accuracy: 0.2306\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.3097 - accuracy: 0.6438\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.9693 - accuracy: 0.2292\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.3416 - accuracy: 0.6340\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.5236 - accuracy: 0.3701\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7039 - accuracy: 0.8042\n",
            "650/650 [==============================] - 2s 2ms/step - loss: nan - accuracy: 0.3709\n",
            "163/163 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.4686 - accuracy: 0.3741\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7407 - accuracy: 0.7917\n",
            "650/650 [==============================] - 2s 2ms/step - loss: nan - accuracy: 0.2031\n",
            "163/163 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "650/650 [==============================] - 2s 2ms/step - loss: nan - accuracy: 0.3476\n",
            "163/163 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.5402 - accuracy: 0.0472\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.3459 - accuracy: 0.0938\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.5022 - accuracy: 0.0457\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.3166 - accuracy: 0.0892\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.5303 - accuracy: 0.0473\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.3431 - accuracy: 0.0927\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.4383 - accuracy: 0.0509\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.2318 - accuracy: 0.0960\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.4003 - accuracy: 0.0483\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.2274 - accuracy: 0.0938\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.2505 - accuracy: 0.1290\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.9799 - accuracy: 0.5024\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.1740 - accuracy: 0.1386\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.9453 - accuracy: 0.5203\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.2182 - accuracy: 0.1409\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.9626 - accuracy: 0.5047\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.2058 - accuracy: 0.1502\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.9249 - accuracy: 0.5079\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.2137 - accuracy: 0.1371\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.9522 - accuracy: 0.5055\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 8.5014 - accuracy: 0.3600\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7488 - accuracy: 0.7801\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 8.4827 - accuracy: 0.3607\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7273 - accuracy: 0.7827\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 8.4744 - accuracy: 0.3649\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7414 - accuracy: 0.7752\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.4826 - accuracy: 0.3613\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7488 - accuracy: 0.7783\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.4933 - accuracy: 0.3615\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7582 - accuracy: 0.7776\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.8991 - accuracy: 0.2455\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.3157 - accuracy: 0.6261\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.8669 - accuracy: 0.2453\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.2988 - accuracy: 0.6333\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.8601 - accuracy: 0.2465\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.3283 - accuracy: 0.6218\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.8554 - accuracy: 0.2469\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.3144 - accuracy: 0.6294\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.8721 - accuracy: 0.2473\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.3242 - accuracy: 0.6249\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.4999 - accuracy: 0.3605\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7256 - accuracy: 0.7854\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.4761 - accuracy: 0.3625\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7781 - accuracy: 0.7646\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.5236 - accuracy: 0.3572\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7737 - accuracy: 0.7693\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.5488 - accuracy: 0.3579\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7696 - accuracy: 0.7758\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.4884 - accuracy: 0.3597\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7663 - accuracy: 0.7742\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.4957 - accuracy: 0.0481\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.1557 - accuracy: 0.1125\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.4410 - accuracy: 0.0595\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.1073 - accuracy: 0.1394\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.4033 - accuracy: 0.0508\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.1077 - accuracy: 0.1222\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.4831 - accuracy: 0.0398\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.1977 - accuracy: 0.1031\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 9.4686 - accuracy: 0.0499\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.1175 - accuracy: 0.1285\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.1111 - accuracy: 0.1552\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.7843 - accuracy: 0.5162\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.0664 - accuracy: 0.1558\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.7610 - accuracy: 0.5313\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.1598 - accuracy: 0.1610\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.7799 - accuracy: 0.5242\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.0787 - accuracy: 0.1656\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.7515 - accuracy: 0.5329\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.1654 - accuracy: 0.1562\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.7660 - accuracy: 0.5245\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 8.5464 - accuracy: 0.3559\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7547 - accuracy: 0.7750\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 8.5265 - accuracy: 0.3634\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7085 - accuracy: 0.7906\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 8.5182 - accuracy: 0.3591\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7575 - accuracy: 0.7728\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 8.4869 - accuracy: 0.3610\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7404 - accuracy: 0.7806\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 8.5176 - accuracy: 0.3615\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7485 - accuracy: 0.7784\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.9204 - accuracy: 0.2461\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.3113 - accuracy: 0.6341\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.9114 - accuracy: 0.2489\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.3090 - accuracy: 0.6325\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.9160 - accuracy: 0.2496\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.3268 - accuracy: 0.6266\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.9144 - accuracy: 0.2465\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.3207 - accuracy: 0.6257\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.8711 - accuracy: 0.2507\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.3246 - accuracy: 0.6212\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.5222 - accuracy: 0.3571\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7803 - accuracy: 0.7648\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.4929 - accuracy: 0.3598\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7686 - accuracy: 0.7707\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.6268 - accuracy: 0.3545\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7703 - accuracy: 0.7716\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.5448 - accuracy: 0.3568\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7661 - accuracy: 0.7742\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.5101 - accuracy: 0.3620\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.7857 - accuracy: 0.7648\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.5226 - accuracy: 0.0470\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 3.1421 - accuracy: 0.1116\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.4879 - accuracy: 0.0481\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.1381 - accuracy: 0.1197\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.4824 - accuracy: 0.0541\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.1077 - accuracy: 0.1246\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.4328 - accuracy: 0.0534\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.0844 - accuracy: 0.1303\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.4765 - accuracy: 0.0499\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.1558 - accuracy: 0.1271\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.1293 - accuracy: 0.1618\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.7565 - accuracy: 0.5295\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.1474 - accuracy: 0.1650\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.7476 - accuracy: 0.5388\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.1699 - accuracy: 0.1641\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.7560 - accuracy: 0.5348\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.1472 - accuracy: 0.1643\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.7624 - accuracy: 0.5217\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.1414 - accuracy: 0.1619\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 1.7723 - accuracy: 0.5339\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 8.5022 - accuracy: 0.3545\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.8781 - accuracy: 0.7402\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 8.5391 - accuracy: 0.3494\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.8906 - accuracy: 0.7317\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 8.5052 - accuracy: 0.3518\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.9103 - accuracy: 0.7239\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 8.5808 - accuracy: 0.3471\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.8696 - accuracy: 0.7405\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 8.5804 - accuracy: 0.3462\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.8849 - accuracy: 0.7366\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.2482 - accuracy: 0.1564\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 2.2391 - accuracy: 0.5277\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.2304 - accuracy: 0.1582\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 2.2296 - accuracy: 0.5211\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.2327 - accuracy: 0.1506\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 2.2497 - accuracy: 0.5086\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.1985 - accuracy: 0.1594\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 2.2402 - accuracy: 0.5233\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.2446 - accuracy: 0.1598\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 2.2529 - accuracy: 0.5221\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.5647 - accuracy: 0.3476\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.8884 - accuracy: 0.7310\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.5115 - accuracy: 0.3497\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.8638 - accuracy: 0.7446\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.4419 - accuracy: 0.3551\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.9080 - accuracy: 0.7303\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.5131 - accuracy: 0.3504\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.9049 - accuracy: 0.7273\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.5461 - accuracy: 0.3473\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.8837 - accuracy: 0.7386\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.5140 - accuracy: 0.0313\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.3352 - accuracy: 0.0448\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.5216 - accuracy: 0.0422\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.4056 - accuracy: 0.0507\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.4095 - accuracy: 0.0388\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.3008 - accuracy: 0.0599\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.4577 - accuracy: 0.0345\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.3611 - accuracy: 0.0469\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.5219 - accuracy: 0.0377\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.4017 - accuracy: 0.0540\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.3810 - accuracy: 0.0724\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 2.8755 - accuracy: 0.3144\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.3749 - accuracy: 0.0782\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 2.8662 - accuracy: 0.3387\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.3740 - accuracy: 0.0920\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 2.8558 - accuracy: 0.3368\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.2701 - accuracy: 0.0753\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 2.8720 - accuracy: 0.3321\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.3261 - accuracy: 0.0837\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 2.8351 - accuracy: 0.3230\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 8.4851 - accuracy: 0.3504\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.8699 - accuracy: 0.7424\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 8.5331 - accuracy: 0.3500\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.9005 - accuracy: 0.7274\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 8.4964 - accuracy: 0.3517\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.8841 - accuracy: 0.7378\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 8.4976 - accuracy: 0.3535\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.8938 - accuracy: 0.7366\n",
            "650/650 [==============================] - 2s 3ms/step - loss: 8.5467 - accuracy: 0.3476\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.8671 - accuracy: 0.7423\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.2354 - accuracy: 0.1524\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 2.2411 - accuracy: 0.5085\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.2691 - accuracy: 0.1557\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 2.2316 - accuracy: 0.5242\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.2415 - accuracy: 0.1611\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 2.2383 - accuracy: 0.5121\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.1808 - accuracy: 0.1695\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 2.2097 - accuracy: 0.5287\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.1676 - accuracy: 0.1622\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 2.2401 - accuracy: 0.5169\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.5629 - accuracy: 0.3453\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.9273 - accuracy: 0.7240\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.5296 - accuracy: 0.3507\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.8631 - accuracy: 0.7452\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.5599 - accuracy: 0.3479\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.9016 - accuracy: 0.7354\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.5469 - accuracy: 0.3473\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.8954 - accuracy: 0.7355\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 8.5779 - accuracy: 0.3450\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.8891 - accuracy: 0.7378\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.4878 - accuracy: 0.0300\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.4188 - accuracy: 0.0288\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.4167 - accuracy: 0.0383\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.3390 - accuracy: 0.0449\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.4463 - accuracy: 0.0449\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.3234 - accuracy: 0.0727\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.4016 - accuracy: 0.0413\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.2783 - accuracy: 0.0618\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.4298 - accuracy: 0.0491\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 3.3279 - accuracy: 0.0796\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.2973 - accuracy: 0.0858\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 2.8292 - accuracy: 0.3400\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.3762 - accuracy: 0.0766\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 2.8659 - accuracy: 0.3203\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.3272 - accuracy: 0.0862\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 2.8413 - accuracy: 0.3310\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.3458 - accuracy: 0.0806\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 2.8484 - accuracy: 0.3388\n",
            "650/650 [==============================] - 2s 2ms/step - loss: 9.3645 - accuracy: 0.0843\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 2.8454 - accuracy: 0.3387\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.9934 - accuracy: 0.5813\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.8370\n",
            "325/325 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.5479\n",
            "82/82 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.9765 - accuracy: 0.5816\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.8316\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.9060 - accuracy: 0.5852\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5595 - accuracy: 0.8293\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.9977 - accuracy: 0.5841\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5733 - accuracy: 0.8335\n",
            "325/325 [==============================] - 1s 2ms/step - loss: 4.9679 - accuracy: 0.3009\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 1.3601 - accuracy: 0.6289\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.0905 - accuracy: 0.2934\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.3562 - accuracy: 0.6349\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.9936 - accuracy: 0.3101\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.3684 - accuracy: 0.6273\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.0222 - accuracy: 0.3087\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.3523 - accuracy: 0.6329\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.0426 - accuracy: 0.3007\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 1.3645 - accuracy: 0.6325\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.9653 - accuracy: 0.5770\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.5600 - accuracy: 0.8352\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.9842 - accuracy: 0.5766\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.8305\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.9471 - accuracy: 0.5786\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.5909 - accuracy: 0.8245\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.9989 - accuracy: 0.5739\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.8347\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.9749 - accuracy: 0.5754\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.8254\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.8352 - accuracy: 0.0558\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.2706 - accuracy: 0.0939\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.9284 - accuracy: 0.0505\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.3539 - accuracy: 0.0813\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.8360 - accuracy: 0.0520\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.2904 - accuracy: 0.0899\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.9234 - accuracy: 0.0408\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.3556 - accuracy: 0.0674\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.9233 - accuracy: 0.0395\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.4095 - accuracy: 0.0624\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.5284 - accuracy: 0.1488\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 2.0707 - accuracy: 0.4723\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.4508 - accuracy: 0.1805\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.0012 - accuracy: 0.5031\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.5147 - accuracy: 0.1675\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.0340 - accuracy: 0.4883\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.4903 - accuracy: 0.1573\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 2.0421 - accuracy: 0.4893\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.4672 - accuracy: 0.1657\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 2.0456 - accuracy: 0.4835\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.9751 - accuracy: 0.5852\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.8401\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.9353 - accuracy: 0.5859\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5568 - accuracy: 0.8316\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.0114 - accuracy: 0.5816\n",
            "82/82 [==============================] - 1s 2ms/step - loss: 0.5967 - accuracy: 0.8172\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.9364 - accuracy: 0.5866\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5868 - accuracy: 0.8204\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.9993 - accuracy: 0.5820\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5632 - accuracy: 0.8320\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.0265 - accuracy: 0.2957\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.3656 - accuracy: 0.6320\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.0664 - accuracy: 0.2957\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 1.3449 - accuracy: 0.6367\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.0236 - accuracy: 0.3067\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 1.3751 - accuracy: 0.6268\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.0116 - accuracy: 0.3021\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 1.3557 - accuracy: 0.6330\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.0248 - accuracy: 0.3056\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.3628 - accuracy: 0.6338\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.9539 - accuracy: 0.5762\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.5454 - accuracy: 0.8372\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.0175 - accuracy: 0.5721\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.5305 - accuracy: 0.8429\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 3.9930 - accuracy: 0.5747\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.5971 - accuracy: 0.8245\n",
            "325/325 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.5736\n",
            "82/82 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "325/325 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.4942\n",
            "82/82 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.8742 - accuracy: 0.0362\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 3.3828 - accuracy: 0.0614\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.8934 - accuracy: 0.0325\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.3711 - accuracy: 0.0590\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.8381 - accuracy: 0.0427\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.3499 - accuracy: 0.0691\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.9971 - accuracy: 0.0384\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.4260 - accuracy: 0.0637\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.9549 - accuracy: 0.0485\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.4154 - accuracy: 0.0783\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.5266 - accuracy: 0.1530\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 2.0443 - accuracy: 0.4761\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.5658 - accuracy: 0.1377\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 2.0509 - accuracy: 0.4871\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.4368 - accuracy: 0.1671\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 2.0491 - accuracy: 0.4779\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.4268 - accuracy: 0.1734\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.0333 - accuracy: 0.4913\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 5.5461 - accuracy: 0.1562\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.0558 - accuracy: 0.4886\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.1101 - accuracy: 0.5449\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.6529 - accuracy: 0.8055\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.0241 - accuracy: 0.5539\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.6412 - accuracy: 0.8093\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.0804 - accuracy: 0.5493\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.6683 - accuracy: 0.8047\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.0520 - accuracy: 0.5496\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.6692 - accuracy: 0.8057\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.0890 - accuracy: 0.5475\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6784 - accuracy: 0.8016\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.9234 - accuracy: 0.3236\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.3280 - accuracy: 0.6245\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.8616 - accuracy: 0.3324\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.3219 - accuracy: 0.6282\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.9423 - accuracy: 0.3331\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.3406 - accuracy: 0.6217\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.9260 - accuracy: 0.3295\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.3358 - accuracy: 0.6263\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.9259 - accuracy: 0.3232\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.3450 - accuracy: 0.6225\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.0664 - accuracy: 0.5464\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.6575 - accuracy: 0.8099\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.1404 - accuracy: 0.5430\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.6826 - accuracy: 0.8005\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.0917 - accuracy: 0.5450\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.6952 - accuracy: 0.7939\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.0986 - accuracy: 0.5427\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.7973\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.0689 - accuracy: 0.5434\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.6747 - accuracy: 0.8077\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.8975 - accuracy: 0.0463\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.2788 - accuracy: 0.0871\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.8453 - accuracy: 0.0495\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 3.2295 - accuracy: 0.0886\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.7194 - accuracy: 0.0554\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.1301 - accuracy: 0.1053\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.7374 - accuracy: 0.0627\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.1490 - accuracy: 0.1167\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.8048 - accuracy: 0.0499\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 3.1827 - accuracy: 0.1061\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.3324 - accuracy: 0.1874\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.8264 - accuracy: 0.5145\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.3117 - accuracy: 0.1916\n",
            "82/82 [==============================] - 1s 3ms/step - loss: 1.8139 - accuracy: 0.5121\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.3929 - accuracy: 0.1838\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 1.8537 - accuracy: 0.5088\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.3496 - accuracy: 0.1770\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.8316 - accuracy: 0.5179\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.3732 - accuracy: 0.1906\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 1.8245 - accuracy: 0.5152\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.0713 - accuracy: 0.5482\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6500 - accuracy: 0.8032\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.0121 - accuracy: 0.5492\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6550 - accuracy: 0.8046\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.0690 - accuracy: 0.5461\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6612 - accuracy: 0.8034\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.0187 - accuracy: 0.5532\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.8075\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.0780 - accuracy: 0.5460\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6569 - accuracy: 0.8087\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.9355 - accuracy: 0.3288\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.3306 - accuracy: 0.6250\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.9412 - accuracy: 0.3227\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 1.3245 - accuracy: 0.6291\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.8795 - accuracy: 0.3234\n",
            "82/82 [==============================] - 1s 2ms/step - loss: 1.3468 - accuracy: 0.6226\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.8730 - accuracy: 0.3221\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.3378 - accuracy: 0.6271\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.8011 - accuracy: 0.3360\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 1.3368 - accuracy: 0.6255\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.1241 - accuracy: 0.5444\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.6675 - accuracy: 0.8031\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.0985 - accuracy: 0.5470\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.6685 - accuracy: 0.8045\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.0996 - accuracy: 0.5447\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.7015 - accuracy: 0.7934\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.0592 - accuracy: 0.5468\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6665 - accuracy: 0.8073\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.0667 - accuracy: 0.5455\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.6834 - accuracy: 0.8024\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.7700 - accuracy: 0.0555\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 3.1623 - accuracy: 0.1004\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.7799 - accuracy: 0.0592\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.1576 - accuracy: 0.1138\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.8452 - accuracy: 0.0416\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.2271 - accuracy: 0.0726\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.9028 - accuracy: 0.0372\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.2986 - accuracy: 0.0708\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.8783 - accuracy: 0.0369\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.2806 - accuracy: 0.0762\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.3253 - accuracy: 0.1966\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.8413 - accuracy: 0.5076\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.3506 - accuracy: 0.2002\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.8158 - accuracy: 0.5132\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.3619 - accuracy: 0.1869\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.8416 - accuracy: 0.5083\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.2636 - accuracy: 0.1999\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.8098 - accuracy: 0.5175\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.3716 - accuracy: 0.1921\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.8193 - accuracy: 0.5198\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.1778 - accuracy: 0.5221\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.8119 - accuracy: 0.7629\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.1606 - accuracy: 0.5212\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.8136 - accuracy: 0.7647\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.1982 - accuracy: 0.5157\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.8432 - accuracy: 0.7540\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.1675 - accuracy: 0.5216\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.8238 - accuracy: 0.7620\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 4.2057 - accuracy: 0.5168\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.8388 - accuracy: 0.7569\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.4499 - accuracy: 0.1909\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.3260 - accuracy: 0.4960\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.5186 - accuracy: 0.1911\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.3346 - accuracy: 0.5044\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.5073 - accuracy: 0.1682\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.3626 - accuracy: 0.4892\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.4501 - accuracy: 0.1999\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 2.3231 - accuracy: 0.5084\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.5098 - accuracy: 0.1777\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.3465 - accuracy: 0.5044\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.2175 - accuracy: 0.5106\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.8509 - accuracy: 0.7506\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.1774 - accuracy: 0.5140\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.8277 - accuracy: 0.7587\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.2568 - accuracy: 0.5114\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.8684 - accuracy: 0.7446\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.1973 - accuracy: 0.5091\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.8583 - accuracy: 0.7464\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 4.2574 - accuracy: 0.5070\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.8476 - accuracy: 0.7563\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.8262 - accuracy: 0.0406\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.3573 - accuracy: 0.0428\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.8634 - accuracy: 0.0393\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.4305 - accuracy: 0.0412\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.8897 - accuracy: 0.0422\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 3.4254 - accuracy: 0.0471\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.8878 - accuracy: 0.0433\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.4443 - accuracy: 0.0594\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.8093 - accuracy: 0.0432\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.3624 - accuracy: 0.0563\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.6499 - accuracy: 0.1004\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.8883 - accuracy: 0.3089\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.6401 - accuracy: 0.0846\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.9085 - accuracy: 0.2981\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.6672 - accuracy: 0.0972\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.8909 - accuracy: 0.3140\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.6155 - accuracy: 0.0871\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.9088 - accuracy: 0.3040\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.6273 - accuracy: 0.0834\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 2.9217 - accuracy: 0.2966\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.1657 - accuracy: 0.5230\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.8407 - accuracy: 0.7510\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 4.1070 - accuracy: 0.5221\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.8367 - accuracy: 0.7526\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.0860 - accuracy: 0.5203\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.8602 - accuracy: 0.7429\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.2068 - accuracy: 0.5151\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.8393 - accuracy: 0.7563\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.1560 - accuracy: 0.5188\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.8499 - accuracy: 0.7510\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.4563 - accuracy: 0.1957\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.3189 - accuracy: 0.5058\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.4828 - accuracy: 0.1800\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.3425 - accuracy: 0.5138\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.4910 - accuracy: 0.1869\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.3502 - accuracy: 0.4944\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.4733 - accuracy: 0.1927\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 2.3304 - accuracy: 0.4961\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.4984 - accuracy: 0.1869\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.3368 - accuracy: 0.5051\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.1785 - accuracy: 0.5121\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.8410 - accuracy: 0.7577\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.2379 - accuracy: 0.5098\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.8433 - accuracy: 0.7571\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.2631 - accuracy: 0.5087\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.8659 - accuracy: 0.7480\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.2409 - accuracy: 0.5076\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.8546 - accuracy: 0.7500\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 4.2256 - accuracy: 0.5105\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.8497 - accuracy: 0.7505\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.8787 - accuracy: 0.0353\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.4395 - accuracy: 0.0417\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.9760 - accuracy: 0.0512\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 3.4647 - accuracy: 0.0621\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.9589 - accuracy: 0.0408\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.5062 - accuracy: 0.0518\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.8374 - accuracy: 0.0435\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 3.3782 - accuracy: 0.0509\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.8629 - accuracy: 0.0504\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.3531 - accuracy: 0.0585\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.6045 - accuracy: 0.0925\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.8886 - accuracy: 0.3088\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.6764 - accuracy: 0.0881\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.9037 - accuracy: 0.2951\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.7115 - accuracy: 0.0798\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.9308 - accuracy: 0.2902\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.6783 - accuracy: 0.0812\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.9219 - accuracy: 0.2697\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 5.6673 - accuracy: 0.0878\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 2.9182 - accuracy: 0.2930\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.5166 - accuracy: 0.3742\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.7004 - accuracy: 0.7980\n",
            "325/325 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.2903\n",
            "82/82 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.4241 - accuracy: 0.3786\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.6969 - accuracy: 0.7975\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.4830 - accuracy: 0.3759\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.7076 - accuracy: 0.7917\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.5000 - accuracy: 0.3740\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.7017 - accuracy: 0.7960\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.0991 - accuracy: 0.1794\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.6429 - accuracy: 0.5804\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.0784 - accuracy: 0.1795\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.6380 - accuracy: 0.5837\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.1247 - accuracy: 0.1744\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.6663 - accuracy: 0.5689\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.1048 - accuracy: 0.1814\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.6310 - accuracy: 0.5779\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.0541 - accuracy: 0.1867\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.6334 - accuracy: 0.5833\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.5226 - accuracy: 0.3673\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.6853 - accuracy: 0.7944\n",
            "325/325 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.3292\n",
            "82/82 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.4615 - accuracy: 0.3704\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.6895 - accuracy: 0.7955\n",
            "325/325 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.3690\n",
            "82/82 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.5002 - accuracy: 0.3681\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.7035 - accuracy: 0.7925\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.4922 - accuracy: 0.0494\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.4117 - accuracy: 0.0761\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.5114 - accuracy: 0.0392\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.4996 - accuracy: 0.0642\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.5119 - accuracy: 0.0400\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.4640 - accuracy: 0.0552\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.4711 - accuracy: 0.0440\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.4578 - accuracy: 0.0710\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.5016 - accuracy: 0.0473\n",
            "82/82 [==============================] - 1s 3ms/step - loss: 3.3955 - accuracy: 0.0770\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.3441 - accuracy: 0.0947\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.4316 - accuracy: 0.3801\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.3485 - accuracy: 0.0936\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 2.3822 - accuracy: 0.3935\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.3145 - accuracy: 0.0993\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.4225 - accuracy: 0.3692\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.2866 - accuracy: 0.1012\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.3955 - accuracy: 0.3808\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.3202 - accuracy: 0.0953\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 2.3917 - accuracy: 0.3757\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.4772 - accuracy: 0.3762\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6851 - accuracy: 0.8053\n",
            "325/325 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.3780\n",
            "82/82 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.4416 - accuracy: 0.3798\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.7027 - accuracy: 0.7942\n",
            "325/325 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.3708\n",
            "82/82 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.5051 - accuracy: 0.3748\n",
            "82/82 [==============================] - 1s 3ms/step - loss: 0.6944 - accuracy: 0.7959\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.0665 - accuracy: 0.1784\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.6460 - accuracy: 0.5705\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.1271 - accuracy: 0.1708\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.6552 - accuracy: 0.5763\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.1032 - accuracy: 0.1818\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.6491 - accuracy: 0.5748\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.0434 - accuracy: 0.1982\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.6188 - accuracy: 0.5831\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.1290 - accuracy: 0.1828\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 1.6396 - accuracy: 0.5820\n",
            "325/325 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.3700\n",
            "82/82 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.4743 - accuracy: 0.3706\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.6874 - accuracy: 0.7940\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.4957 - accuracy: 0.3686\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.7127 - accuracy: 0.7909\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.4180 - accuracy: 0.3757\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.6843 - accuracy: 0.8004\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.4829 - accuracy: 0.3688\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.6974 - accuracy: 0.7974\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.5238 - accuracy: 0.0358\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.4319 - accuracy: 0.0551\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 9.4674 - accuracy: 0.0425\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.3657 - accuracy: 0.0629\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.5113 - accuracy: 0.0411\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.4149 - accuracy: 0.0640\n",
            "325/325 [==============================] - 1s 3ms/step - loss: nan - accuracy: 0.0379\n",
            "82/82 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.5522 - accuracy: 0.0399\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 3.4767 - accuracy: 0.0662\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.2957 - accuracy: 0.0938\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.4057 - accuracy: 0.3777\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.2792 - accuracy: 0.0952\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.4130 - accuracy: 0.3815\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.4032 - accuracy: 0.0933\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.4337 - accuracy: 0.3709\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.3117 - accuracy: 0.0923\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.4106 - accuracy: 0.3776\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.2874 - accuracy: 0.0861\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.4623 - accuracy: 0.3642\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.5068 - accuracy: 0.3595\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.8013 - accuracy: 0.7571\n",
            "325/325 [==============================] - 2s 4ms/step - loss: 8.5658 - accuracy: 0.3567\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.7807 - accuracy: 0.7673\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.4866 - accuracy: 0.3595\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.7993 - accuracy: 0.7663\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.5177 - accuracy: 0.3597\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.8301 - accuracy: 0.7558\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.4683 - accuracy: 0.3597\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.7822 - accuracy: 0.7679\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.0296 - accuracy: 0.1982\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.5407 - accuracy: 0.5774\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.9716 - accuracy: 0.2018\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 1.5329 - accuracy: 0.5815\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.0538 - accuracy: 0.1934\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.5498 - accuracy: 0.5734\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.0277 - accuracy: 0.1902\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.5490 - accuracy: 0.5730\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.0163 - accuracy: 0.1913\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.5572 - accuracy: 0.5802\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.4908 - accuracy: 0.3569\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.8091 - accuracy: 0.7640\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.4840 - accuracy: 0.3558\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.8015 - accuracy: 0.7601\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.5071 - accuracy: 0.3572\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.8321 - accuracy: 0.7568\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.5168 - accuracy: 0.3540\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.8297 - accuracy: 0.7531\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.4903 - accuracy: 0.3576\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.7971 - accuracy: 0.7650\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.4338 - accuracy: 0.0361\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.3001 - accuracy: 0.0661\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.4600 - accuracy: 0.0530\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.2826 - accuracy: 0.0936\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.4218 - accuracy: 0.0490\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.2434 - accuracy: 0.0831\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.4879 - accuracy: 0.0458\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.3050 - accuracy: 0.0816\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.4269 - accuracy: 0.0633\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.2255 - accuracy: 0.1130\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.2247 - accuracy: 0.1099\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.1498 - accuracy: 0.4230\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.2488 - accuracy: 0.1077\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.1599 - accuracy: 0.4242\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.2744 - accuracy: 0.1133\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.1487 - accuracy: 0.4279\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.2881 - accuracy: 0.1031\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.1819 - accuracy: 0.4109\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 9.3609 - accuracy: 0.0966\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.2030 - accuracy: 0.4209\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.5049 - accuracy: 0.3552\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.8310 - accuracy: 0.7554\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.6338 - accuracy: 0.3520\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.8250 - accuracy: 0.7552\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.5435 - accuracy: 0.3555\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.8260 - accuracy: 0.7564\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.5321 - accuracy: 0.3567\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.7831 - accuracy: 0.7686\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.5601 - accuracy: 0.3564\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.7988 - accuracy: 0.7644\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.0378 - accuracy: 0.2031\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.5354 - accuracy: 0.5783\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.9625 - accuracy: 0.2107\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.5004 - accuracy: 0.5941\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.0709 - accuracy: 0.1942\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.5691 - accuracy: 0.5680\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.0835 - accuracy: 0.1946\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.5473 - accuracy: 0.5819\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.0462 - accuracy: 0.1881\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 1.5543 - accuracy: 0.5738\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.5595 - accuracy: 0.3530\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.8235 - accuracy: 0.7544\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.5295 - accuracy: 0.3550\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.8129 - accuracy: 0.7589\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.5309 - accuracy: 0.3544\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.8159 - accuracy: 0.7615\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.4998 - accuracy: 0.3531\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.8298 - accuracy: 0.7576\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.5381 - accuracy: 0.3535\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.8127 - accuracy: 0.7601\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.4444 - accuracy: 0.0560\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.1996 - accuracy: 0.1025\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.4864 - accuracy: 0.0422\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.2775 - accuracy: 0.0841\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.4604 - accuracy: 0.0523\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.2267 - accuracy: 0.0992\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.4484 - accuracy: 0.0477\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.2545 - accuracy: 0.0793\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.4264 - accuracy: 0.0507\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.2293 - accuracy: 0.0908\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.2946 - accuracy: 0.1119\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.1275 - accuracy: 0.4333\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.2193 - accuracy: 0.1205\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.1412 - accuracy: 0.4389\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.2495 - accuracy: 0.1128\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.1656 - accuracy: 0.4255\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.2844 - accuracy: 0.1075\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.1520 - accuracy: 0.4269\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.2891 - accuracy: 0.1103\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.1861 - accuracy: 0.4166\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.5583 - accuracy: 0.3472\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.9583 - accuracy: 0.7190\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.5818 - accuracy: 0.3418\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.9179 - accuracy: 0.7245\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.5832 - accuracy: 0.3438\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.9593 - accuracy: 0.7165\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.5115 - accuracy: 0.3455\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.9220 - accuracy: 0.7249\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.6168 - accuracy: 0.3411\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.9232 - accuracy: 0.7258\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.2787 - accuracy: 0.1181\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.6291 - accuracy: 0.4334\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.2911 - accuracy: 0.1215\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.6126 - accuracy: 0.4279\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.2715 - accuracy: 0.1178\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.6300 - accuracy: 0.4208\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.3531 - accuracy: 0.0998\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.6610 - accuracy: 0.4007\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.3986 - accuracy: 0.1046\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.6559 - accuracy: 0.4135\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.5845 - accuracy: 0.3391\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.9364 - accuracy: 0.7221\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.5811 - accuracy: 0.3366\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.9355 - accuracy: 0.7189\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.6082 - accuracy: 0.3403\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.9684 - accuracy: 0.7104\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.6015 - accuracy: 0.3390\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.9209 - accuracy: 0.7289\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.5722 - accuracy: 0.3394\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.9712 - accuracy: 0.7086\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.4874 - accuracy: 0.0368\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.4070 - accuracy: 0.0398\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.5772 - accuracy: 0.0254\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.5594 - accuracy: 0.0292\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.4862 - accuracy: 0.0429\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.4259 - accuracy: 0.0555\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.5262 - accuracy: 0.0342\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.5415 - accuracy: 0.0365\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.4269 - accuracy: 0.0360\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.4371 - accuracy: 0.0392\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.4044 - accuracy: 0.0438\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.0870 - accuracy: 0.1726\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.3147 - accuracy: 0.0611\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.0548 - accuracy: 0.2092\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.3783 - accuracy: 0.0527\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.0578 - accuracy: 0.1811\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.4080 - accuracy: 0.0571\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.0536 - accuracy: 0.2053\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.3004 - accuracy: 0.0589\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.0533 - accuracy: 0.1912\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.5799 - accuracy: 0.3462\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.9275 - accuracy: 0.7238\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.5126 - accuracy: 0.3481\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.9152 - accuracy: 0.7223\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 8.5688 - accuracy: 0.3446\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.9540 - accuracy: 0.7115\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.5784 - accuracy: 0.3424\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.9362 - accuracy: 0.7249\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.5885 - accuracy: 0.3428\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.9412 - accuracy: 0.7207\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.2956 - accuracy: 0.1083\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.6405 - accuracy: 0.4195\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.4051 - accuracy: 0.0965\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.6595 - accuracy: 0.4274\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.2889 - accuracy: 0.1161\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.6368 - accuracy: 0.4046\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.3340 - accuracy: 0.1038\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.6550 - accuracy: 0.4238\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.2797 - accuracy: 0.1191\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 2.6157 - accuracy: 0.4325\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.5625 - accuracy: 0.3411\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.9331 - accuracy: 0.7251\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.5698 - accuracy: 0.3379\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.9389 - accuracy: 0.7228\n",
            "325/325 [==============================] - 2s 3ms/step - loss: 8.6521 - accuracy: 0.3380\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.9521 - accuracy: 0.7151\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.5253 - accuracy: 0.3392\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.9303 - accuracy: 0.7257\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 8.6004 - accuracy: 0.3384\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 0.9588 - accuracy: 0.7229\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.5498 - accuracy: 0.0394\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.4344 - accuracy: 0.0468\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.5661 - accuracy: 0.0382\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.4897 - accuracy: 0.0398\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.4347 - accuracy: 0.0401\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.4522 - accuracy: 0.0399\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.4495 - accuracy: 0.0351\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 3.4320 - accuracy: 0.0348\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.4856 - accuracy: 0.0410\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.3734 - accuracy: 0.0497\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.3480 - accuracy: 0.0647\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.0453 - accuracy: 0.2053\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.3896 - accuracy: 0.0446\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.1013 - accuracy: 0.1604\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.3522 - accuracy: 0.0609\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.0582 - accuracy: 0.1926\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.3538 - accuracy: 0.0580\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.0545 - accuracy: 0.1829\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 9.3998 - accuracy: 0.0631\n",
            "82/82 [==============================] - 0s 3ms/step - loss: 3.0514 - accuracy: 0.2045\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 4.0231 - accuracy: 0.5658\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5785 - accuracy: 0.8264\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.0389 - accuracy: 0.5667\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5926 - accuracy: 0.8157\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 3.9612 - accuracy: 0.5699\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5989 - accuracy: 0.8200\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 3.9708 - accuracy: 0.5707\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5939 - accuracy: 0.8207\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.0317 - accuracy: 0.5708\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.6184 - accuracy: 0.8128\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.3375 - accuracy: 0.2167\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.7253 - accuracy: 0.5583\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.3392 - accuracy: 0.2079\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.7150 - accuracy: 0.5631\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.2512 - accuracy: 0.2255\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.7137 - accuracy: 0.5652\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.3124 - accuracy: 0.2130\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.7227 - accuracy: 0.5593\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.3560 - accuracy: 0.2084\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.7196 - accuracy: 0.5612\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.0874 - accuracy: 0.5468\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5771 - accuracy: 0.8284\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.0926 - accuracy: 0.5470\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5620 - accuracy: 0.8317\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.1119 - accuracy: 0.5514\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5908 - accuracy: 0.8246\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.1128 - accuracy: 0.5455\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.5684 - accuracy: 0.8281\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.0390 - accuracy: 0.5525\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5827 - accuracy: 0.8294\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.8700 - accuracy: 0.0495\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.3923 - accuracy: 0.0608\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 6.0114 - accuracy: 0.0425\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.6424 - accuracy: 0.0550\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.9688 - accuracy: 0.0273\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.5620 - accuracy: 0.0375\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.9915 - accuracy: 0.0414\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.5781 - accuracy: 0.0611\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.9720 - accuracy: 0.0324\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.5992 - accuracy: 0.0421\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.6337 - accuracy: 0.1045\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.5102 - accuracy: 0.3399\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.6425 - accuracy: 0.1069\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.5077 - accuracy: 0.3486\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.6321 - accuracy: 0.1050\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.5064 - accuracy: 0.3448\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.6085 - accuracy: 0.1132\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.4886 - accuracy: 0.3401\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.6733 - accuracy: 0.0982\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.5137 - accuracy: 0.3483\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.0364 - accuracy: 0.5633\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.6351 - accuracy: 0.8033\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.0119 - accuracy: 0.5678\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5874 - accuracy: 0.8232\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 4.0048 - accuracy: 0.5696\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.6189 - accuracy: 0.8130\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.0196 - accuracy: 0.5687\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.6245 - accuracy: 0.8096\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 3.9932 - accuracy: 0.5678\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.6239 - accuracy: 0.8114\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.3927 - accuracy: 0.2148\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.7057 - accuracy: 0.5582\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.2664 - accuracy: 0.2150\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.6884 - accuracy: 0.5714\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.3312 - accuracy: 0.2069\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.7350 - accuracy: 0.5532\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.3142 - accuracy: 0.2156\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.7052 - accuracy: 0.5602\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.3024 - accuracy: 0.2111\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.7215 - accuracy: 0.5583\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.1130 - accuracy: 0.5480\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5635 - accuracy: 0.8329\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.0567 - accuracy: 0.5531\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5650 - accuracy: 0.8343\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.1028 - accuracy: 0.5513\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5869 - accuracy: 0.8253\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.0752 - accuracy: 0.5516\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.5565 - accuracy: 0.8331\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.0605 - accuracy: 0.5507\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5993 - accuracy: 0.8216\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.8497 - accuracy: 0.0431\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.3662 - accuracy: 0.0608\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.9644 - accuracy: 0.0366\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.4762 - accuracy: 0.0486\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.9192 - accuracy: 0.0500\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.4828 - accuracy: 0.0666\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 6.0270 - accuracy: 0.0234\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.5947 - accuracy: 0.0353\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.9143 - accuracy: 0.0446\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.4857 - accuracy: 0.0538\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.6794 - accuracy: 0.0908\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.5334 - accuracy: 0.3295\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.6891 - accuracy: 0.0952\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.5460 - accuracy: 0.3433\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.6823 - accuracy: 0.1025\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.5435 - accuracy: 0.3505\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.6897 - accuracy: 0.1082\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.5081 - accuracy: 0.3436\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.6454 - accuracy: 0.1079\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.4941 - accuracy: 0.3603\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.1426 - accuracy: 0.5300\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.7744 - accuracy: 0.7685\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 4.1407 - accuracy: 0.5305\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.7511 - accuracy: 0.7804\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.1158 - accuracy: 0.5310\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.7592 - accuracy: 0.7744\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.1367 - accuracy: 0.5290\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.7425 - accuracy: 0.7834\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.1468 - accuracy: 0.5317\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.7557 - accuracy: 0.7809\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.2066 - accuracy: 0.2302\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.5757 - accuracy: 0.5694\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.1766 - accuracy: 0.2452\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.5685 - accuracy: 0.5756\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.2307 - accuracy: 0.2361\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.6074 - accuracy: 0.5589\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.1407 - accuracy: 0.2393\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.5871 - accuracy: 0.5701\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.1365 - accuracy: 0.2453\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.5975 - accuracy: 0.5670\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.1368 - accuracy: 0.5287\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.7602 - accuracy: 0.7776\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.1761 - accuracy: 0.5256\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.7593 - accuracy: 0.7806\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.1397 - accuracy: 0.5263\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.7716 - accuracy: 0.7775\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.1480 - accuracy: 0.5261\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.7680 - accuracy: 0.7814\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.1741 - accuracy: 0.5240\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.7757 - accuracy: 0.7782\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.9810 - accuracy: 0.0336\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.4420 - accuracy: 0.0506\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.8462 - accuracy: 0.0491\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.3549 - accuracy: 0.0752\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.9320 - accuracy: 0.0403\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.4155 - accuracy: 0.0626\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.8403 - accuracy: 0.0467\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.3064 - accuracy: 0.0708\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.9026 - accuracy: 0.0357\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.4204 - accuracy: 0.0531\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.5593 - accuracy: 0.1206\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.2397 - accuracy: 0.4046\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.5677 - accuracy: 0.1226\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.2774 - accuracy: 0.3826\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.5593 - accuracy: 0.1194\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.2746 - accuracy: 0.3957\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.4992 - accuracy: 0.1373\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.2366 - accuracy: 0.3972\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.6016 - accuracy: 0.1172\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.2742 - accuracy: 0.3912\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.1224 - accuracy: 0.5346\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.7467 - accuracy: 0.7807\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.1046 - accuracy: 0.5305\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.7630 - accuracy: 0.7730\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 4.1569 - accuracy: 0.5308\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.7836 - accuracy: 0.7699\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.1335 - accuracy: 0.5302\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.7696 - accuracy: 0.7768\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 4.1894 - accuracy: 0.5300\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.7669 - accuracy: 0.7735\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.2270 - accuracy: 0.2347\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.5832 - accuracy: 0.5712\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.1196 - accuracy: 0.2552\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.5551 - accuracy: 0.5751\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.1730 - accuracy: 0.2471\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.5776 - accuracy: 0.5712\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.1651 - accuracy: 0.2484\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.5806 - accuracy: 0.5736\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.1272 - accuracy: 0.2474\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.5758 - accuracy: 0.5747\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.1726 - accuracy: 0.5235\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.7479 - accuracy: 0.7838\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.1392 - accuracy: 0.5273\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.7443 - accuracy: 0.7871\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.1831 - accuracy: 0.5256\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.7720 - accuracy: 0.7778\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.1354 - accuracy: 0.5260\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.7532 - accuracy: 0.7842\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.2043 - accuracy: 0.5242\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.7585 - accuracy: 0.7833\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.8355 - accuracy: 0.0409\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.3522 - accuracy: 0.0618\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.7941 - accuracy: 0.0595\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.3266 - accuracy: 0.0876\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.8841 - accuracy: 0.0375\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.4421 - accuracy: 0.0571\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.8090 - accuracy: 0.0562\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.3071 - accuracy: 0.0861\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.8421 - accuracy: 0.0451\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.3793 - accuracy: 0.0665\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.4391 - accuracy: 0.1555\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.2150 - accuracy: 0.3954\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.5212 - accuracy: 0.1364\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.2503 - accuracy: 0.4074\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.6267 - accuracy: 0.1246\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.2892 - accuracy: 0.3914\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.5968 - accuracy: 0.1121\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.2716 - accuracy: 0.3997\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.5960 - accuracy: 0.1124\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.2874 - accuracy: 0.3954\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 4.2157 - accuracy: 0.5003\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.9268 - accuracy: 0.7307\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 4.2389 - accuracy: 0.4961\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.8971 - accuracy: 0.7364\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 4.2682 - accuracy: 0.4975\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.9349 - accuracy: 0.7236\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.2915 - accuracy: 0.4978\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.9301 - accuracy: 0.7210\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 4.2611 - accuracy: 0.4971\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.9733 - accuracy: 0.7086\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.5542 - accuracy: 0.1124\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.7361 - accuracy: 0.3919\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.5967 - accuracy: 0.1238\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.7157 - accuracy: 0.3865\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.6496 - accuracy: 0.1049\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.7319 - accuracy: 0.3931\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.5385 - accuracy: 0.1309\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.6971 - accuracy: 0.3917\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.5827 - accuracy: 0.1088\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.7274 - accuracy: 0.3819\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.3059 - accuracy: 0.4871\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.9218 - accuracy: 0.7326\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.3119 - accuracy: 0.4858\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.9281 - accuracy: 0.7253\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.3395 - accuracy: 0.4821\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.9352 - accuracy: 0.7272\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.3289 - accuracy: 0.4852\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.9350 - accuracy: 0.7292\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.3688 - accuracy: 0.4789\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.9395 - accuracy: 0.7271\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.8864 - accuracy: 0.0409\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.5057 - accuracy: 0.0449\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.8269 - accuracy: 0.0312\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.3825 - accuracy: 0.0320\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.8631 - accuracy: 0.0220\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.4135 - accuracy: 0.0237\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.7668 - accuracy: 0.0447\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.3644 - accuracy: 0.0517\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.9199 - accuracy: 0.0430\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.5248 - accuracy: 0.0438\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.7370 - accuracy: 0.0635\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.0858 - accuracy: 0.1729\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.7042 - accuracy: 0.0608\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.0772 - accuracy: 0.1936\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.7234 - accuracy: 0.0548\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.1087 - accuracy: 0.1588\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.7214 - accuracy: 0.0534\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.0895 - accuracy: 0.1810\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.6730 - accuracy: 0.0552\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.1078 - accuracy: 0.1624\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 4.2397 - accuracy: 0.5003\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.9086 - accuracy: 0.7308\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 4.2454 - accuracy: 0.4947\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.9316 - accuracy: 0.7209\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 4.2447 - accuracy: 0.4980\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.9206 - accuracy: 0.7268\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.2461 - accuracy: 0.4997\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.9269 - accuracy: 0.7287\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.2716 - accuracy: 0.4984\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.9540 - accuracy: 0.7207\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.6219 - accuracy: 0.1058\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.7397 - accuracy: 0.3831\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.5807 - accuracy: 0.1204\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.7198 - accuracy: 0.3929\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.6044 - accuracy: 0.1331\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.7156 - accuracy: 0.3945\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.5766 - accuracy: 0.1211\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.7358 - accuracy: 0.3657\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.6354 - accuracy: 0.1318\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.7209 - accuracy: 0.3953\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 4.3323 - accuracy: 0.4829\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.9238 - accuracy: 0.7330\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.3108 - accuracy: 0.4811\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.9133 - accuracy: 0.7352\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.3321 - accuracy: 0.4840\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.9414 - accuracy: 0.7227\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.2729 - accuracy: 0.4863\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.9214 - accuracy: 0.7322\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 4.3724 - accuracy: 0.4830\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.9339 - accuracy: 0.7345\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.8048 - accuracy: 0.0333\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.3846 - accuracy: 0.0343\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.7968 - accuracy: 0.0463\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.3888 - accuracy: 0.0536\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.8871 - accuracy: 0.0449\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.4721 - accuracy: 0.0497\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.8864 - accuracy: 0.0289\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.4338 - accuracy: 0.0284\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.8197 - accuracy: 0.0392\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.4040 - accuracy: 0.0434\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.6922 - accuracy: 0.0566\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.1167 - accuracy: 0.1416\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.6288 - accuracy: 0.0576\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.0816 - accuracy: 0.1625\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.7490 - accuracy: 0.0686\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.0827 - accuracy: 0.1849\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.7174 - accuracy: 0.0571\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.1029 - accuracy: 0.1533\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 5.6959 - accuracy: 0.0561\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.0905 - accuracy: 0.1727\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 8.5153 - accuracy: 0.3660\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.7124 - accuracy: 0.7842\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 8.4603 - accuracy: 0.3733\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.7198 - accuracy: 0.7875\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 8.5826 - accuracy: 0.3640\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.7108 - accuracy: 0.7852\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 8.4933 - accuracy: 0.3652\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.7148 - accuracy: 0.7836\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 8.4415 - accuracy: 0.3719\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.7165 - accuracy: 0.7833\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.2724 - accuracy: 0.1179\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.0799 - accuracy: 0.4787\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.2184 - accuracy: 0.1316\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.0579 - accuracy: 0.4965\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.3034 - accuracy: 0.1108\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.1237 - accuracy: 0.4657\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.2547 - accuracy: 0.1190\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.0803 - accuracy: 0.4850\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.2809 - accuracy: 0.1301\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.0668 - accuracy: 0.4791\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 8.5295 - accuracy: 0.3557\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.6705 - accuracy: 0.8017\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 8.4378 - accuracy: 0.3620\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6660 - accuracy: 0.8001\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 8.5266 - accuracy: 0.3581\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.6887 - accuracy: 0.7941\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 8.5343 - accuracy: 0.3559\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.6719 - accuracy: 0.7988\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 8.5104 - accuracy: 0.3584\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.6750 - accuracy: 0.7980\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.4449 - accuracy: 0.0499\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.4958 - accuracy: 0.0693\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.4989 - accuracy: 0.0389\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.5604 - accuracy: 0.0423\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.4790 - accuracy: 0.0534\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.4064 - accuracy: 0.0701\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.5435 - accuracy: 0.0354\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.5144 - accuracy: 0.0419\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 9.5148 - accuracy: 0.0363\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.5517 - accuracy: 0.0452\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.5138 - accuracy: 0.0523\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.9042 - accuracy: 0.2034\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.4303 - accuracy: 0.0651\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.8561 - accuracy: 0.2227\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.4093 - accuracy: 0.0650\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.8716 - accuracy: 0.2233\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.4148 - accuracy: 0.0623\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.8682 - accuracy: 0.2134\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.4247 - accuracy: 0.0618\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.8122 - accuracy: 0.2297\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 8.4667 - accuracy: 0.3690\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.7041 - accuracy: 0.7907\n",
            "163/163 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.3520\n",
            "41/41 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 8.4421 - accuracy: 0.3714\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.7735 - accuracy: 0.7689\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 8.5271 - accuracy: 0.3674\n",
            "41/41 [==============================] - 1s 3ms/step - loss: 0.7067 - accuracy: 0.7887\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 8.5338 - accuracy: 0.3661\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.7200 - accuracy: 0.7844\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.2528 - accuracy: 0.1282\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.0566 - accuracy: 0.4915\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.2896 - accuracy: 0.1186\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.0670 - accuracy: 0.4837\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.2734 - accuracy: 0.1206\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.1003 - accuracy: 0.4650\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.2169 - accuracy: 0.1304\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.0659 - accuracy: 0.4822\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.3070 - accuracy: 0.1272\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.0759 - accuracy: 0.4757\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 8.5829 - accuracy: 0.3560\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.6958 - accuracy: 0.7886\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 8.5336 - accuracy: 0.3594\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6698 - accuracy: 0.8014\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 8.5070 - accuracy: 0.3590\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.6908 - accuracy: 0.7911\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 8.5457 - accuracy: 0.3583\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.6576 - accuracy: 0.8049\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 8.5184 - accuracy: 0.3576\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.6779 - accuracy: 0.7978\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.5241 - accuracy: 0.0406\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.5361 - accuracy: 0.0537\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 9.5522 - accuracy: 0.0391\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.4982 - accuracy: 0.0509\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 9.5337 - accuracy: 0.0467\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.5437 - accuracy: 0.0621\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.5480 - accuracy: 0.0460\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.5644 - accuracy: 0.0612\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.4382 - accuracy: 0.0435\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.4155 - accuracy: 0.0551\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.4713 - accuracy: 0.0563\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.8677 - accuracy: 0.2096\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.4372 - accuracy: 0.0665\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.8274 - accuracy: 0.2325\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.3734 - accuracy: 0.0733\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.7856 - accuracy: 0.2576\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.3845 - accuracy: 0.0589\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.8640 - accuracy: 0.2113\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.3899 - accuracy: 0.0603\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.8654 - accuracy: 0.2275\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 8.6480 - accuracy: 0.3468\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.9202 - accuracy: 0.7255\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 8.5654 - accuracy: 0.3481\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.8522 - accuracy: 0.7471\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 8.5172 - accuracy: 0.3501\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.8909 - accuracy: 0.7326\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 8.5340 - accuracy: 0.3536\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.8983 - accuracy: 0.7330\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 8.5320 - accuracy: 0.3482\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.8642 - accuracy: 0.7484\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.2079 - accuracy: 0.1439\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.8649 - accuracy: 0.4986\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.1158 - accuracy: 0.1519\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.8411 - accuracy: 0.5159\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.1954 - accuracy: 0.1530\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.8815 - accuracy: 0.4975\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.1735 - accuracy: 0.1381\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.8681 - accuracy: 0.5002\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.1392 - accuracy: 0.1457\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.8667 - accuracy: 0.5036\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 8.4749 - accuracy: 0.3529\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.8695 - accuracy: 0.7457\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 8.5671 - accuracy: 0.3452\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.8778 - accuracy: 0.7384\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 8.4803 - accuracy: 0.3479\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.8952 - accuracy: 0.7376\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 8.4974 - accuracy: 0.3508\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.8783 - accuracy: 0.7402\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 8.5550 - accuracy: 0.3469\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.8772 - accuracy: 0.7458\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 9.5031 - accuracy: 0.0341\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.4468 - accuracy: 0.0440\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.5038 - accuracy: 0.0325\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.4220 - accuracy: 0.0468\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 9.5202 - accuracy: 0.0310\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.5085 - accuracy: 0.0409\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.4179 - accuracy: 0.0634\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.2867 - accuracy: 0.1012\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 9.4735 - accuracy: 0.0427\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.3488 - accuracy: 0.0645\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.4163 - accuracy: 0.0631\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.6468 - accuracy: 0.2651\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.4060 - accuracy: 0.0735\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.6227 - accuracy: 0.2675\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.4213 - accuracy: 0.0710\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.6456 - accuracy: 0.2769\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.3207 - accuracy: 0.0848\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.5485 - accuracy: 0.3228\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.3808 - accuracy: 0.0701\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.6530 - accuracy: 0.2661\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 8.5235 - accuracy: 0.3522\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.8747 - accuracy: 0.7437\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 8.6115 - accuracy: 0.3448\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.8803 - accuracy: 0.7404\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 8.5396 - accuracy: 0.3518\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.8884 - accuracy: 0.7423\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 8.5015 - accuracy: 0.3530\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.8894 - accuracy: 0.7367\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 8.5240 - accuracy: 0.3530\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.8898 - accuracy: 0.7376\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.2253 - accuracy: 0.1395\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.8668 - accuracy: 0.5070\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.2047 - accuracy: 0.1366\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.8835 - accuracy: 0.4993\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.1883 - accuracy: 0.1457\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.8804 - accuracy: 0.4971\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.1673 - accuracy: 0.1543\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.8480 - accuracy: 0.5117\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.1473 - accuracy: 0.1461\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.8637 - accuracy: 0.5092\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 8.5869 - accuracy: 0.3466\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.8879 - accuracy: 0.7378\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 8.6090 - accuracy: 0.3419\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.8679 - accuracy: 0.7449\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 8.5273 - accuracy: 0.3484\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.8884 - accuracy: 0.7392\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 8.5768 - accuracy: 0.3437\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.8815 - accuracy: 0.7464\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 8.5431 - accuracy: 0.3487\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.8919 - accuracy: 0.7373\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.5439 - accuracy: 0.0321\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.4648 - accuracy: 0.0464\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.4710 - accuracy: 0.0426\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.3648 - accuracy: 0.0613\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 9.5152 - accuracy: 0.0305\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.5205 - accuracy: 0.0407\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.5260 - accuracy: 0.0386\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.4848 - accuracy: 0.0547\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.4573 - accuracy: 0.0433\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.4066 - accuracy: 0.0655\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 9.3577 - accuracy: 0.0767\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.6213 - accuracy: 0.2804\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.4120 - accuracy: 0.0658\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.6455 - accuracy: 0.2840\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.3872 - accuracy: 0.0614\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.6460 - accuracy: 0.2663\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.3446 - accuracy: 0.0824\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.5878 - accuracy: 0.2872\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.3874 - accuracy: 0.0810\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.6294 - accuracy: 0.2851\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 8.6228 - accuracy: 0.3318\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.0379 - accuracy: 0.6916\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 8.6560 - accuracy: 0.3300\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.9839 - accuracy: 0.7100\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 8.6157 - accuracy: 0.3322\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.0230 - accuracy: 0.6966\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 8.5915 - accuracy: 0.3343\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.0650 - accuracy: 0.6712\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 8.6047 - accuracy: 0.3311\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.0320 - accuracy: 0.6863\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.3348 - accuracy: 0.0769\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.9112 - accuracy: 0.2925\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.3028 - accuracy: 0.0742\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.9109 - accuracy: 0.2861\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.3295 - accuracy: 0.0699\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.9214 - accuracy: 0.2832\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.3232 - accuracy: 0.0800\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.9071 - accuracy: 0.2885\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.3082 - accuracy: 0.0813\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.9135 - accuracy: 0.3026\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 8.5653 - accuracy: 0.3292\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.0174 - accuracy: 0.6958\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 8.6292 - accuracy: 0.3227\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.9891 - accuracy: 0.7134\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 8.6445 - accuracy: 0.3216\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.0057 - accuracy: 0.7015\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 8.6566 - accuracy: 0.3236\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.9922 - accuracy: 0.7072\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 8.6592 - accuracy: 0.3219\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.0060 - accuracy: 0.7046\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.4948 - accuracy: 0.0356\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.4770 - accuracy: 0.0344\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.4374 - accuracy: 0.0382\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.4327 - accuracy: 0.0404\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 9.4882 - accuracy: 0.0343\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.4443 - accuracy: 0.0350\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.5292 - accuracy: 0.0367\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.4247 - accuracy: 0.0347\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 9.4823 - accuracy: 0.0321\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.5076 - accuracy: 0.0350\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 9.3582 - accuracy: 0.0423\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.1895 - accuracy: 0.0985\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.4530 - accuracy: 0.0410\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.2061 - accuracy: 0.0866\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.3602 - accuracy: 0.0424\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.1648 - accuracy: 0.1000\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.4241 - accuracy: 0.0384\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.1745 - accuracy: 0.0990\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.4254 - accuracy: 0.0462\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.1972 - accuracy: 0.0785\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 8.6081 - accuracy: 0.3315\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.0766 - accuracy: 0.6702\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 8.6214 - accuracy: 0.3313\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.9884 - accuracy: 0.7048\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 8.5916 - accuracy: 0.3326\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.0308 - accuracy: 0.6924\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 8.5956 - accuracy: 0.3327\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.0222 - accuracy: 0.6892\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 8.6451 - accuracy: 0.3299\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.0551 - accuracy: 0.6800\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.4072 - accuracy: 0.0760\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.9140 - accuracy: 0.3066\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.4118 - accuracy: 0.0733\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.9249 - accuracy: 0.3010\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.3675 - accuracy: 0.0735\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.9348 - accuracy: 0.2837\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.3777 - accuracy: 0.0816\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.9096 - accuracy: 0.3141\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.3666 - accuracy: 0.0791\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 2.9238 - accuracy: 0.2788\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 8.6224 - accuracy: 0.3246\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.0122 - accuracy: 0.6983\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 8.7020 - accuracy: 0.3182\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.9749 - accuracy: 0.7132\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 8.6373 - accuracy: 0.3256\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.0100 - accuracy: 0.7037\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 8.5986 - accuracy: 0.3290\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.9795 - accuracy: 0.7136\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 8.5879 - accuracy: 0.3279\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 1.0008 - accuracy: 0.7094\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 9.4922 - accuracy: 0.0334\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.5216 - accuracy: 0.0311\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.3874 - accuracy: 0.0438\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.3409 - accuracy: 0.0481\n",
            "163/163 [==============================] - 1s 5ms/step - loss: 9.4727 - accuracy: 0.0398\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.4904 - accuracy: 0.0437\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.4456 - accuracy: 0.0406\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.3959 - accuracy: 0.0409\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.4095 - accuracy: 0.0375\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.4085 - accuracy: 0.0378\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.4669 - accuracy: 0.0429\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.1826 - accuracy: 0.1101\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.4321 - accuracy: 0.0486\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.1615 - accuracy: 0.1016\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.4383 - accuracy: 0.0438\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.1883 - accuracy: 0.0919\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.3859 - accuracy: 0.0462\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.1715 - accuracy: 0.0869\n",
            "163/163 [==============================] - 1s 4ms/step - loss: 9.4329 - accuracy: 0.0419\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 3.2041 - accuracy: 0.0855\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 900 out of 900 | elapsed: 30.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "407/407 [==============================] - 2s 3ms/step - loss: nan - accuracy: 0.5598\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yinZj47UjV2q",
        "outputId": "ef7dea3d-d098-4166-e6d3-87ba11e1b54a"
      },
      "source": [
        "print(f'Best accuracy: {grid_res.best_score_} using {grid_res.best_params_}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best accuracy: 0.8300673007965088 using {'batch_size': 256, 'dropout_rate': 0.2, 'func_name': 'relu', 'kernel_initializer': 'glorot_uniform', 'optimizer': 'adam'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOyCWj1ZZGNZ"
      },
      "source": [
        "# building model (run this)\n",
        "model = models.Sequential()\n",
        "model.add(Dense(10000,\n",
        "                # activation=LeakyReLU(alpha=0.01), \n",
        "                # activation='relu',\n",
        "                input_shape=(28*28,),\n",
        "                kernel_initializer='glorot_normal',\n",
        "                # kernel_regularizer=l2(0.01),\n",
        "                use_bias=False)) # set False if BatchNormalization is used and remove dropout\n",
        "model.add(BatchNormalization()) # pre-activation normalization\n",
        "model.add(LeakyReLU(alpha=0.01))\n",
        "# model.add(Activation(relu))\n",
        "# model.add(Dropout(0.2)) # don't use this when using with BatchNormalization??\n",
        "model.add(Dense(27, activation='softmax'))"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqrdQYeIiUcE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24731151-4904-4c8d-cdba-b4d59ec09d74"
      },
      "source": [
        "# compile model (run this)\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "              # optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "callback = EarlyStopping(monitor='accuracy', \n",
        "                         patience=10,\n",
        "                        #  restore_best_weights=False)\n",
        "                         restore_best_weights=True)\n",
        "\n",
        "model.fit(train_images, \n",
        "          train_labels, \n",
        "          epochs=1000, \n",
        "          batch_size=256, \n",
        "          # batch_size=128,\n",
        "          validation_data=(validate_images,validate_labels),\n",
        "          callbacks=[callback],\n",
        "          verbose=1)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "407/407 [==============================] - 4s 8ms/step - loss: 1.3393 - accuracy: 0.7152 - val_loss: 1.8784 - val_accuracy: 0.4358\n",
            "Epoch 2/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.4473 - accuracy: 0.8671 - val_loss: 1.5449 - val_accuracy: 0.5373\n",
            "Epoch 3/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.3586 - accuracy: 0.8894 - val_loss: 1.3136 - val_accuracy: 0.6137\n",
            "Epoch 4/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.2874 - accuracy: 0.9085 - val_loss: 1.3341 - val_accuracy: 0.5895\n",
            "Epoch 5/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.2453 - accuracy: 0.9196 - val_loss: 1.3431 - val_accuracy: 0.5846\n",
            "Epoch 6/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.2071 - accuracy: 0.9296 - val_loss: 1.2749 - val_accuracy: 0.6262\n",
            "Epoch 7/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.1960 - accuracy: 0.9326 - val_loss: 1.2473 - val_accuracy: 0.6249\n",
            "Epoch 8/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.1577 - accuracy: 0.9431 - val_loss: 1.3136 - val_accuracy: 0.5989\n",
            "Epoch 9/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.1597 - accuracy: 0.9437 - val_loss: 1.3152 - val_accuracy: 0.6079\n",
            "Epoch 10/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.1371 - accuracy: 0.9505 - val_loss: 1.3308 - val_accuracy: 0.5960\n",
            "Epoch 11/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.1233 - accuracy: 0.9546 - val_loss: 1.3131 - val_accuracy: 0.6122\n",
            "Epoch 12/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.1218 - accuracy: 0.9557 - val_loss: 1.3825 - val_accuracy: 0.5880\n",
            "Epoch 13/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.1142 - accuracy: 0.9579 - val_loss: 1.3157 - val_accuracy: 0.6001\n",
            "Epoch 14/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.1057 - accuracy: 0.9613 - val_loss: 1.3840 - val_accuracy: 0.5933\n",
            "Epoch 15/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0937 - accuracy: 0.9640 - val_loss: 1.3926 - val_accuracy: 0.5855\n",
            "Epoch 16/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0920 - accuracy: 0.9647 - val_loss: 1.4488 - val_accuracy: 0.5558\n",
            "Epoch 17/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0922 - accuracy: 0.9647 - val_loss: 1.4238 - val_accuracy: 0.5716\n",
            "Epoch 18/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0835 - accuracy: 0.9672 - val_loss: 1.4964 - val_accuracy: 0.5481\n",
            "Epoch 19/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0825 - accuracy: 0.9690 - val_loss: 1.5370 - val_accuracy: 0.5276\n",
            "Epoch 20/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0826 - accuracy: 0.9682 - val_loss: 1.4903 - val_accuracy: 0.5385\n",
            "Epoch 21/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0811 - accuracy: 0.9704 - val_loss: 1.4479 - val_accuracy: 0.5686\n",
            "Epoch 22/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0663 - accuracy: 0.9735 - val_loss: 1.4687 - val_accuracy: 0.5481\n",
            "Epoch 23/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0621 - accuracy: 0.9746 - val_loss: 1.4916 - val_accuracy: 0.5405\n",
            "Epoch 24/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0613 - accuracy: 0.9745 - val_loss: 1.5573 - val_accuracy: 0.5113\n",
            "Epoch 25/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0694 - accuracy: 0.9748 - val_loss: 1.4607 - val_accuracy: 0.5524\n",
            "Epoch 26/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0648 - accuracy: 0.9746 - val_loss: 1.5285 - val_accuracy: 0.5212\n",
            "Epoch 27/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0632 - accuracy: 0.9753 - val_loss: 1.5120 - val_accuracy: 0.5316\n",
            "Epoch 28/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0626 - accuracy: 0.9759 - val_loss: 1.5410 - val_accuracy: 0.5157\n",
            "Epoch 29/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0569 - accuracy: 0.9766 - val_loss: 1.4930 - val_accuracy: 0.5399\n",
            "Epoch 30/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0585 - accuracy: 0.9783 - val_loss: 1.6052 - val_accuracy: 0.5103\n",
            "Epoch 31/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0492 - accuracy: 0.9793 - val_loss: 1.6381 - val_accuracy: 0.4818\n",
            "Epoch 32/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0546 - accuracy: 0.9778 - val_loss: 1.5310 - val_accuracy: 0.5305\n",
            "Epoch 33/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0537 - accuracy: 0.9782 - val_loss: 1.6197 - val_accuracy: 0.5025\n",
            "Epoch 34/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0475 - accuracy: 0.9801 - val_loss: 1.5384 - val_accuracy: 0.5259\n",
            "Epoch 35/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0488 - accuracy: 0.9795 - val_loss: 1.5795 - val_accuracy: 0.5103\n",
            "Epoch 36/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0489 - accuracy: 0.9797 - val_loss: 1.5972 - val_accuracy: 0.5046\n",
            "Epoch 37/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0503 - accuracy: 0.9801 - val_loss: 1.6194 - val_accuracy: 0.4939\n",
            "Epoch 38/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0494 - accuracy: 0.9796 - val_loss: 1.6236 - val_accuracy: 0.4950\n",
            "Epoch 39/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0440 - accuracy: 0.9810 - val_loss: 1.5963 - val_accuracy: 0.5096\n",
            "Epoch 40/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0439 - accuracy: 0.9824 - val_loss: 1.6456 - val_accuracy: 0.4917\n",
            "Epoch 41/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0421 - accuracy: 0.9818 - val_loss: 1.6455 - val_accuracy: 0.4936\n",
            "Epoch 42/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0427 - accuracy: 0.9823 - val_loss: 1.6896 - val_accuracy: 0.4718\n",
            "Epoch 43/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0417 - accuracy: 0.9826 - val_loss: 1.6918 - val_accuracy: 0.4767\n",
            "Epoch 44/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0411 - accuracy: 0.9830 - val_loss: 1.6481 - val_accuracy: 0.4863\n",
            "Epoch 45/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0406 - accuracy: 0.9834 - val_loss: 1.6831 - val_accuracy: 0.4727\n",
            "Epoch 46/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0491 - accuracy: 0.9821 - val_loss: 1.6779 - val_accuracy: 0.4819\n",
            "Epoch 47/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0403 - accuracy: 0.9838 - val_loss: 1.7051 - val_accuracy: 0.4679\n",
            "Epoch 48/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0400 - accuracy: 0.9849 - val_loss: 1.7064 - val_accuracy: 0.4681\n",
            "Epoch 49/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0363 - accuracy: 0.9847 - val_loss: 1.6531 - val_accuracy: 0.4814\n",
            "Epoch 50/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0475 - accuracy: 0.9819 - val_loss: 1.6952 - val_accuracy: 0.4793\n",
            "Epoch 51/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0377 - accuracy: 0.9840 - val_loss: 1.7312 - val_accuracy: 0.4572\n",
            "Epoch 52/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0316 - accuracy: 0.9866 - val_loss: 1.7030 - val_accuracy: 0.4664\n",
            "Epoch 53/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0320 - accuracy: 0.9862 - val_loss: 1.7345 - val_accuracy: 0.4625\n",
            "Epoch 54/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0366 - accuracy: 0.9845 - val_loss: 1.6789 - val_accuracy: 0.4908\n",
            "Epoch 55/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0413 - accuracy: 0.9831 - val_loss: 1.7873 - val_accuracy: 0.4323\n",
            "Epoch 56/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0385 - accuracy: 0.9842 - val_loss: 1.7837 - val_accuracy: 0.4575\n",
            "Epoch 57/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0409 - accuracy: 0.9848 - val_loss: 1.8172 - val_accuracy: 0.4393\n",
            "Epoch 58/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0427 - accuracy: 0.9842 - val_loss: 1.8240 - val_accuracy: 0.4362\n",
            "Epoch 59/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0290 - accuracy: 0.9875 - val_loss: 1.8142 - val_accuracy: 0.4500\n",
            "Epoch 60/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0279 - accuracy: 0.9872 - val_loss: 1.7913 - val_accuracy: 0.4570\n",
            "Epoch 61/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0288 - accuracy: 0.9876 - val_loss: 1.7219 - val_accuracy: 0.4763\n",
            "Epoch 62/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0313 - accuracy: 0.9868 - val_loss: 1.7858 - val_accuracy: 0.4526\n",
            "Epoch 63/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0360 - accuracy: 0.9853 - val_loss: 1.7894 - val_accuracy: 0.4567\n",
            "Epoch 64/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0427 - accuracy: 0.9847 - val_loss: 1.8098 - val_accuracy: 0.4456\n",
            "Epoch 65/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0315 - accuracy: 0.9871 - val_loss: 1.8326 - val_accuracy: 0.4513\n",
            "Epoch 66/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0294 - accuracy: 0.9875 - val_loss: 1.8101 - val_accuracy: 0.4490\n",
            "Epoch 67/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0348 - accuracy: 0.9869 - val_loss: 1.7987 - val_accuracy: 0.4551\n",
            "Epoch 68/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0318 - accuracy: 0.9874 - val_loss: 1.8677 - val_accuracy: 0.4369\n",
            "Epoch 69/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0299 - accuracy: 0.9873 - val_loss: 1.8555 - val_accuracy: 0.4388\n",
            "Epoch 70/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0287 - accuracy: 0.9879 - val_loss: 1.7751 - val_accuracy: 0.4644\n",
            "Epoch 71/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0237 - accuracy: 0.9897 - val_loss: 1.8200 - val_accuracy: 0.4470\n",
            "Epoch 72/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0289 - accuracy: 0.9879 - val_loss: 1.8839 - val_accuracy: 0.4251\n",
            "Epoch 73/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0377 - accuracy: 0.9862 - val_loss: 1.8431 - val_accuracy: 0.4317\n",
            "Epoch 74/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0400 - accuracy: 0.9868 - val_loss: 1.8689 - val_accuracy: 0.4215\n",
            "Epoch 75/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0286 - accuracy: 0.9884 - val_loss: 1.8359 - val_accuracy: 0.4425\n",
            "Epoch 76/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0262 - accuracy: 0.9890 - val_loss: 1.8469 - val_accuracy: 0.4304\n",
            "Epoch 77/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0218 - accuracy: 0.9905 - val_loss: 1.8439 - val_accuracy: 0.4333\n",
            "Epoch 78/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0257 - accuracy: 0.9889 - val_loss: 1.8982 - val_accuracy: 0.4144\n",
            "Epoch 79/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0259 - accuracy: 0.9891 - val_loss: 1.9339 - val_accuracy: 0.4002\n",
            "Epoch 80/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0273 - accuracy: 0.9889 - val_loss: 1.8451 - val_accuracy: 0.4394\n",
            "Epoch 81/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0259 - accuracy: 0.9889 - val_loss: 1.8373 - val_accuracy: 0.4460\n",
            "Epoch 82/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0270 - accuracy: 0.9893 - val_loss: 1.9109 - val_accuracy: 0.4071\n",
            "Epoch 83/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0259 - accuracy: 0.9894 - val_loss: 1.9074 - val_accuracy: 0.4229\n",
            "Epoch 84/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0259 - accuracy: 0.9896 - val_loss: 1.9194 - val_accuracy: 0.4065\n",
            "Epoch 85/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0250 - accuracy: 0.9905 - val_loss: 1.8942 - val_accuracy: 0.4203\n",
            "Epoch 86/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0252 - accuracy: 0.9895 - val_loss: 1.9611 - val_accuracy: 0.4103\n",
            "Epoch 87/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0265 - accuracy: 0.9898 - val_loss: 1.8740 - val_accuracy: 0.4316\n",
            "Epoch 88/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0259 - accuracy: 0.9908 - val_loss: 1.9748 - val_accuracy: 0.3716\n",
            "Epoch 89/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0268 - accuracy: 0.9902 - val_loss: 1.8700 - val_accuracy: 0.4253\n",
            "Epoch 90/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0253 - accuracy: 0.9902 - val_loss: 1.9817 - val_accuracy: 0.3786\n",
            "Epoch 91/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0222 - accuracy: 0.9903 - val_loss: 1.9469 - val_accuracy: 0.3853\n",
            "Epoch 92/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0232 - accuracy: 0.9903 - val_loss: 1.9279 - val_accuracy: 0.3973\n",
            "Epoch 93/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0253 - accuracy: 0.9907 - val_loss: 1.9778 - val_accuracy: 0.3875\n",
            "Epoch 94/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0219 - accuracy: 0.9905 - val_loss: 1.9734 - val_accuracy: 0.3881\n",
            "Epoch 95/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0222 - accuracy: 0.9909 - val_loss: 1.9390 - val_accuracy: 0.3931\n",
            "Epoch 96/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0224 - accuracy: 0.9911 - val_loss: 1.9921 - val_accuracy: 0.3798\n",
            "Epoch 97/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0233 - accuracy: 0.9906 - val_loss: 1.9627 - val_accuracy: 0.3943\n",
            "Epoch 98/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0212 - accuracy: 0.9917 - val_loss: 1.9330 - val_accuracy: 0.4155\n",
            "Epoch 99/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0192 - accuracy: 0.9918 - val_loss: 1.9332 - val_accuracy: 0.4092\n",
            "Epoch 100/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0201 - accuracy: 0.9918 - val_loss: 2.0168 - val_accuracy: 0.3797\n",
            "Epoch 101/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0231 - accuracy: 0.9910 - val_loss: 1.9764 - val_accuracy: 0.3946\n",
            "Epoch 102/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0314 - accuracy: 0.9893 - val_loss: 1.9785 - val_accuracy: 0.3917\n",
            "Epoch 103/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0205 - accuracy: 0.9922 - val_loss: 2.0534 - val_accuracy: 0.3758\n",
            "Epoch 104/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0216 - accuracy: 0.9914 - val_loss: 1.9479 - val_accuracy: 0.4118\n",
            "Epoch 105/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0241 - accuracy: 0.9905 - val_loss: 2.0219 - val_accuracy: 0.3940\n",
            "Epoch 106/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0210 - accuracy: 0.9916 - val_loss: 2.0138 - val_accuracy: 0.3963\n",
            "Epoch 107/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0191 - accuracy: 0.9925 - val_loss: 2.0306 - val_accuracy: 0.3813\n",
            "Epoch 108/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0173 - accuracy: 0.9927 - val_loss: 2.0908 - val_accuracy: 0.3753\n",
            "Epoch 109/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0204 - accuracy: 0.9919 - val_loss: 2.0762 - val_accuracy: 0.3902\n",
            "Epoch 110/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0199 - accuracy: 0.9918 - val_loss: 2.0763 - val_accuracy: 0.3807\n",
            "Epoch 111/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0188 - accuracy: 0.9931 - val_loss: 2.1124 - val_accuracy: 0.3755\n",
            "Epoch 112/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0202 - accuracy: 0.9920 - val_loss: 2.1011 - val_accuracy: 0.3881\n",
            "Epoch 113/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0190 - accuracy: 0.9927 - val_loss: 2.0798 - val_accuracy: 0.3989\n",
            "Epoch 114/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0207 - accuracy: 0.9919 - val_loss: 2.0658 - val_accuracy: 0.3889\n",
            "Epoch 115/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0270 - accuracy: 0.9920 - val_loss: 2.0638 - val_accuracy: 0.3954\n",
            "Epoch 116/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0172 - accuracy: 0.9930 - val_loss: 2.0610 - val_accuracy: 0.3969\n",
            "Epoch 117/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0171 - accuracy: 0.9930 - val_loss: 2.1110 - val_accuracy: 0.3905\n",
            "Epoch 118/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0199 - accuracy: 0.9925 - val_loss: 2.0398 - val_accuracy: 0.4096\n",
            "Epoch 119/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0154 - accuracy: 0.9938 - val_loss: 2.0633 - val_accuracy: 0.3886\n",
            "Epoch 120/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0172 - accuracy: 0.9930 - val_loss: 2.0728 - val_accuracy: 0.3887\n",
            "Epoch 121/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0158 - accuracy: 0.9933 - val_loss: 2.0481 - val_accuracy: 0.3936\n",
            "Epoch 122/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0163 - accuracy: 0.9933 - val_loss: 2.0303 - val_accuracy: 0.4085\n",
            "Epoch 123/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0214 - accuracy: 0.9923 - val_loss: 2.1203 - val_accuracy: 0.3889\n",
            "Epoch 124/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0210 - accuracy: 0.9920 - val_loss: 2.1149 - val_accuracy: 0.4014\n",
            "Epoch 125/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0177 - accuracy: 0.9934 - val_loss: 2.0967 - val_accuracy: 0.4024\n",
            "Epoch 126/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0152 - accuracy: 0.9947 - val_loss: 2.1283 - val_accuracy: 0.3938\n",
            "Epoch 127/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0159 - accuracy: 0.9940 - val_loss: 2.1095 - val_accuracy: 0.3901\n",
            "Epoch 128/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0194 - accuracy: 0.9932 - val_loss: 2.1990 - val_accuracy: 0.3684\n",
            "Epoch 129/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0200 - accuracy: 0.9936 - val_loss: 2.1492 - val_accuracy: 0.3803\n",
            "Epoch 130/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0152 - accuracy: 0.9940 - val_loss: 2.1356 - val_accuracy: 0.3887\n",
            "Epoch 131/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0135 - accuracy: 0.9949 - val_loss: 2.1522 - val_accuracy: 0.3862\n",
            "Epoch 132/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0234 - accuracy: 0.9917 - val_loss: 2.2037 - val_accuracy: 0.3792\n",
            "Epoch 133/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0197 - accuracy: 0.9930 - val_loss: 2.1379 - val_accuracy: 0.3815\n",
            "Epoch 134/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0143 - accuracy: 0.9945 - val_loss: 2.0762 - val_accuracy: 0.4030\n",
            "Epoch 135/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0154 - accuracy: 0.9943 - val_loss: 2.0839 - val_accuracy: 0.3958\n",
            "Epoch 136/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0154 - accuracy: 0.9945 - val_loss: 2.1425 - val_accuracy: 0.3877\n",
            "Epoch 137/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0137 - accuracy: 0.9948 - val_loss: 2.1145 - val_accuracy: 0.3860\n",
            "Epoch 138/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0160 - accuracy: 0.9939 - val_loss: 2.0849 - val_accuracy: 0.4125\n",
            "Epoch 139/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0158 - accuracy: 0.9943 - val_loss: 2.1200 - val_accuracy: 0.3942\n",
            "Epoch 140/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0151 - accuracy: 0.9943 - val_loss: 2.0713 - val_accuracy: 0.4078\n",
            "Epoch 141/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0201 - accuracy: 0.9940 - val_loss: 2.1224 - val_accuracy: 0.4058\n",
            "Epoch 142/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0132 - accuracy: 0.9950 - val_loss: 2.1557 - val_accuracy: 0.4000\n",
            "Epoch 143/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0134 - accuracy: 0.9946 - val_loss: 2.1891 - val_accuracy: 0.3951\n",
            "Epoch 144/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0149 - accuracy: 0.9945 - val_loss: 2.1729 - val_accuracy: 0.3955\n",
            "Epoch 145/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0167 - accuracy: 0.9942 - val_loss: 2.1855 - val_accuracy: 0.3882\n",
            "Epoch 146/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0180 - accuracy: 0.9934 - val_loss: 2.2031 - val_accuracy: 0.3845\n",
            "Epoch 147/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0157 - accuracy: 0.9943 - val_loss: 2.2197 - val_accuracy: 0.3849\n",
            "Epoch 148/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0140 - accuracy: 0.9947 - val_loss: 2.2545 - val_accuracy: 0.3884\n",
            "Epoch 149/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 2.1757 - val_accuracy: 0.3903\n",
            "Epoch 150/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0115 - accuracy: 0.9955 - val_loss: 2.2270 - val_accuracy: 0.3836\n",
            "Epoch 151/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0157 - accuracy: 0.9941 - val_loss: 2.2070 - val_accuracy: 0.3934\n",
            "Epoch 152/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0163 - accuracy: 0.9942 - val_loss: 2.2972 - val_accuracy: 0.3756\n",
            "Epoch 153/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0148 - accuracy: 0.9940 - val_loss: 2.2854 - val_accuracy: 0.3818\n",
            "Epoch 154/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0118 - accuracy: 0.9954 - val_loss: 2.1734 - val_accuracy: 0.4042\n",
            "Epoch 155/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0162 - accuracy: 0.9943 - val_loss: 2.2199 - val_accuracy: 0.3977\n",
            "Epoch 156/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 2.2394 - val_accuracy: 0.3907\n",
            "Epoch 157/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0161 - accuracy: 0.9950 - val_loss: 2.1725 - val_accuracy: 0.4083\n",
            "Epoch 158/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0125 - accuracy: 0.9955 - val_loss: 2.2218 - val_accuracy: 0.4030\n",
            "Epoch 159/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0098 - accuracy: 0.9964 - val_loss: 2.1952 - val_accuracy: 0.3975\n",
            "Epoch 160/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0113 - accuracy: 0.9958 - val_loss: 2.2356 - val_accuracy: 0.4013\n",
            "Epoch 161/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0128 - accuracy: 0.9953 - val_loss: 2.2604 - val_accuracy: 0.3985\n",
            "Epoch 162/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 2.2329 - val_accuracy: 0.3986\n",
            "Epoch 163/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0167 - accuracy: 0.9943 - val_loss: 2.2320 - val_accuracy: 0.3854\n",
            "Epoch 164/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 2.2729 - val_accuracy: 0.3809\n",
            "Epoch 165/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0112 - accuracy: 0.9960 - val_loss: 2.2297 - val_accuracy: 0.3954\n",
            "Epoch 166/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0121 - accuracy: 0.9953 - val_loss: 2.2912 - val_accuracy: 0.3835\n",
            "Epoch 167/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 2.2135 - val_accuracy: 0.3960\n",
            "Epoch 168/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 2.2963 - val_accuracy: 0.3856\n",
            "Epoch 169/1000\n",
            "407/407 [==============================] - 3s 8ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 2.3305 - val_accuracy: 0.3717\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdd6154f1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03PUTvHYm4Fg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17a74b62-d982-408e-b978-6c2159004706"
      },
      "source": [
        "# run model against TEST SET (this)\n",
        "test_lost, test_acc = model.evaluate(test_images, test_labels)\n",
        "\n",
        "# get accuracy\n",
        "print('Test Accuracy: ', test_acc)\n",
        "modified_model_acc = test_acc"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "650/650 [==============================] - 1s 2ms/step - loss: 1.0368 - accuracy: 0.9068\n",
            "Test Accuracy:  0.906826913356781\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQQV3_EaCpic",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47862994-b811-4e6b-d9e5-bb5eb376442e"
      },
      "source": [
        "(modified_model_acc - modified_org_model_acc)*100 #run this"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5625009536743164"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "0elR0DWIgKu5",
        "outputId": "be0e5e26-a03e-4116-f159-33de432ae2f6"
      },
      "source": [
        "# attempt to do augmentation\n",
        "# inspired from https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/\n",
        "\n",
        "X_train = train_images.reshape(104000, 28, 28, 1)\n",
        "datagen = ImageDataGenerator(featurewise_center=True,\n",
        "                             featurewise_std_normalization=True,\n",
        "                             rotation_range=40,\n",
        "                             width_shift_range=0.2,\n",
        "                             height_shift_range=0.2,\n",
        "                             horizontal_flip=True)\n",
        "datagen.fit(X_train)\n",
        "it = datagen.flow(X_train, train_labels)\n",
        "\n",
        "print(it[0][0][0].shape)\n",
        "# print(it[0][0][0])\n",
        "plt.imshow(it[0][0][0].reshape(28,28))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fdd6183b690>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "3PvyxuwtgPsC",
        "outputId": "3e958d4c-7825-4ccc-de5a-5a90bdc86679"
      },
      "source": [
        "# original image\n",
        "plt.imshow(train_images[0].reshape(28,28))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fdd615911d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "RCfX9UJ8gUbQ",
        "outputId": "85d24b62-7333-4875-b7bf-e978e7845114"
      },
      "source": [
        "test_rotate_0 = np.rot90(train_images[0].reshape(28,28))\n",
        "plt.imshow(test_rotate_0)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fdd61cce8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "2W8rD8GqgXHV",
        "outputId": "e15b3092-154f-417f-d9b7-2e3fd8538287"
      },
      "source": [
        "test_flip_0 = np.flip(train_images[0].reshape(28,28))\n",
        "plt.imshow(test_flip_0)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fdd62dc8bd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "SDgZNzlPgbll",
        "outputId": "8d989d71-3beb-46c9-f853-2ba190d36cd9"
      },
      "source": [
        "print(train_images.shape)\n",
        "print(train_images.mean(axis=0).mean(axis=0))\n",
        "mean = train_images.mean(axis=0).mean(axis=0)\n",
        "print(train_images.std(axis=0).std(axis=0))\n",
        "std = train_images.std(axis=0).std(axis=0)\n",
        "noise = np.random.normal(mean, std, train_images.shape)\n",
        "test_add_noise = train_images + noise\n",
        "plt.imshow(test_add_noise[1].reshape(28,28))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(104000, 784)\n",
            "-2.9526291438142732e-15\n",
            "0.23501253876711675\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fdd611ccc90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZaUlEQVR4nO2da4ycV3nH/8/OzszuzO56b/Z67Wx8SewkVgCn2RhQAoRrQ1qU0KqICNEgIcIHIkHLh9K0EvlSKaoKiA8IyUBEWqWhFBIlVKEQ3Ig0LRdvUmM7dmI7jp1de71re+/X2Zl5+sEDMsHn/y57mVlx/j9ptbPzzHnf8573/c87O//znMfcHUKIP3zqat0BIUR1kNiFiASJXYhIkNiFiASJXYhIqK/qzhrynm1qD8ZLWd6+rhiOecLbVl2Bx8sZHgcxLVIJ207qm6eWvu9EEtpaOSGe0L68jCvILeEFSbeiZRxb0r6TxiWxbwntnYyblRK2TfpemBhBcXb6iq9YltjN7A4AXwWQAvBNd3+IvT7b1I7r7/qrYHxqCz8DDRfCsUIzbYqW03z0J3v42atbCMeaB/i2C3l+XAtNPJ544RHqFrgi0tM8niLHDQBzbbzvTFSlBt621MD3nfQGzo6t2Mj3nTQuxYS+p+Z5+7mOcPuGEd62lA23PfHYl4OxJX+MN7MUgK8B+CCAXQDuMbNdS92eEGJ1Wc7/7HsAnHD3k+5eAPAdAHetTLeEECvNcsS+GUD/ZX8PVJ77LczsPjPrM7O+4tz0MnYnhFgOq/5tvLvvdfded++tb8iv9u6EEAGWI/YzAHou+/uqynNCiDXIcsS+H8AOM9tmZhkAHwXw1Mp0Swix0izZenP3opndD+BHuGS9PezuL9E2ddzPzozyfaZmw5ZEum7pFhAAZMe43cHiy/XRGy9yb21+He98c3/YmK2f4abt6HUJEwwSvGxmIQFA0xkybglXX90EjyeNKztnzEoFgOnNCWN+mg+MlROsO2LHlusTbL05sm1yKS3LZ3f3pwE8vZxtCCGqg6bLChEJErsQkSCxCxEJErsQkSCxCxEJErsQkVDVfHYYUE6HPcTsOPcmp3rCbTc/O0Pbnn1HjsYzCZ6ulcMGZj3zPQGUU/w9NSld0o3H59eFtz/Xxs3o3Pll5M8C6Dw4R+PDN4enSCem1yakiSb50Wx+AvO5gWQfveXkLI2P7Gqk8fRUePvT3bxvrcfDbVk6tO7sQkSCxC5EJEjsQkSCxC5EJEjsQkSCxC5EJFTVevM6oEgcsPQUb984HLYcRq/nVkfLKW4xJaWpznaGX9DyOlnjGsD0Jr7xjpd4vmVqnve9lA1vn1mdAFA/u/RtA8DMJr4EbNf+8Ekd2cVXLppv5ftuf3mexodvDq9N3vVLbhnOdPHU3/Fr+PXWdoz37eKu8Ljlz3Lbb/za8Liw5dh1ZxciEiR2ISJBYhciEiR2ISJBYhciEiR2ISJBYhciEqqb4gq+pPPEtoRqpsR+rE+oLFXMJVQMTVhRueNo2AtPzXGvuuMI99GLjfw9Nz3B2xfWhU9j0vyBczfyA5/bxJeiTk3yHfjbwxMrtu0eoG0vTHEf/uztaRpfKITPS+n9I7TtxGQTja9v5pNC+kfW0Xjd0XAsN0ib8jLZ5DLXnV2ISJDYhYgEiV2ISJDYhYgEiV2ISJDYhYgEiV2ISKiqz15OA7PdYe9zfR9vz5YWLjbw9626YkIJ3YTlnLPnw/nP5UY+jIUMjy/keN9H38mXwS7cGF5G+y9ueJG2PTLRTeMdWT6BYWC6lcZv6TgdjB2b2kDbjszwnPH3bj1G41lSl3m+zD36ciu/Hj7W8b80/qnxv6RxJ5djUnnx9qNhDZ0lafrLEruZnQIwCaAEoOjuvcvZnhBi9ViJO/u73f3CCmxHCLGK6H92ISJhuWJ3AD82sxfM7L4rvcDM7jOzPjPrK00lTGAXQqway/0Yf5u7nzGzDQCeMbOX3f25y1/g7nsB7AWA7NU9/FsyIcSqsaw7u7ufqfweBvAEgD0r0SkhxMqzZLGbWd7Mmn/9GMAHABxeqY4JIVaW5XyM7wLwhF0qJ1wP4F/d/T9Zg/QUsJHYkwuNCfnsxBotNPO2KZ4SDiRULp7dFPZ8R3fyYZzr4P+9sDx9AFho4evSd7WGc6tfn22nbcfmE9bbz/DSxF05Xuv6uaFrg7GtLRdp24Y0P+6BGe7xF8rhctUXZniu/AM7f0jjz07tovG5c3z72B42xPNnyeLv4KWoySEvXezufhLAW5baXghRXWS9CREJErsQkSCxCxEJErsQkSCxCxEJ1U1xTQHzLWHbID3DPagpVvo44W0r91qCt5ZAXSHcN1ZKGgD+7GPP0fhMwjrW/bNtNH58pDMYG5nn6bG3bXiVxn92YRuNzxX5JXTuQnhJ5Ww9t9YujPPlnLtyk7z9TEswNjrOrbG//tHHaLz5VeJxAbj2F3xq+Pi14fOSZCOnp8PXm5HLXHd2ISJBYhciEiR2ISJBYhciEiR2ISJBYhciEiR2ISKhqj67OZCaD8eLWe4v5s+FTcSkpaBLCdtu7icdAzC8O5wKWv8+vt7meJGnkb4+zX30QwObaTydCfvVre08RXXf4E4az6Z4yea2Br79XHc4t3hrEy+b/PoFPi4HTvXQeDobHhcfbKBtM9P8esmRaxEAPMXvoyWSxdr+Mr8Wh24JN2YrZOvOLkQkSOxCRILELkQkSOxCRILELkQkSOxCRILELkQkVDefvR6Y2Rj2L/OD3LtkPnyqwPddx1OnMd3Nl++d7Q7nEG/M8HWqJxe4p3t2KpzzDQCbO8dofJSUNu776fW0rfO0bOzYEy65DAD1LIEawNhC2Pg9PLKRtl2/LrxENgBMz/N1AGZ/Ffbpt/8wXOYaABbW8W2XEuZ1zHfwktCMuYS2mXGSz06mRejOLkQkSOxCRILELkQkSOxCRILELkQkSOxCRILELkQkVD+fPVypFrMd/L2n6WzYRJy8mhvGqbmE/OQPnaPxDSR2VRP3wcvg+y47j58+tZ7G8yfDvmx7P/fBM9M8PjC8lcbbj/I5BsV2cl4SSlUP3sLjSXQfDB+b1/NrrdjI47kz3KcvZ/j1eOFN4XXjF3L8emgi81HYfJLEO7uZPWxmw2Z2+LLn2s3sGTM7XvnNVxkQQtScxXyM/zaAO97w3BcA7HP3HQD2Vf4WQqxhEsXu7s8BeOP6QXcBeKTy+BEAd69wv4QQK8xSv6DrcvfByuNzALpCLzSz+8ysz8z6irO8/pUQYvVY9rfx7u4gX7W4+15373X33vpGXkxPCLF6LFXsQ2bWDQCV38Mr1yUhxGqwVLE/BeDeyuN7ATy5Mt0RQqwWiT67mT0G4HYAnWY2AOCLAB4C8F0z+ySA0wA+spideR2w0ByONw4lGK8W9h9bTvP1zSd7uO/57o3HaZx54d89cjNtu759gsZTddzrzr3G85uv2heuUz5+Lf/XKTPGE/3bj/Bzkh3la5znToS/p7EiP2cT2zfReBLpyfAiB5nX+IdRK/O5DWPX8drxCzyMhvPhcWW1FQBgtiN8LZaJohPF7u73BELvTWorhFg7aLqsEJEgsQsRCRK7EJEgsQsRCRK7EJFQ1RTX1DzQdixst8yt4+89dQvErihw+2riRm7zDM230PhkMbzU9KaEpZ6bMtxLOXqMl2TeeJofWykXPo25IZ6CmhnmyzWn65Z3PygdezUYK9zBc1jn2xLSc8cS0lBfCdtrF9+VUO55hluOzQMJZZV7+fLhLeScpub5cU9uXppsdWcXIhIkdiEiQWIXIhIkdiEiQWIXIhIkdiEiQWIXIhKq6rOXssD49nCqadd+ss40gNGdYa/bivx964btvPTwzjxfSjpXF06X3FfiZZGP/mQHjV/9Ik8zzY7M0nj9aHhZ49mreTnocp6XqoYnpB2XEuJ73hQMTVzNL7/8dj5/oaWBe90jJ8IpsmPX8eWam0/xeOMw98LTk3xcCvnw9psmeNsyqSbNViXXnV2ISJDYhYgEiV2ISJDYhYgEiV2ISJDYhYgEiV2ISKiqz163wJfQnevgSyYXmsMmoiXYvV2N4eWWAaA9xUtT/WD4LcHYbJH3O6FiM+ZYWWMAjed4Lj4je5HPXSi087zr6Y382Ga6Eg6OhKd28Fz792zsp/F8PffZn/7T8BoFpTFiVgMoXsP7Vso00ng9H3Y0XiDrOiRcDyV2ysjtW3d2ISJBYhciEiR2ISJBYhciEiR2ISJBYhciEiR2ISKhqj57OQUUWsLGa2qBe7YLe8Jeeb6Re64fbD9I489P7KTxXS2Dwdi/HeYlmzMJcwDajvA5AFbg+e4n7u0Mxha6wnn4AFA3xi+BVDeff5Bv5NvfvG48GDvav5G2LSdMUMjW8XHZsyW8hsEn9jxP26aM56v/7E18jYInvvZuGh/fHh73tlf4mDLZkmUXku/sZvawmQ2b2eHLnnvQzM6Y2YHKz51J2xFC1JbFfIz/NoA7rvD8V9x9d+Xn6ZXtlhBipUkUu7s/B2CkCn0RQqwiy/mC7n4zO1j5mN8WepGZ3WdmfWbWV5rl//8JIVaPpYr96wCuAbAbwCCAL4Ve6O573b3X3XtTjfkl7k4IsVyWJHZ3H3L3kruXAXwDwJ6V7ZYQYqVZktjNrPuyPz8M4HDotUKItUGiz25mjwG4HUCnmQ0A+CKA281sNwAHcArApxezs7oSkB0Lm87zCfXZS8Vwnu/4BP8XoSPF65DfmD9D4988eWsw1tM1StsOneC5z3NdPD6+jeeU528If39an+J+8Wg2R+PNeZ6Y3d3M5whc1zwUjK3fwc9JEv2zwa+KAABvaz0ZjJ1aWM/bNobbAsDfd75M4492vYfGWb57Mcfz2YtZMv+AhBLF7u73XOHpbyW1E0KsLTRdVohIkNiFiASJXYhIkNiFiASJXYhIqG7J5gZg7IZwPD2R0P5CuLzwh2/dT9sen+fplP9+lqep5tLhpYUHR8NLFgNAfULGYsMwt7dmO/hpypLSxf2vcovJ8jxNtDHN4ze08FLXp2fag7F1aX7cjSk+cJ0Zbt29I3csGPvRZLiUNAA05/hx33/mrTSe4hnXSJOyzFbmOdGZadY23E53diEiQWIXIhIkdiEiQWIXIhIkdiEiQWIXIhIkdiEioao+e2oOaD0ajueHeJnc1/84nPr3g2PcN/0QXykag2PcK0/Xh0vsZrO838WEt9RSAz8NbYf4BITBp7uDse4hnuI6sis8dwEAhoa6aPzx9AYav6n3RDB26GK43wCwIc999K35izT+D/1/EowdOLidtv1G6l003nqIn7MNJ/gcAZa2XGzkF8x0VzheItnQurMLEQkSuxCRILELEQkSuxCRILELEQkSuxCRILELEQlV9dk9qWRzgS+ha8Vw21KCmT1f5ssxv7n7LI0XSuG+HR3iufJzPTw3uv99fCnpjsMZGu/aHy6rVWzix731yVkaL2f5JTLwHr6E9+h8eKnqa1sv0LbpuvDcBgAoOz/nB/uvCsa2/Aeff1BiyzUDWMjz9oVmfi0XmsPbbx7g18v4dnLcSwsJIf6QkNiFiASJXYhIkNiFiASJXYhIkNiFiASJXYhIqKrPbmUgTda8ntjK33u8PuxtvmXLAG07UeR52+vS3G9+tn9HMHZ99zBtO5xvovHzTc00PriFj0vP98PHNnI9P8Vd+7lfzEoAA0Apy9c4P3kqnO9+MsXXtM+18HXlt3WES1UDQJnUGZjs4QfW/DpfoyA9xecATG3icyMaRsLjNrUxQZZ8yIMk3tnNrMfMnjWzI2b2kpl9tvJ8u5k9Y2bHK795sWwhRE1ZzMf4IoDPu/suAG8D8Bkz2wXgCwD2ufsOAPsqfwsh1iiJYnf3QXd/sfJ4EsBRAJsB3AXgkcrLHgFw92p1UgixfH6vL+jMbCuAmwD8AkCXuw9WQucAXHGxMjO7z8z6zKyvOBuewy2EWF0WLXYzawLwfQCfc/ffWgHR3R2Brw3cfa+797p7b30jT5oQQqweixK7maVxSeiPuvvjlaeHzKy7Eu8GwL+SFkLUlETrzcwMwLcAHHX3L18WegrAvQAeqvx+Mmlb5Xpgdn3Y8mg5lZA22BZue/S/wtYYAPz53f9N40PzfCnpu3YeCsa+90IvbWsZbtN0dk7S+LoGbkF1/W24/egwX6751Z3cFsyc45fIwhZem/imrf3B2FvbTtG2/XPhcs8A8D9nt9G4Z8LXU3qK3+dm1/Pjbhjh5zS1wP2xllPhcTvzTp7y3HielGwm2bGL8dlvBfBxAIfM7EDluQdwSeTfNbNPAjgN4COL2JYQokYkit3dn0d4asV7V7Y7QojVQtNlhYgEiV2ISJDYhYgEiV2ISJDYhYiEqqa41s86Ol4KG4EzG/jyuyliN7e+wj36R3/+dhq/dscgjc8shEsXd3aP07ZJuPN0y6FJ7oWfHOwMxm7Zdpq2bdzIU4N/3rqVxpvSfNnjdZnwSds/toW2PT3Offaxi3xcLBfuWznNU54bRrmPPt/Kr9Vyip/T4ZvDXjpLfwWAYi68bba6tu7sQkSCxC5EJEjsQkSCxC5EJEjsQkSCxC5EJEjsQkRCVX32YqPh4o3hXWbGuL/YOET8xRRvu+1x7sOPbQ6X9wWA+jmyBPYu7qkWNnAvOjXJPdvsNp7vvnn9WDB2Q9M52vZ7J3fTeGO2QONbW/lyzrOlcMnoFw5vp21bD/HLc/1Mgh9N0sJLfKVnzLXxc7IQrkQNAMhd4Nfbwnz4PpviSwQgOxbedh251HRnFyISJHYhIkFiFyISJHYhIkFiFyISJHYhIkFiFyISquqzw4E6XgmXUj8b9lXn2hLKPVvY7wWAltPcT57rDLff/FPeFnXch284fYHGX/touOwxAPT3hA3lR4beRts25rmpO3qRl5Oe+b8OGm89FvaEe6a4F52a5xfLbCf3wt3C10TbcV6ie/gmvnZ7bpj3vZTh53yhKRyvK/D5A0bCbK+6swsRCRK7EJEgsQsRCRK7EJEgsQsRCRK7EJEgsQsRCYupz94D4J8BdAFwAHvd/atm9iCATwE4X3npA+7+dOL2iD2ZmeT+YmY63LiY44eSnuW+6Ph2nuCcu0DWEU/w0ac2cY+/boHXhs+E09UBAPUz4b6XE85wqaGBxlvP0/ClK4LAPOGZ9Qk+ecKtqJTl4844dwv30ZvO8uulQHxyAJhv53G2dkMdX7Kejgs7HYuZVFME8Hl3f9HMmgG8YGbPVGJfcfd/WsQ2hBA1ZjH12QcBDFYeT5rZUQCbV7tjQoiV5ff6n93MtgK4CcAvKk/db2YHzexhM2sLtLnPzPrMrK80M72szgohls6ixW5mTQC+D+Bz7j4B4OsArgGwG5fu/F+6Ujt33+vuve7em8rlV6DLQoilsCixm1kal4T+qLs/DgDuPuTuJXcvA/gGgD2r100hxHJJFLuZGYBvATjq7l++7Pnuy172YQCHV757QoiVYjHfxt8K4OMADpnZgcpzDwC4x8x249K3/acAfHoxO2TViSe38PeezHg4vsCr92K+mW87Pc09JCf2WqE5YSnocW7jnH8zt7+Sjq3lVHj7E1v5cW/8JU8jnVnPLxG2xDYAZCbDPtJCnm87P5TgQSXAbN7Jq/g5m9nAxy2prLKP83iKZEXPt3LbrkzSZ8vEQV7Mt/HP48ppsomeuhBi7aAZdEJEgsQuRCRI7EJEgsQuRCRI7EJEgsQuRCRUdylp8JTHzDhvW8qGY0lLVNfPc99zqifBhyfpt0kldjOTCemS63h75skCPCWy6Qw/7smr+CUwl5Cq2XGEe+ETPeHtJ6WoTndxL7ywjrdvGgiPe5KXnXQtzifse3YDH/ccKT/edIaP6ej14XFh81h0ZxciEiR2ISJBYhciEiR2ISJBYhciEiR2ISJBYhciEsw9YS3gldyZ2XkApy97qhMAr1dcO9Zq39ZqvwD1bamsZN+2uPv6KwWqKvbf2blZn7v31qwDhLXat7XaL0B9WyrV6ps+xgsRCRK7EJFQa7HvrfH+GWu1b2u1X4D6tlSq0rea/s8uhKgetb6zCyGqhMQuRCTUROxmdoeZvWJmJ8zsC7XoQwgzO2Vmh8zsgJn11bgvD5vZsJkdvuy5djN7xsyOV35fscZejfr2oJmdqYzdATO7s0Z96zGzZ83siJm9ZGafrTxf07Ej/arKuFX9f3YzSwE4BuD9AAYA7Adwj7sfqWpHApjZKQC97l7zCRhm9k4AUwD+2d1vrDz3jwBG3P2hyhtlm7v/zRrp24MApmpdxrtSraj78jLjAO4G8AnUcOxIvz6CKoxbLe7sewCccPeT7l4A8B0Ad9WgH2sed38OwMgbnr4LwCOVx4/g0sVSdQJ9WxO4+6C7v1h5PAng12XGazp2pF9VoRZi3wyg/7K/B7C26r07gB+b2Qtmdl+tO3MFutx9sPL4HICuWnbmCiSW8a4mbygzvmbGbinlz5eLvqD7XW5z9z8C8EEAn6l8XF2T+KX/wdaSd7qoMt7V4gplxn9DLcduqeXPl0stxH4GQM9lf19VeW5N4O5nKr+HATyBtVeKeujXFXQrv4dr3J/fsJbKeF+pzDjWwNjVsvx5LcS+H8AOM9tmZhkAHwXwVA368TuYWb7yxQnMLA/gA1h7paifAnBv5fG9AJ6sYV9+i7VSxjtUZhw1Hrualz9396r/ALgTl76RfxXA39WiD4F+bQfwq8rPS7XuG4DHcOlj3QIufbfxSQAdAPYBOA7gJwDa11Df/gXAIQAHcUlY3TXq22249BH9IIADlZ87az12pF9VGTdNlxUiEvQFnRCRILELEQkSuxCRILELEQkSuxCRILELEQkSuxCR8P+aoMH1aA2lcAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5zeGkYfgjr3"
      },
      "source": [
        "# this takes too long\n",
        "train_images_shape = train_images.shape\n",
        "for i in range(train_images_shape[0]):\n",
        "  curr_rotate_img = np.rot90(train_images[i].reshape(28,28))\n",
        "  curr_rotate_img = curr_rotate_img.reshape(28*28,)\n",
        "#   print(curr_rotate_img.shape)\n",
        "#   train_images = np.append(train_images, [curr_rotate_img], axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdyJUB_EWR81"
      },
      "source": [
        "### 5. Add additional Dense hidden layers as appropriate to improve the accuracy. Note that you may need to adjust your hyperparameters or other aspects of the network architecture in response to these changes. How does the accuracy for your deep network compare with the accuracy you achieved in experiment (4)?. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GFBOrV0jV3D"
      },
      "source": [
        "# build model\n",
        "model = models.Sequential()\n",
        "model.add(Dense(10000,\n",
        "                input_shape=(28*28,),\n",
        "                kernel_initializer='glorot_normal',\n",
        "                # kernel_regularizer=l2(0.01),\n",
        "                use_bias=False)) # set False if BatchNormalization is used and remove dropout\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU(alpha=0.01))\n",
        "model.add(Dense(10000,\n",
        "                input_shape=(28*28,),\n",
        "                use_bias=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU(alpha=0.01))\n",
        "# model.add(Dense(10000,\n",
        "#                 input_shape=(28*28,),\n",
        "#                 use_bias=False))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(LeakyReLU(alpha=0.01))\n",
        "model.add(Dense(27, activation='softmax'))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sy8nI4xSX_rM",
        "outputId": "90fe1677-95d2-4a86-8645-2338eb25d22c"
      },
      "source": [
        "# compile model (run this)\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "              # optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "callback = EarlyStopping(monitor='accuracy', \n",
        "                         patience=10,\n",
        "                        #  restore_best_weights=False)\n",
        "                         restore_best_weights=True)\n",
        "\n",
        "model.fit(train_images, \n",
        "          train_labels, \n",
        "          epochs=1000, \n",
        "          batch_size=256, \n",
        "          # batch_size=128,\n",
        "          validation_data=(validate_images,validate_labels),\n",
        "          callbacks=[callback],\n",
        "          verbose=1)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "407/407 [==============================] - 29s 62ms/step - loss: 1.4920 - accuracy: 0.7190 - val_loss: 4.8472 - val_accuracy: 0.3054\n",
            "Epoch 2/1000\n",
            "407/407 [==============================] - 26s 63ms/step - loss: 0.4462 - accuracy: 0.8686 - val_loss: 6.9787 - val_accuracy: 0.2312\n",
            "Epoch 3/1000\n",
            "407/407 [==============================] - 27s 66ms/step - loss: 0.3206 - accuracy: 0.8988 - val_loss: 9.6418 - val_accuracy: 0.1205\n",
            "Epoch 4/1000\n",
            "407/407 [==============================] - 28s 69ms/step - loss: 0.2570 - accuracy: 0.9167 - val_loss: 9.4174 - val_accuracy: 0.2268\n",
            "Epoch 5/1000\n",
            "407/407 [==============================] - 27s 66ms/step - loss: 0.2250 - accuracy: 0.9222 - val_loss: 11.3936 - val_accuracy: 0.1780\n",
            "Epoch 6/1000\n",
            "407/407 [==============================] - 27s 66ms/step - loss: 0.2020 - accuracy: 0.9321 - val_loss: 13.4434 - val_accuracy: 0.0942\n",
            "Epoch 7/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.1790 - accuracy: 0.9370 - val_loss: 12.8502 - val_accuracy: 0.1438\n",
            "Epoch 8/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.1528 - accuracy: 0.9451 - val_loss: 14.9954 - val_accuracy: 0.1154\n",
            "Epoch 9/1000\n",
            "407/407 [==============================] - 27s 66ms/step - loss: 0.1295 - accuracy: 0.9513 - val_loss: 14.2590 - val_accuracy: 0.1250\n",
            "Epoch 10/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.1246 - accuracy: 0.9533 - val_loss: 15.1098 - val_accuracy: 0.1038\n",
            "Epoch 11/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.1183 - accuracy: 0.9561 - val_loss: 15.9793 - val_accuracy: 0.1345\n",
            "Epoch 12/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.1286 - accuracy: 0.9546 - val_loss: 16.4209 - val_accuracy: 0.1118\n",
            "Epoch 13/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.1024 - accuracy: 0.9612 - val_loss: 16.9762 - val_accuracy: 0.1289\n",
            "Epoch 14/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0922 - accuracy: 0.9638 - val_loss: 16.6336 - val_accuracy: 0.1258\n",
            "Epoch 15/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0884 - accuracy: 0.9660 - val_loss: 18.3158 - val_accuracy: 0.1040\n",
            "Epoch 16/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0844 - accuracy: 0.9663 - val_loss: 16.8737 - val_accuracy: 0.1120\n",
            "Epoch 17/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0860 - accuracy: 0.9658 - val_loss: 17.6776 - val_accuracy: 0.0884\n",
            "Epoch 18/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0792 - accuracy: 0.9691 - val_loss: 18.4770 - val_accuracy: 0.1071\n",
            "Epoch 19/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0748 - accuracy: 0.9721 - val_loss: 19.4757 - val_accuracy: 0.1022\n",
            "Epoch 20/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0693 - accuracy: 0.9717 - val_loss: 19.7579 - val_accuracy: 0.1036\n",
            "Epoch 21/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0698 - accuracy: 0.9725 - val_loss: 18.5875 - val_accuracy: 0.1109\n",
            "Epoch 22/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0616 - accuracy: 0.9747 - val_loss: 17.3812 - val_accuracy: 0.1188\n",
            "Epoch 23/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0592 - accuracy: 0.9754 - val_loss: 17.0006 - val_accuracy: 0.1198\n",
            "Epoch 24/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0555 - accuracy: 0.9766 - val_loss: 18.7173 - val_accuracy: 0.0900\n",
            "Epoch 25/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0590 - accuracy: 0.9760 - val_loss: 16.8338 - val_accuracy: 0.1067\n",
            "Epoch 26/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0669 - accuracy: 0.9741 - val_loss: 20.2772 - val_accuracy: 0.1054\n",
            "Epoch 27/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0522 - accuracy: 0.9789 - val_loss: 18.6344 - val_accuracy: 0.1152\n",
            "Epoch 28/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0472 - accuracy: 0.9792 - val_loss: 19.5991 - val_accuracy: 0.0976\n",
            "Epoch 29/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0522 - accuracy: 0.9793 - val_loss: 18.5329 - val_accuracy: 0.1025\n",
            "Epoch 30/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0526 - accuracy: 0.9786 - val_loss: 20.8570 - val_accuracy: 0.0982\n",
            "Epoch 31/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0505 - accuracy: 0.9796 - val_loss: 20.3799 - val_accuracy: 0.0750\n",
            "Epoch 32/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0465 - accuracy: 0.9805 - val_loss: 19.4815 - val_accuracy: 0.0865\n",
            "Epoch 33/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0469 - accuracy: 0.9809 - val_loss: 20.0191 - val_accuracy: 0.0690\n",
            "Epoch 34/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0463 - accuracy: 0.9814 - val_loss: 19.4283 - val_accuracy: 0.0737\n",
            "Epoch 35/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0429 - accuracy: 0.9818 - val_loss: 19.9497 - val_accuracy: 0.0742\n",
            "Epoch 36/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0412 - accuracy: 0.9831 - val_loss: 20.2448 - val_accuracy: 0.0741\n",
            "Epoch 37/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0389 - accuracy: 0.9835 - val_loss: 18.9368 - val_accuracy: 0.0743\n",
            "Epoch 38/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0457 - accuracy: 0.9824 - val_loss: 18.6458 - val_accuracy: 0.0831\n",
            "Epoch 39/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0402 - accuracy: 0.9840 - val_loss: 19.1969 - val_accuracy: 0.0707\n",
            "Epoch 40/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0444 - accuracy: 0.9826 - val_loss: 16.4021 - val_accuracy: 0.0999\n",
            "Epoch 41/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0379 - accuracy: 0.9840 - val_loss: 16.9299 - val_accuracy: 0.0820\n",
            "Epoch 42/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0428 - accuracy: 0.9843 - val_loss: 17.4116 - val_accuracy: 0.0832\n",
            "Epoch 43/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0356 - accuracy: 0.9854 - val_loss: 18.3244 - val_accuracy: 0.0684\n",
            "Epoch 44/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0381 - accuracy: 0.9854 - val_loss: 16.9171 - val_accuracy: 0.0718\n",
            "Epoch 45/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0297 - accuracy: 0.9865 - val_loss: 18.7063 - val_accuracy: 0.0731\n",
            "Epoch 46/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0383 - accuracy: 0.9858 - val_loss: 18.9402 - val_accuracy: 0.0706\n",
            "Epoch 47/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0394 - accuracy: 0.9855 - val_loss: 17.2010 - val_accuracy: 0.0809\n",
            "Epoch 48/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0276 - accuracy: 0.9881 - val_loss: 18.9060 - val_accuracy: 0.0702\n",
            "Epoch 49/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0277 - accuracy: 0.9879 - val_loss: 17.4872 - val_accuracy: 0.0763\n",
            "Epoch 50/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0268 - accuracy: 0.9884 - val_loss: 16.6925 - val_accuracy: 0.0797\n",
            "Epoch 51/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0344 - accuracy: 0.9867 - val_loss: 16.4123 - val_accuracy: 0.0723\n",
            "Epoch 52/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0352 - accuracy: 0.9864 - val_loss: 16.3750 - val_accuracy: 0.0676\n",
            "Epoch 53/1000\n",
            "407/407 [==============================] - 27s 66ms/step - loss: 0.0277 - accuracy: 0.9882 - val_loss: 16.5442 - val_accuracy: 0.0668\n",
            "Epoch 54/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0312 - accuracy: 0.9885 - val_loss: 14.9145 - val_accuracy: 0.0743\n",
            "Epoch 55/1000\n",
            "407/407 [==============================] - 27s 66ms/step - loss: 0.0240 - accuracy: 0.9896 - val_loss: 14.5315 - val_accuracy: 0.0751\n",
            "Epoch 56/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0282 - accuracy: 0.9886 - val_loss: 15.7366 - val_accuracy: 0.0659\n",
            "Epoch 57/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0315 - accuracy: 0.9881 - val_loss: 15.8725 - val_accuracy: 0.0685\n",
            "Epoch 58/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0272 - accuracy: 0.9901 - val_loss: 14.4234 - val_accuracy: 0.0748\n",
            "Epoch 59/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0292 - accuracy: 0.9898 - val_loss: 15.8667 - val_accuracy: 0.0555\n",
            "Epoch 60/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0237 - accuracy: 0.9913 - val_loss: 15.9742 - val_accuracy: 0.0720\n",
            "Epoch 61/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0202 - accuracy: 0.9924 - val_loss: 14.8933 - val_accuracy: 0.0739\n",
            "Epoch 62/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0208 - accuracy: 0.9920 - val_loss: 15.1041 - val_accuracy: 0.0749\n",
            "Epoch 63/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0279 - accuracy: 0.9897 - val_loss: 13.0419 - val_accuracy: 0.0942\n",
            "Epoch 64/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0251 - accuracy: 0.9909 - val_loss: 13.9517 - val_accuracy: 0.0861\n",
            "Epoch 65/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0204 - accuracy: 0.9919 - val_loss: 13.9489 - val_accuracy: 0.0763\n",
            "Epoch 66/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0237 - accuracy: 0.9914 - val_loss: 13.5590 - val_accuracy: 0.0680\n",
            "Epoch 67/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0183 - accuracy: 0.9925 - val_loss: 13.9102 - val_accuracy: 0.0722\n",
            "Epoch 68/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0192 - accuracy: 0.9927 - val_loss: 13.7213 - val_accuracy: 0.0734\n",
            "Epoch 69/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0239 - accuracy: 0.9915 - val_loss: 14.0457 - val_accuracy: 0.0752\n",
            "Epoch 70/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0258 - accuracy: 0.9915 - val_loss: 14.8401 - val_accuracy: 0.0594\n",
            "Epoch 71/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0215 - accuracy: 0.9922 - val_loss: 12.7701 - val_accuracy: 0.0737\n",
            "Epoch 72/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0168 - accuracy: 0.9936 - val_loss: 13.2535 - val_accuracy: 0.0642\n",
            "Epoch 73/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0174 - accuracy: 0.9941 - val_loss: 13.5974 - val_accuracy: 0.0458\n",
            "Epoch 74/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0161 - accuracy: 0.9940 - val_loss: 12.7442 - val_accuracy: 0.0615\n",
            "Epoch 75/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0168 - accuracy: 0.9937 - val_loss: 11.5732 - val_accuracy: 0.0745\n",
            "Epoch 76/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0202 - accuracy: 0.9931 - val_loss: 10.9777 - val_accuracy: 0.0746\n",
            "Epoch 77/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0257 - accuracy: 0.9930 - val_loss: 12.5808 - val_accuracy: 0.0709\n",
            "Epoch 78/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0235 - accuracy: 0.9947 - val_loss: 12.7223 - val_accuracy: 0.0629\n",
            "Epoch 79/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0269 - accuracy: 0.9934 - val_loss: 13.8663 - val_accuracy: 0.0734\n",
            "Epoch 80/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0137 - accuracy: 0.9957 - val_loss: 15.2972 - val_accuracy: 0.0709\n",
            "Epoch 81/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0110 - accuracy: 0.9959 - val_loss: 14.9426 - val_accuracy: 0.0734\n",
            "Epoch 82/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0116 - accuracy: 0.9962 - val_loss: 14.2781 - val_accuracy: 0.0640\n",
            "Epoch 83/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0142 - accuracy: 0.9949 - val_loss: 14.3803 - val_accuracy: 0.0733\n",
            "Epoch 84/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 14.4771 - val_accuracy: 0.0663\n",
            "Epoch 85/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0174 - accuracy: 0.9942 - val_loss: 13.4592 - val_accuracy: 0.0720\n",
            "Epoch 86/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 13.1581 - val_accuracy: 0.0687\n",
            "Epoch 87/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0157 - accuracy: 0.9942 - val_loss: 12.4192 - val_accuracy: 0.0698\n",
            "Epoch 88/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0155 - accuracy: 0.9945 - val_loss: 12.6245 - val_accuracy: 0.0650\n",
            "Epoch 89/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0107 - accuracy: 0.9960 - val_loss: 11.9996 - val_accuracy: 0.0677\n",
            "Epoch 90/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 12.6962 - val_accuracy: 0.0658\n",
            "Epoch 91/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0179 - accuracy: 0.9946 - val_loss: 13.2935 - val_accuracy: 0.0538\n",
            "Epoch 92/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0150 - accuracy: 0.9956 - val_loss: 11.8803 - val_accuracy: 0.0645\n",
            "Epoch 93/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 11.8303 - val_accuracy: 0.0588\n",
            "Epoch 94/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0135 - accuracy: 0.9960 - val_loss: 11.7879 - val_accuracy: 0.0555\n",
            "Epoch 95/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0148 - accuracy: 0.9963 - val_loss: 11.6050 - val_accuracy: 0.0748\n",
            "Epoch 96/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0133 - accuracy: 0.9959 - val_loss: 11.7077 - val_accuracy: 0.0662\n",
            "Epoch 97/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0117 - accuracy: 0.9966 - val_loss: 11.9754 - val_accuracy: 0.0624\n",
            "Epoch 98/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0131 - accuracy: 0.9968 - val_loss: 12.5749 - val_accuracy: 0.0511\n",
            "Epoch 99/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 11.5803 - val_accuracy: 0.0613\n",
            "Epoch 100/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 12.1858 - val_accuracy: 0.0525\n",
            "Epoch 101/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 12.4376 - val_accuracy: 0.0484\n",
            "Epoch 102/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 12.6096 - val_accuracy: 0.0503\n",
            "Epoch 103/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 11.7405 - val_accuracy: 0.0502\n",
            "Epoch 104/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 12.0978 - val_accuracy: 0.0465\n",
            "Epoch 105/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0130 - accuracy: 0.9961 - val_loss: 12.1022 - val_accuracy: 0.0440\n",
            "Epoch 106/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0144 - accuracy: 0.9964 - val_loss: 12.1962 - val_accuracy: 0.0522\n",
            "Epoch 107/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0116 - accuracy: 0.9978 - val_loss: 11.9179 - val_accuracy: 0.0520\n",
            "Epoch 108/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 12.2027 - val_accuracy: 0.0483\n",
            "Epoch 109/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 13.1553 - val_accuracy: 0.0434\n",
            "Epoch 110/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 12.4413 - val_accuracy: 0.0456\n",
            "Epoch 111/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 12.4972 - val_accuracy: 0.0452\n",
            "Epoch 112/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 12.4289 - val_accuracy: 0.0433\n",
            "Epoch 113/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 11.5909 - val_accuracy: 0.0450\n",
            "Epoch 114/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 10.9483 - val_accuracy: 0.0453\n",
            "Epoch 115/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 10.8849 - val_accuracy: 0.0471\n",
            "Epoch 116/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 9.5988 - val_accuracy: 0.0543\n",
            "Epoch 117/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0122 - accuracy: 0.9968 - val_loss: 9.1435 - val_accuracy: 0.0635\n",
            "Epoch 118/1000\n",
            "407/407 [==============================] - 27s 67ms/step - loss: 0.0100 - accuracy: 0.9978 - val_loss: 9.2702 - val_accuracy: 0.0690\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fde0c2ee850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaqcHhQOYDsf",
        "outputId": "b30d94d8-7f3d-41e1-d912-9fbfe8dd1898"
      },
      "source": [
        "# run model against TEST SET\n",
        "test_lost, test_acc = model.evaluate(test_images, test_labels)\n",
        "\n",
        "# get accuracy\n",
        "print('Test Accuracy: ', test_acc)\n",
        "deep_net_model_acc = test_acc"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "650/650 [==============================] - 3s 4ms/step - loss: 0.7852 - accuracy: 0.9169\n",
            "Test Accuracy:  0.9168750047683716\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pEBJ63WYHEG",
        "outputId": "0823492e-c482-4e09-90ac-712545a5c5aa"
      },
      "source": [
        "print(f'Improvement/Loss accuracy: {(deep_net_model_acc - modified_model_acc)*100}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Improvement/Loss accuracy: 1.7980754375457764\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBOMiomP6UmP"
      },
      "source": [
        "How does the accuracy for your deep network compare with the accuracy you achieved in experiment (4)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnUtzebW6LiB",
        "outputId": "08152f8b-18fd-4cdb-bef9-bb8e9735c837"
      },
      "source": [
        "print(f\"Test accuracy of experience (4): {modified_model_acc}\")\n",
        "print(f\"Test accuracy of experience (5): {deep_net_model_acc}\")\n",
        "print(f\"Improvement/Loss accuracy between (4) and (5): {(deep_net_model_acc - modified_model_acc)*100}\")"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy of experience (4): 0.906826913356781\n",
            "Test accuracy of experience (5): 0.9168750047683716\n",
            "Improvement/Loss accuracy between (4) and (5): 1.0048091411590576\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mt3HKgIwZfs5"
      },
      "source": [
        "### 6. When finished tuning, evaluate your results on the test set. Compare the test performance of your original network from experiment (2) and the final networks for experiments (3) and (4)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlFUl1yUZs6G",
        "outputId": "ff7e2d42-277a-45dc-a325-1783d3b5d7f7"
      },
      "source": [
        "print(f\"Test accuracy of experience (2): {orginal_model_acc}\")\n",
        "print(f\"Test accuracy of experience (3): {modified_org_model_acc}\")\n",
        "print(f\"Test accuracy of experience (4): {modified_model_acc}\")"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy of experience (2): 0.8962019085884094\n",
            "Test accuracy of experience (3): 0.9012019038200378\n",
            "Test accuracy of experience (4): 0.906826913356781\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tpiqsuo6uYe"
      },
      "source": [
        "- Increase the number of neuron in experiment (3)compare with (2), it doesn't improve much. \n",
        "- Even in eperiment (4) we try tune parameters to make improvement compare with (2), the training process experiment(4) run faster and test accuracy doesn't improve much. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5x5qZ8vNhF8o"
      },
      "source": [
        "### 7. Use plt.imshow() to view some of the misclassified images and examine their labels. Describe what you think might have gone wrong."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGti5fAaxUzR",
        "outputId": "85ae5cb6-4728-4882-b46e-8d61e71acd32"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 10000)             7840000   \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 10000)             40000     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 10000)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10000)             100000000 \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 10000)             40000     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 10000)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 27)                270027    \n",
            "=================================================================\n",
            "Total params: 108,190,027\n",
            "Trainable params: 108,150,027\n",
            "Non-trainable params: 40,000\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayux-3cvto5e"
      },
      "source": [
        "misclassificationIdx = []\n",
        "for idx,img in enumerate(test_images[:200]):\n",
        "  pred = model.predict(img.reshape(1,28*28))\n",
        "  pred_letter = chr(np.argmax(pred) - 1 + ord('A'))\n",
        "  target_letter = chr(np.argmax(test_labels[idx]) - 1 + ord('A'))\n",
        "  if pred_letter != target_letter:\n",
        "    misclassificationIdx.append(idx)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYVTEREdvLsU",
        "outputId": "f1cd9566-b96a-4ab8-c070-62d7bb1ff458"
      },
      "source": [
        "print(misclassificationIdx)\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[33, 44, 51, 76, 90, 119, 128, 129, 132, 164]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "IYnvWwSH2Ljh",
        "outputId": "d98616a0-60e7-485f-8d4b-72a6343be29b"
      },
      "source": [
        "plt.imshow(test_images[misclassificationIdx[0]].reshape(28,28))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fdd6136e290>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "1YVBffhK2aIz",
        "outputId": "47a1479f-8228-41f4-fa79-0e475433ab5e"
      },
      "source": [
        "plt.imshow(test_images[misclassificationIdx[1]].reshape(28,28))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fdd61abfc90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "tCWqOkSa2za9",
        "outputId": "715026ca-ef29-499e-ca15-8864f5f53042"
      },
      "source": [
        "plt.imshow(test_images[misclassificationIdx[2]].reshape(28,28))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fdd61197850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "02OzTtiy26iG",
        "outputId": "88b316c1-cb63-4333-e63e-13a0f22bc340"
      },
      "source": [
        "plt.imshow(test_images[misclassificationIdx[3]].reshape(28,28))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fdd61a32c90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "1NTUvuJQ290H",
        "outputId": "0aea25a9-8922-470c-dc22-c7466cb9aabe"
      },
      "source": [
        "plt.imshow(test_images[misclassificationIdx[4]].reshape(28,28))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fdd61582d10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "iAvx8oKw3A-u",
        "outputId": "5b479b2e-1f83-499d-9901-f24aee64165f"
      },
      "source": [
        "plt.imshow(test_images[misclassificationIdx[5]].reshape(28,28))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fdd61c7ef50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "1sLxJTNa3Dhn",
        "outputId": "16d6ea88-2226-4064-f986-ab17677aa2b1"
      },
      "source": [
        "plt.imshow(test_images[misclassificationIdx[6]].reshape(28,28))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fdd61bf1e90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "JglrPtZt3FxZ",
        "outputId": "fd4fb83d-d401-4c83-cb67-354f6e0de1ce"
      },
      "source": [
        "plt.imshow(test_images[misclassificationIdx[7]].reshape(28,28))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fdd61ca8090>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "_t0TiqN93ILl",
        "outputId": "2e0aea32-92cf-47cf-916b-7e665f02c393"
      },
      "source": [
        "plt.imshow(test_images[misclassificationIdx[8]].reshape(28,28))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fdd62d5e610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "uf2VKM793KVK",
        "outputId": "d8f0d5cd-68f3-4f56-9b0e-951bfaa44d9d"
      },
      "source": [
        "plt.imshow(test_images[misclassificationIdx[9]].reshape(28,28))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fdd6155ff10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVuFJY3M4f4c"
      },
      "source": [
        "Describe what you think might have gone wrong:\n",
        "First of all, with human eye there is a couple image we couldn't recognize it. Secondly, different people will have different ways to write the same letter or penmanship."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj4orlO33N0w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}