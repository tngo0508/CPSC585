{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "warming-section",
   "metadata": {},
   "source": [
    "# Thomas Ngo\n",
    "# Tevin Vu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-basketball",
   "metadata": {},
   "source": [
    "# 1. Use from dataset import * to load the module, then examine TRAINING_SET, TEST_SET, and MESSAGE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "compact-judgment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import sys\n",
    "import string\n",
    "\n",
    "from dataset import *\n",
    "from numpy.random import default_rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eight-biology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1], 'A')\n"
     ]
    }
   ],
   "source": [
    "print(TRAINING_SET[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "advanced-editing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1], 'A')\n"
     ]
    }
   ],
   "source": [
    "print(TEST_SET[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "laughing-trigger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(MESSAGE[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-arabic",
   "metadata": {},
   "source": [
    "# 2. In order to use the images in TRAINING_SET, TEST_SET, and MESSAGE, convert them into two-dimensional NumPy arrays of feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bright-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_2d(dataset):\n",
    "    copyDataset = copy.deepcopy(dataset)\n",
    "    if len(copyDataset) == 0: return None\n",
    "    res = []\n",
    "    if len(copyDataset[0]) == 2:\n",
    "        for x, _ in(copyDataset):\n",
    "            x.insert(0,1)            # include bias\n",
    "            res.append(np.array(x))\n",
    "    else:\n",
    "        for x in(copyDataset):\n",
    "            x.insert(0,1)            # include bias\n",
    "            res.append(np.array(x))\n",
    "    \n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "wooden-zimbabwe",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SET_2D = convert_to_2d(TRAINING_SET)\n",
    "TEST_SET_2D = convert_to_2d(TEST_SET)\n",
    "MESSAGE_2D = convert_to_2d(MESSAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aggressive-basin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 36)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_SET_2D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "executed-yukon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 36)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_SET_2D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "promising-jesus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 36)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MESSAGE_2D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "perceived-jonathan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, ..., 0, 0, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 0],\n",
       "       [1, 0, 1, ..., 1, 1, 0],\n",
       "       ...,\n",
       "       [1, 1, 0, ..., 0, 0, 1],\n",
       "       [1, 1, 0, ..., 1, 0, 0],\n",
       "       [1, 1, 1, ..., 1, 1, 1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_SET_2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-oklahoma",
   "metadata": {},
   "source": [
    "# 3. Implementing a Python function show(image) to reshape a one-dimensional feature vector into a 7√ó5 array, then print() the image. Test this function on some of the images in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "median-reason",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    reshaped_img = np.reshape(np.array(img), (7,5))\n",
    "#     print(reshaped_img)\n",
    "    rows = len(reshaped_img)\n",
    "    cols = len(reshaped_img[0])\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            if reshaped_img[row][col] == 1:\n",
    "                print('#', end='')\n",
    "            else:\n",
    "                print(' ', end='')\n",
    "        print('\\n', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "hydraulic-peeing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ### \n",
      "#   #\n",
      "#   #\n",
      "#   #\n",
      "#####\n",
      "#   #\n",
      "#   #\n"
     ]
    }
   ],
   "source": [
    "show(TRAINING_SET[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-monaco",
   "metadata": {},
   "source": [
    "# 4.In order to use the character labels in TRAINING_SET and TEST_SET, convert them into an integer class vector using ord(), then use NumPy to convert them into 26 one-hot encoded vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "three-storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://www.kite.com/python/answers/how-to-do-one-hot-encoding-with-numpy-in-python\n",
    "\n",
    "def convert_labels_to_int(dataset):\n",
    "    res = []\n",
    "    for _, letter in dataset:\n",
    "        res.append(ord(letter)-ord('A'))\n",
    "    tempRes = np.array(res)\n",
    "    print(tempRes)\n",
    "    shape = (tempRes.size, tempRes.max() + 1)\n",
    "    print(shape)\n",
    "    one_hot = np.zeros(shape)\n",
    "    rows = np.arange(tempRes.size)\n",
    "    print(rows)\n",
    "    one_hot[rows, tempRes] = 1 # using fancy index\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "descending-belle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21\n",
      " 22 23 24 25]\n",
      "(52, 26)\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51]\n",
      "(52, 26)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_SET_LABELS = convert_labels_to_int(TRAINING_SET)\n",
    "print(TRAINING_SET_LABELS.shape)\n",
    "TRAINING_SET_LABELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-enhancement",
   "metadata": {},
   "source": [
    "# 5. Implement a multiclass perceptron as described in Section 2.3.1 of the textbook to recognize the letters A-Z.\n",
    "## Begin with weights initialized to random values and a learning rate of ùõº = 0.01. Predict the letter by choosing the class with the largest WÃÖr‚àôXÃÖi value.\n",
    "##  If the prediction is incorrect, train the multiclass perceptron by applying the update rule of Equation 2.24 in the textbook. Continue training until all items in the training set are correctly classified.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "satellite-witness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use while-loop and no epochs\n",
    "def check_for_misclassification(epochs, W, X_train):\n",
    "    N = len(X_train)\n",
    "    misclassification = 0\n",
    "    pred_idx = 0\n",
    "    for i in range(N):\n",
    "        if pred_idx == 26:\n",
    "            pred_idx = 0\n",
    "        ascii_idx = np.argmax(np.matmul(W, X_train[i]))\n",
    "        y_pred = chr(ascii_idx + ord('A'))\n",
    "        if y_pred != string.ascii_uppercase[pred_idx]:\n",
    "            misclassification += 1\n",
    "        pred_idx += 1\n",
    "    print(f'Epoch {epochs} - Accuracy: {N - misclassification}/{N}')\n",
    "    return misclassification\n",
    "    \n",
    "    \n",
    "def train(data_train, target_train):\n",
    "    ALPHA = 0.01\n",
    "    \n",
    "    D = len(data_train[0])             # dimensions (including bias)\n",
    "    N = len(data_train)                # training instance\n",
    "    P = len(string.ascii_uppercase)    # number of perceptrons\n",
    "    \n",
    "    rng = default_rng()\n",
    "    W = rng.uniform(-1, +1, (P, D))\n",
    "    X_train = data_train\n",
    "    Y_train = target_train\n",
    "    \n",
    "    idx = np.arange(N)\n",
    "    w_idx = 0\n",
    "    misclassification = 0\n",
    "    epochs = 0\n",
    "    while True:\n",
    "        for i in range(N):\n",
    "            if w_idx == P:\n",
    "                w_idx = 0\n",
    "            Y_hat = np.dot(W, X_train[i])\n",
    "            y_pred_idx = np.argmax(Y_hat)\n",
    "\n",
    "            # prediction is incorrect, use update rule of equation 2.24 in textbook\n",
    "            if Y_train[i][y_pred_idx] == 0:\n",
    "                W[w_idx] = W[w_idx] + ALPHA * X_train[i]\n",
    "                W[y_pred_idx] = W[y_pred_idx] + (-ALPHA * X_train[i])\n",
    "            w_idx += 1\n",
    "            \n",
    "        # check if all items in the training set are correctly classified\n",
    "        misclassification = check_for_misclassification(epochs, W, X_train)\n",
    "        if misclassification == 0:\n",
    "            print('All items are correctly classified')\n",
    "            print(f'number of epochs: {epochs}')\n",
    "            return W\n",
    "        else:\n",
    "            misclassification = 0\n",
    "        epochs += 1\n",
    "    return W "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "korean-diamond",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Accuracy: 4/52\n",
      "Epoch 1 - Accuracy: 3/52\n",
      "Epoch 2 - Accuracy: 3/52\n",
      "Epoch 3 - Accuracy: 3/52\n",
      "Epoch 4 - Accuracy: 4/52\n",
      "Epoch 5 - Accuracy: 5/52\n",
      "Epoch 6 - Accuracy: 6/52\n",
      "Epoch 7 - Accuracy: 7/52\n",
      "Epoch 8 - Accuracy: 8/52\n",
      "Epoch 9 - Accuracy: 9/52\n",
      "Epoch 10 - Accuracy: 9/52\n",
      "Epoch 11 - Accuracy: 11/52\n",
      "Epoch 12 - Accuracy: 15/52\n",
      "Epoch 13 - Accuracy: 16/52\n",
      "Epoch 14 - Accuracy: 17/52\n",
      "Epoch 15 - Accuracy: 21/52\n",
      "Epoch 16 - Accuracy: 20/52\n",
      "Epoch 17 - Accuracy: 24/52\n",
      "Epoch 18 - Accuracy: 24/52\n",
      "Epoch 19 - Accuracy: 19/52\n",
      "Epoch 20 - Accuracy: 24/52\n",
      "Epoch 21 - Accuracy: 23/52\n",
      "Epoch 22 - Accuracy: 26/52\n",
      "Epoch 23 - Accuracy: 27/52\n",
      "Epoch 24 - Accuracy: 30/52\n",
      "Epoch 25 - Accuracy: 29/52\n",
      "Epoch 26 - Accuracy: 36/52\n",
      "Epoch 27 - Accuracy: 38/52\n",
      "Epoch 28 - Accuracy: 41/52\n",
      "Epoch 29 - Accuracy: 38/52\n",
      "Epoch 30 - Accuracy: 40/52\n",
      "Epoch 31 - Accuracy: 43/52\n",
      "Epoch 32 - Accuracy: 42/52\n",
      "Epoch 33 - Accuracy: 45/52\n",
      "Epoch 34 - Accuracy: 45/52\n",
      "Epoch 35 - Accuracy: 44/52\n",
      "Epoch 36 - Accuracy: 42/52\n",
      "Epoch 37 - Accuracy: 47/52\n",
      "Epoch 38 - Accuracy: 43/52\n",
      "Epoch 39 - Accuracy: 40/52\n",
      "Epoch 40 - Accuracy: 47/52\n",
      "Epoch 41 - Accuracy: 44/52\n",
      "Epoch 42 - Accuracy: 47/52\n",
      "Epoch 43 - Accuracy: 49/52\n",
      "Epoch 44 - Accuracy: 47/52\n",
      "Epoch 45 - Accuracy: 48/52\n",
      "Epoch 46 - Accuracy: 47/52\n",
      "Epoch 47 - Accuracy: 52/52\n",
      "All items are correctly classified\n",
      "number of epochs: 47\n",
      "(26, 36)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-4.95999572e-01, -6.90368687e-01,  3.83840079e-01,\n",
       "        -2.12482219e-01,  2.93956784e-01, -4.99503503e-01,\n",
       "         7.38728292e-01,  4.33950422e-01, -6.56363242e-01,\n",
       "        -2.73963186e-01,  4.35544119e-01, -2.07062657e-01,\n",
       "         2.18344734e-01, -2.07456454e-01,  6.57367554e-01,\n",
       "         3.42926702e-01, -2.31676680e-01, -2.39311445e-01,\n",
       "         4.85474870e-01,  4.73257049e-01, -2.63514382e-01,\n",
       "        -1.06024499e-01,  5.98318671e-01,  1.03115915e+00,\n",
       "         6.14131858e-01,  1.08335074e+00, -6.34051603e-01,\n",
       "        -2.83243155e-01, -7.23172527e-01, -9.44674095e-01,\n",
       "        -4.85443178e-01, -2.63726897e-01,  2.98735762e-01,\n",
       "        -8.98441924e-01, -2.12707402e-01,  1.08298973e+00],\n",
       "       [-7.65452257e-01,  9.39356768e-01, -2.07981979e-01,\n",
       "         8.23802715e-01, -1.81218973e-01, -6.99838891e-01,\n",
       "         4.54862281e-01, -1.93400449e-01, -6.32940088e-01,\n",
       "        -2.49623022e-01,  5.42241305e-01, -8.00894988e-01,\n",
       "         3.56942968e-01,  3.91772613e-01, -2.65581155e-01,\n",
       "        -8.55779531e-01, -9.25308518e-02,  1.32139024e-01,\n",
       "         1.78279509e-02,  3.97943108e-01,  4.56142097e-01,\n",
       "         1.86280014e-01, -8.49912413e-01, -2.07840880e-01,\n",
       "        -3.13106665e-01, -5.60390054e-01,  3.52430391e-01,\n",
       "         6.98548095e-01, -4.27462392e-01,  6.21009063e-01,\n",
       "         3.79584038e-01,  4.14304068e-01, -2.50736400e-01,\n",
       "        -5.08216985e-01,  9.43293907e-01, -1.19256485e-01],\n",
       "       [-2.77559826e-01, -9.92131979e-01, -1.13903351e-01,\n",
       "         7.10758646e-01,  7.72308003e-01,  9.53065394e-01,\n",
       "         1.37152751e-01, -5.95290866e-01,  6.45857906e-01,\n",
       "         2.31609874e-01, -2.69548686e-01,  9.05489017e-01,\n",
       "        -5.29434534e-01, -9.43309353e-01, -9.80859671e-01,\n",
       "        -6.06821917e-01, -3.95275583e-01,  2.19840621e-01,\n",
       "        -7.35791172e-01, -3.30110471e-01,  5.21268051e-01,\n",
       "         8.92574718e-01,  3.17668725e-01,  4.37537757e-01,\n",
       "         2.94946754e-01, -5.67633856e-01, -7.98189244e-01,\n",
       "        -9.21634238e-01,  4.69088711e-01,  8.95535520e-01,\n",
       "        -1.66991179e-01,  1.54551854e-01,  1.62941994e-01,\n",
       "         2.77872017e-01,  7.01072174e-02, -8.00832745e-01],\n",
       "       [ 6.29040603e-01,  5.19897291e-01,  6.73654424e-01,\n",
       "         3.71880956e-01,  5.11308413e-01,  3.17366955e-01,\n",
       "         6.61839390e-01, -1.81728573e-03, -9.14679767e-01,\n",
       "         8.45352850e-01, -4.56277061e-01, -9.33466928e-01,\n",
       "        -6.46155510e-01, -7.94518376e-01,  2.52889144e-01,\n",
       "         8.06460446e-01, -7.39923071e-01, -1.09259830e+00,\n",
       "        -1.00004696e+00,  2.82553359e-01, -4.80371110e-01,\n",
       "        -4.83543012e-01, -7.65079995e-01, -1.36170039e-01,\n",
       "        -6.94521884e-01,  4.26221411e-01, -4.21369277e-01,\n",
       "         6.07349417e-01,  7.08339556e-02, -4.15277802e-02,\n",
       "         7.44867786e-01,  9.22744419e-01, -1.73231897e-02,\n",
       "         5.10627706e-01, -9.03427830e-01, -6.29837222e-01],\n",
       "       [-2.41780381e-01, -5.40472673e-01,  5.32337922e-01,\n",
       "         7.91809844e-01,  2.92066011e-01,  6.13061328e-01,\n",
       "         2.05270452e-01,  6.86007628e-01,  4.46883094e-01,\n",
       "         3.10516757e-01,  1.14441425e-01, -6.04071107e-02,\n",
       "         9.20572557e-01, -2.54946012e-01, -1.67680152e-01,\n",
       "        -2.10914532e-01,  5.68043272e-01,  6.21044375e-01,\n",
       "        -9.87323287e-01,  2.96111661e-01, -1.01127714e+00,\n",
       "        -4.00136752e-01,  6.93934429e-02,  5.95982001e-01,\n",
       "         4.42008854e-01, -2.21875247e-01, -7.00664380e-01,\n",
       "         1.45831865e-01, -5.48308583e-01, -8.37511910e-01,\n",
       "         2.63078290e-01,  7.67937237e-01, -5.96652807e-01,\n",
       "         3.85209813e-01, -4.53169697e-01,  7.72205112e-01],\n",
       "       [ 5.25898767e-01,  6.42664015e-01,  8.24229943e-01,\n",
       "        -6.62087041e-01,  1.04725289e+00,  2.52932884e-01,\n",
       "        -7.80483313e-01, -5.09484358e-01, -3.33178315e-01,\n",
       "        -5.00788139e-01,  1.13668968e-01,  4.42867444e-01,\n",
       "        -3.79825934e-01,  2.88499764e-01, -5.03446091e-02,\n",
       "         4.22832949e-01,  1.33557669e-02, -1.54278218e-01,\n",
       "        -6.54614201e-01,  1.95883211e-01,  5.41467722e-01,\n",
       "         3.65972670e-02, -6.25301647e-01,  4.52196739e-03,\n",
       "        -6.56402898e-01, -2.25242063e-01, -8.48570018e-01,\n",
       "         6.98306934e-01,  2.86658393e-01, -7.00903634e-01,\n",
       "         3.15501598e-01,  1.01014785e+00, -7.61456714e-01,\n",
       "        -8.62007609e-01,  2.76824761e-01, -1.01569401e+00],\n",
       "       [-2.31876331e-01,  4.50764736e-01,  3.44409900e-01,\n",
       "         2.89185815e-01,  9.77682706e-01,  4.46352112e-01,\n",
       "         9.87975779e-01, -9.48596332e-01,  7.39410604e-01,\n",
       "        -9.35770997e-01, -5.58272001e-01, -9.26415405e-01,\n",
       "         8.52671263e-01, -5.62647085e-01, -1.00804827e+00,\n",
       "        -8.39578893e-01, -4.16807558e-01,  4.12829558e-01,\n",
       "        -8.43680890e-01,  9.55167903e-02,  3.67083698e-01,\n",
       "         2.32797570e-01,  8.77188491e-01, -3.90753384e-01,\n",
       "         1.45370838e-01,  8.24895471e-01,  8.41155762e-01,\n",
       "         9.79640779e-01,  3.10551586e-01, -9.57112044e-01,\n",
       "         3.22597407e-01, -1.02362060e+00, -2.72888461e-01,\n",
       "        -3.98627470e-01, -3.03897795e-01,  4.79120431e-01],\n",
       "       [-2.80895416e-01, -6.98768384e-01, -2.57778136e-01,\n",
       "        -5.65684546e-01,  5.01055550e-01,  2.15431420e-01,\n",
       "         6.71519120e-01,  5.56860340e-01, -2.68882048e-01,\n",
       "        -3.34431737e-04,  4.49993909e-01,  1.36344546e-01,\n",
       "         8.41942125e-01,  6.31464636e-02, -9.62597953e-01,\n",
       "        -1.72222490e-01,  3.62397162e-01,  9.24277311e-01,\n",
       "        -4.21746985e-01, -1.67598956e-01,  3.43350217e-01,\n",
       "        -2.08782031e-01,  4.58288430e-01, -8.25198178e-01,\n",
       "        -2.98228800e-01, -6.23876525e-01,  4.80895120e-01,\n",
       "         5.87982592e-01,  2.70519883e-01, -2.62512195e-01,\n",
       "         2.08684432e-01,  7.10022322e-01, -7.54738015e-01,\n",
       "         6.23308603e-01,  3.22003712e-01, -3.43852282e-01],\n",
       "       [-9.85582384e-01,  1.42322812e-01, -7.56146722e-01,\n",
       "         2.61902106e-01, -1.91623741e-01,  3.27127094e-01,\n",
       "        -7.92743256e-01, -7.60385940e-01, -4.71553360e-01,\n",
       "         4.63389623e-01,  9.23358895e-02,  3.96008395e-01,\n",
       "         7.63685868e-01,  8.38487690e-01, -3.94952751e-01,\n",
       "         2.34835969e-01,  5.29827419e-01,  5.66254441e-03,\n",
       "         7.92335037e-01,  3.32614985e-01,  3.94483994e-01,\n",
       "         1.51726576e-01,  2.67135723e-01,  1.05499938e+00,\n",
       "         2.35562367e-01, -9.37499100e-01, -8.53003462e-01,\n",
       "         7.44108593e-01, -4.02804398e-01, -1.02491663e+00,\n",
       "         2.87535892e-01,  5.77026292e-01, -1.62292611e-01,\n",
       "         8.00270229e-01,  1.06927057e+00, -9.62650163e-01],\n",
       "       [ 8.56631288e-02, -7.57426499e-01, -1.19147547e+00,\n",
       "         5.83922857e-01,  9.81343211e-01,  3.95494179e-02,\n",
       "         3.20469157e-01,  9.08929529e-01,  2.73411281e-01,\n",
       "        -6.32880191e-01,  1.94443841e-02, -5.03395897e-01,\n",
       "         7.61024956e-02, -1.50533948e-01,  1.07379018e-01,\n",
       "         6.63457716e-01, -1.96519201e-01, -7.16657642e-01,\n",
       "         4.53864020e-01,  1.10091704e+00,  9.28393665e-01,\n",
       "        -6.99569002e-01, -1.46866291e-01,  2.02981051e-01,\n",
       "         4.30525440e-01,  6.84493276e-01,  6.86289519e-01,\n",
       "        -4.96814485e-02,  7.16970370e-01, -7.06630325e-01,\n",
       "        -6.32550133e-01, -9.90171237e-01,  6.34732510e-02,\n",
       "         4.36233857e-02, -6.20600601e-01,  1.32083503e-01],\n",
       "       [ 6.15094379e-01, -6.54245894e-01,  8.80778769e-01,\n",
       "        -6.34500455e-02, -6.46672938e-01,  3.11093656e-01,\n",
       "         2.09824758e-01, -8.19294419e-01, -7.07518529e-03,\n",
       "         2.87738245e-01, -5.38233778e-01,  6.44191953e-01,\n",
       "        -2.96598446e-01, -1.68592906e-01,  8.44458510e-01,\n",
       "        -3.55461504e-01,  7.64867248e-01, -3.95978581e-01,\n",
       "        -8.88420396e-01, -9.52593854e-01,  2.48967309e-01,\n",
       "        -6.97198337e-01,  4.61687694e-01,  1.12037898e-01,\n",
       "         9.29067865e-01, -1.02096355e+00,  1.01977015e-01,\n",
       "         2.83810231e-01, -5.10499557e-01,  8.26676060e-01,\n",
       "         8.70786054e-01, -2.37984435e-01, -8.22333318e-01,\n",
       "        -1.44755532e-01, -2.85942475e-01, -4.56059093e-02],\n",
       "       [-6.93255087e-01, -3.68925196e-01, -1.09417721e+00,\n",
       "         5.87102586e-01, -3.91796509e-01, -5.03545845e-02,\n",
       "         8.43756346e-01,  5.55804372e-01, -7.84421585e-01,\n",
       "         2.32646092e-01, -8.50740106e-01,  8.03710516e-01,\n",
       "         2.75835389e-01,  5.84673170e-01, -1.43160938e-01,\n",
       "         6.62430350e-01,  1.52180388e-01,  1.11658480e-01,\n",
       "        -1.39235818e-01,  4.80879307e-01,  7.41332223e-01,\n",
       "         2.59897018e-01, -3.87458284e-01, -2.33328133e-01,\n",
       "        -5.63629072e-01, -9.10182907e-01, -5.16176202e-01,\n",
       "         6.59745124e-01, -7.59651531e-01, -4.05315502e-01,\n",
       "        -8.40992060e-01, -4.54633957e-02,  4.38171292e-01,\n",
       "         5.19033315e-01,  1.00868588e+00, -1.28380739e-01],\n",
       "       [-1.66302298e-01, -9.28879074e-02, -7.85334095e-01,\n",
       "         1.83706459e-01,  2.23256020e-01,  8.25641475e-02,\n",
       "         3.24644111e-01,  1.21963444e+00, -8.27877293e-01,\n",
       "        -3.01838436e-01,  8.08239364e-02,  3.44957741e-01,\n",
       "        -5.49902990e-01,  6.58406363e-01, -2.88408324e-01,\n",
       "        -3.27611099e-01, -6.24480444e-01,  1.67457044e-01,\n",
       "        -4.01906452e-02, -8.91264965e-01, -3.75623082e-01,\n",
       "         3.02259969e-01, -7.33758845e-01, -1.87520555e-01,\n",
       "        -6.31305963e-01,  2.88390121e-01,  6.18253012e-01,\n",
       "        -8.14679439e-01, -2.46276170e-01, -9.49200663e-01,\n",
       "        -5.18577654e-01,  1.56578329e-01,  2.39471542e-01,\n",
       "        -2.74462467e-01,  3.71261707e-01,  6.37081362e-01],\n",
       "       [ 6.57564452e-04,  7.65584929e-01,  1.87952897e-01,\n",
       "        -6.23834044e-01, -3.72824315e-01, -2.95709522e-01,\n",
       "        -5.54452318e-01,  2.52645406e-02, -9.82892778e-01,\n",
       "        -8.33658636e-01,  2.07805909e-01,  8.08220759e-01,\n",
       "         6.71188847e-01,  3.87849563e-01,  4.64055552e-01,\n",
       "        -5.51325433e-01, -2.54136706e-01, -3.10645488e-01,\n",
       "        -1.87194696e-01, -5.12639941e-01,  5.44256291e-01,\n",
       "         7.54075296e-01, -3.36090874e-02, -4.91887709e-01,\n",
       "         4.04481464e-01,  4.66065631e-01, -3.95221538e-01,\n",
       "        -2.10656448e-01,  7.31120386e-01, -2.50729287e-01,\n",
       "        -1.64552797e-01,  6.47596037e-01, -8.38796827e-01,\n",
       "         2.99417182e-01,  4.22541121e-01,  2.33532505e-02],\n",
       "       [ 6.58898533e-02,  3.38001123e-01,  6.80628189e-02,\n",
       "        -7.67836313e-02,  6.91831118e-01, -2.29058237e-01,\n",
       "        -2.29394965e-01, -1.00983935e+00, -4.06871226e-01,\n",
       "         8.71507908e-01,  4.13921896e-01, -8.04177474e-02,\n",
       "         7.68749091e-01,  2.71247824e-01, -5.90935984e-01,\n",
       "         1.10909313e-01,  1.20494195e+00, -6.75209657e-01,\n",
       "         2.57242643e-01, -8.56516543e-01,  4.01167922e-01,\n",
       "        -4.41146657e-01,  2.38369694e-01,  3.06392148e-01,\n",
       "        -1.76999054e-01, -2.63535705e-01, -6.06727404e-01,\n",
       "        -9.39505573e-01,  2.50410455e-01,  1.83473174e-01,\n",
       "         3.22215147e-02, -8.70984658e-01,  1.05539767e+00,\n",
       "        -4.33738812e-01, -2.26273431e-01,  4.04562854e-01],\n",
       "       [-5.31273448e-02, -1.77110013e-01,  2.56987453e-01,\n",
       "        -4.88045273e-01,  7.12231888e-01, -9.75201098e-01,\n",
       "         3.94700830e-01,  2.41731032e-01, -4.41119953e-01,\n",
       "         1.00840564e-01,  8.36758478e-02,  3.28992235e-02,\n",
       "        -6.27374308e-01, -2.50655458e-01,  4.17169549e-01,\n",
       "        -4.26198653e-02,  3.73386419e-01, -3.40234722e-01,\n",
       "         6.87474116e-01,  4.43424279e-01, -7.36584590e-01,\n",
       "        -3.43708651e-01,  5.82697377e-01, -8.16257923e-01,\n",
       "         8.72366736e-01,  6.37145551e-01,  6.35373898e-01,\n",
       "        -3.81064007e-01, -9.58966860e-01,  3.64812168e-01,\n",
       "        -1.00954180e+00,  9.02092490e-02,  1.63098794e-01,\n",
       "        -7.45473903e-01, -7.22291366e-01, -1.74741753e-01],\n",
       "       [ 8.41638668e-01,  3.83047023e-01,  5.42244813e-01,\n",
       "         1.04993575e+00, -7.90400743e-01,  2.68636266e-02,\n",
       "        -2.91062847e-02,  6.07386678e-01, -4.37325391e-01,\n",
       "        -9.37990549e-01, -1.75654994e-01,  1.01808541e-02,\n",
       "         4.10213998e-01, -7.47109645e-01, -2.40921723e-02,\n",
       "        -3.85979973e-01,  9.58370097e-01, -9.06037578e-01,\n",
       "        -3.96665907e-01, -1.30231150e-01,  7.73558186e-01,\n",
       "         1.61198781e-01, -1.52323896e-02,  1.29750156e-01,\n",
       "         6.37263984e-01, -5.73517815e-01,  1.47856319e-01,\n",
       "        -5.19909194e-02, -2.77234723e-02,  6.82216708e-01,\n",
       "        -8.07621238e-01, -9.30211387e-01,  7.46262163e-01,\n",
       "        -9.55929939e-01,  7.61805266e-02, -4.08879751e-02],\n",
       "       [ 3.38864707e-01,  8.85229790e-02,  5.12135278e-01,\n",
       "         1.37481954e-01,  6.29418622e-01, -3.32591451e-02,\n",
       "        -9.23974016e-02,  3.85475066e-01, -5.60621266e-01,\n",
       "        -4.55760144e-01,  6.43553563e-01,  4.80723701e-01,\n",
       "        -9.88359686e-01, -8.58273466e-03, -8.62007961e-01,\n",
       "         2.27805924e-01, -7.69030464e-01,  1.52956604e-01,\n",
       "         5.57183958e-01, -6.07770316e-01, -1.30674977e-01,\n",
       "        -7.93640640e-02,  5.57500592e-01, -4.25888877e-01,\n",
       "        -2.80516387e-02,  1.75517299e-01,  1.94508926e-01,\n",
       "        -1.63790087e-02,  7.48181366e-02, -7.61553467e-02,\n",
       "        -5.02373680e-01, -6.24713677e-01, -9.55303867e-01,\n",
       "        -9.14981903e-01, -2.58110927e-01,  4.78505895e-01],\n",
       "       [-3.30213024e-01,  4.76681370e-01,  3.10684293e-01,\n",
       "         8.08828932e-01,  5.92367363e-01, -2.50434718e-01,\n",
       "         7.09549714e-01, -3.75187490e-01, -2.84356204e-01,\n",
       "         2.99092099e-01, -9.60491877e-02,  6.41137457e-02,\n",
       "        -3.42104392e-01, -4.43752356e-01,  7.97485387e-01,\n",
       "         8.32690555e-02, -8.16645247e-01, -1.92681145e-01,\n",
       "         6.86088641e-01,  5.10322481e-02, -9.04143948e-01,\n",
       "        -5.16056969e-01, -8.94849093e-01,  2.71073865e-01,\n",
       "         2.93744505e-01, -3.39092131e-01, -4.86971070e-01,\n",
       "         4.77523045e-01,  2.10206921e-01,  8.87387266e-01,\n",
       "         4.06249577e-01, -4.22039296e-02,  7.96719123e-01,\n",
       "        -7.88536085e-01, -2.07232240e-01, -9.07964039e-01],\n",
       "       [ 1.34241677e-03, -9.17316113e-02,  8.60792437e-02,\n",
       "         2.22239795e-01, -4.02628008e-01,  8.15127161e-01,\n",
       "         1.13916483e-01,  8.00234961e-01,  2.43605916e-01,\n",
       "         7.38265305e-01, -7.09642103e-01,  6.59543979e-01,\n",
       "         1.46407378e-01, -1.26035040e-01, -2.81441396e-01,\n",
       "        -3.20524132e-01, -1.21420238e+00, -1.86398726e-01,\n",
       "        -3.15469295e-01, -1.24704658e-01,  1.99669148e-01,\n",
       "         7.53665127e-01, -4.65363361e-01, -4.73568875e-01,\n",
       "         5.60676423e-01, -4.37068228e-01, -1.18090279e-01,\n",
       "        -2.21416430e-01,  1.42995333e+00, -1.07266794e-01,\n",
       "        -4.46821323e-01, -3.13666254e-01,  1.05562789e-01,\n",
       "         2.57158293e-01,  6.37753853e-01,  6.97515940e-01],\n",
       "       [ 6.58952192e-01, -5.49602213e-01,  3.16607107e-01,\n",
       "         3.66140367e-02, -9.73119621e-01, -3.43132503e-01,\n",
       "         8.69341310e-01, -1.37210873e-01, -3.72722521e-01,\n",
       "         7.36119150e-01, -6.72508681e-01,  1.41697126e-02,\n",
       "        -1.23856651e-01, -3.76553632e-01, -1.54390435e-01,\n",
       "         6.21340919e-01,  2.76455572e-01, -7.18661473e-01,\n",
       "        -3.85278328e-02, -4.26675978e-03, -3.15538883e-01,\n",
       "        -7.57843223e-01,  5.67015323e-01,  1.83291130e-01,\n",
       "        -6.36375821e-01,  7.46102884e-01,  3.31776410e-01,\n",
       "         2.35248213e-01, -1.11653585e-01,  9.52299249e-02,\n",
       "        -3.90158575e-01,  2.30187249e-01, -2.98515493e-01,\n",
       "         3.89951160e-02,  1.16624082e+00,  1.87537526e-01],\n",
       "       [-4.80900734e-01, -3.88809604e-01, -1.15515582e+00,\n",
       "         6.86624099e-01,  4.74735753e-01,  3.60324412e-01,\n",
       "         4.10484240e-01, -6.31819734e-01,  1.80472449e-01,\n",
       "         7.22318477e-01, -1.69897957e-01,  2.75432863e-01,\n",
       "        -8.55030903e-01,  1.02559830e-01, -5.27193669e-01,\n",
       "         9.08714765e-01,  6.85779737e-01, -5.15427460e-01,\n",
       "        -9.80399408e-01,  4.04691349e-01,  3.45152700e-01,\n",
       "         1.15225429e-01, -3.25762540e-01, -5.64399117e-02,\n",
       "         7.32475726e-01, -6.50694623e-01,  1.55707619e-01,\n",
       "         6.00399206e-01, -8.43211768e-01,  8.76939856e-01,\n",
       "        -7.63826266e-02, -1.19679087e+00, -2.27791091e-01,\n",
       "        -5.57526327e-01,  3.74951596e-01, -2.80845211e-01],\n",
       "       [-1.98212643e-02,  4.41016989e-02,  1.84870068e-01,\n",
       "        -9.93503021e-01, -6.75318902e-01,  5.52938519e-01,\n",
       "         8.76253147e-01, -2.18359438e-01,  8.86661936e-01,\n",
       "        -6.74485918e-01, -2.37295446e-01,  7.31669596e-01,\n",
       "         1.46524389e-01,  6.52017353e-01, -5.06316869e-01,\n",
       "         3.31707753e-02,  7.81910190e-04, -1.09067155e-01,\n",
       "         4.20553963e-01, -9.35072326e-01,  1.04050753e-01,\n",
       "         1.39694460e-01,  8.22270150e-01, -1.87205587e-01,\n",
       "         7.03817077e-02,  8.50296232e-01, -1.13264410e-02,\n",
       "        -2.62715072e-01, -3.45021297e-01, -3.75828089e-02,\n",
       "        -5.94820751e-01, -3.48895547e-01, -7.38155555e-02,\n",
       "        -4.60227090e-01, -8.53966121e-01, -1.47596409e-01],\n",
       "       [-1.44419007e-01,  8.94070940e-01, -1.02482169e+00,\n",
       "        -2.18875191e-01,  5.84780628e-01, -5.77236931e-01,\n",
       "        -4.53123046e-01,  3.74389620e-02,  2.15187030e-02,\n",
       "         7.65990682e-02, -7.77929337e-01,  5.38055601e-01,\n",
       "        -2.83654517e-01, -2.41890106e-01, -7.28697709e-02,\n",
       "        -1.74296037e-01, -8.51502123e-01,  5.97709229e-01,\n",
       "        -4.20734972e-01,  9.61303223e-01, -9.16499143e-01,\n",
       "        -4.03975597e-01,  1.10015598e+00,  7.72593269e-02,\n",
       "         8.30501401e-01, -5.42166794e-01, -5.62705989e-01,\n",
       "        -4.60147978e-01,  1.17791854e-01,  5.06923198e-01,\n",
       "         4.28840159e-01,  9.60184468e-01,  3.71870480e-01,\n",
       "        -6.92780806e-01,  1.99263564e-01,  9.44447210e-01],\n",
       "       [-2.71019731e-01,  8.31062255e-01,  3.89610752e-01,\n",
       "        -8.16098190e-01,  7.36045827e-01, -2.42462810e-02,\n",
       "         2.55264651e-01, -5.73120579e-01, -4.05177371e-01,\n",
       "        -7.94520837e-02,  5.29628248e-01, -5.29310403e-01,\n",
       "        -4.94214477e-02, -9.90920640e-01, -1.56326849e-01,\n",
       "         8.87220042e-01,  4.95941132e-01, -3.91659793e-01,\n",
       "         1.34065448e-01, -4.18358424e-01, -7.17595801e-01,\n",
       "        -1.07117772e+00,  8.20484898e-01, -3.65209311e-01,\n",
       "         9.50205741e-01, -4.53807663e-02, -1.05204305e+00,\n",
       "         5.77607370e-01,  3.76466684e-01,  6.12883816e-01,\n",
       "        -7.67151859e-01, -7.83751412e-01,  2.48206447e-01,\n",
       "         6.45828669e-01, -5.36119699e-01, -1.54485834e-01],\n",
       "       [-2.41373350e-01,  4.25570816e-02, -3.59645781e-01,\n",
       "        -3.40943258e-01, -1.66180438e-01, -2.97098486e-01,\n",
       "         7.56144590e-01, -9.09942635e-01, -6.09625588e-01,\n",
       "        -4.47831040e-01, -4.86850357e-01, -4.69450192e-01,\n",
       "         1.40453348e-01, -5.56838541e-01,  5.82484141e-02,\n",
       "        -3.65054877e-01, -4.12516113e-01,  5.53588941e-02,\n",
       "        -1.89299671e-01, -9.05080089e-02, -1.85410657e-01,\n",
       "        -1.01120216e-01,  4.30430000e-01,  8.28726877e-01,\n",
       "         2.59734067e-01,  5.50130316e-01,  8.07150429e-01,\n",
       "         5.38794453e-01,  4.89945074e-01,  1.39444629e-01,\n",
       "         5.28332678e-02,  2.52431325e-01,  3.59588824e-01,\n",
       "         7.28438691e-01,  3.00941817e-01, -1.78576005e-01]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ask professor why epoch 0 has poor accuracy while his binary perceptron has relatively high accuracy\n",
    "# train model with TRAINING SET\n",
    "mul_pct_model = train(TRAINING_SET_2D, TRAINING_SET_LABELS)\n",
    "print(mul_pct_model.shape)\n",
    "mul_pct_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-stephen",
   "metadata": {},
   "source": [
    "# 6. Use your trained multiclass perceptron to classify each image in the test set.\n",
    "## Apply the weights to all feature vectors in the test set at once using np.matmul(), then make predictions using np.amax().\n",
    "## What accuracy do you obtain? If the accuracy is less than 100%, which test images are misclassified?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "helpful-probe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(dataset_2D, model):\n",
    "    len_train_set = len(dataset_2D)\n",
    "    w_idx = 0\n",
    "    misclassification = 0\n",
    "    for i in range(len_train_set):\n",
    "        if w_idx == 26:\n",
    "            w_idx = 0\n",
    "        ascii_idx = np.argmax(np.dot(model, dataset_2D[i]))\n",
    "        y_pred = chr(ascii_idx + ord('A'))\n",
    "        print(f'Prediction: {y_pred}, Target: {string.ascii_uppercase[w_idx]}, {y_pred == string.ascii_uppercase[w_idx]}')\n",
    "        if y_pred != string.ascii_uppercase[w_idx]:\n",
    "            misclassification += 1\n",
    "        w_idx += 1\n",
    "    \n",
    "    correct = len_train_set - misclassification\n",
    "    res = correct if correct > 0 else 0\n",
    "    print(f'\\nAccuracy: {res}/{len_train_set} Percentage: {(res/len_train_set * 100):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "artistic-bernard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: A, Target: A, True\n",
      "Prediction: B, Target: B, True\n",
      "Prediction: C, Target: C, True\n",
      "Prediction: D, Target: D, True\n",
      "Prediction: E, Target: E, True\n",
      "Prediction: F, Target: F, True\n",
      "Prediction: G, Target: G, True\n",
      "Prediction: H, Target: H, True\n",
      "Prediction: I, Target: I, True\n",
      "Prediction: J, Target: J, True\n",
      "Prediction: K, Target: K, True\n",
      "Prediction: L, Target: L, True\n",
      "Prediction: M, Target: M, True\n",
      "Prediction: N, Target: N, True\n",
      "Prediction: O, Target: O, True\n",
      "Prediction: P, Target: P, True\n",
      "Prediction: Q, Target: Q, True\n",
      "Prediction: R, Target: R, True\n",
      "Prediction: S, Target: S, True\n",
      "Prediction: T, Target: T, True\n",
      "Prediction: U, Target: U, True\n",
      "Prediction: V, Target: V, True\n",
      "Prediction: W, Target: W, True\n",
      "Prediction: X, Target: X, True\n",
      "Prediction: Y, Target: Y, True\n",
      "Prediction: Z, Target: Z, True\n",
      "Prediction: A, Target: A, True\n",
      "Prediction: B, Target: B, True\n",
      "Prediction: C, Target: C, True\n",
      "Prediction: D, Target: D, True\n",
      "Prediction: E, Target: E, True\n",
      "Prediction: F, Target: F, True\n",
      "Prediction: G, Target: G, True\n",
      "Prediction: H, Target: H, True\n",
      "Prediction: I, Target: I, True\n",
      "Prediction: J, Target: J, True\n",
      "Prediction: K, Target: K, True\n",
      "Prediction: L, Target: L, True\n",
      "Prediction: M, Target: M, True\n",
      "Prediction: N, Target: N, True\n",
      "Prediction: O, Target: O, True\n",
      "Prediction: P, Target: P, True\n",
      "Prediction: Q, Target: Q, True\n",
      "Prediction: R, Target: R, True\n",
      "Prediction: S, Target: S, True\n",
      "Prediction: T, Target: T, True\n",
      "Prediction: U, Target: U, True\n",
      "Prediction: V, Target: V, True\n",
      "Prediction: W, Target: W, True\n",
      "Prediction: X, Target: X, True\n",
      "Prediction: Y, Target: Y, True\n",
      "Prediction: Z, Target: Z, True\n",
      "\n",
      "Accuracy: 52/52 Percentage: 100.00%\n"
     ]
    }
   ],
   "source": [
    "test_model(TRAINING_SET_2D, mul_pct_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dietary-massage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: E, Target: A, False\n",
      "Prediction: B, Target: B, True\n",
      "Prediction: C, Target: C, True\n",
      "Prediction: D, Target: D, True\n",
      "Prediction: E, Target: E, True\n",
      "Prediction: F, Target: F, True\n",
      "Prediction: G, Target: G, True\n",
      "Prediction: H, Target: H, True\n",
      "Prediction: I, Target: I, True\n",
      "Prediction: J, Target: J, True\n",
      "Prediction: K, Target: K, True\n",
      "Prediction: L, Target: L, True\n",
      "Prediction: M, Target: M, True\n",
      "Prediction: N, Target: N, True\n",
      "Prediction: O, Target: O, True\n",
      "Prediction: P, Target: P, True\n",
      "Prediction: Q, Target: Q, True\n",
      "Prediction: R, Target: R, True\n",
      "Prediction: S, Target: S, True\n",
      "Prediction: S, Target: T, False\n",
      "Prediction: U, Target: U, True\n",
      "Prediction: V, Target: V, True\n",
      "Prediction: O, Target: W, False\n",
      "Prediction: X, Target: X, True\n",
      "Prediction: Y, Target: Y, True\n",
      "Prediction: X, Target: Z, False\n",
      "\n",
      "Accuracy: 22/26 Percentage: 84.62%\n"
     ]
    }
   ],
   "source": [
    "test_model(TEST_SET_2D, mul_pct_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-likelihood",
   "metadata": {},
   "source": [
    "# 7. Implement and train a multinomial logistic regression classifier as described in Section 2.3.3 of the textbook. \n",
    "## Begin with weights initialized to random values and a learning rate of ùõº = 0.01. Predict the letter using the softmax activation function of Equation 2.29 in the textbook.\n",
    "## Train the classifier by applying the update rule of Equation 2.37 in the textbook until all items in the training set are correctly classified.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "thrown-blues",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use while-loop and no epochs\n",
    "def check_for_misclassification(epochs, W, X_train):\n",
    "    N = len(X_train)\n",
    "    misclassification = 0\n",
    "    pred_idx = 0\n",
    "    for i in range(N):\n",
    "        if pred_idx == 26:\n",
    "            pred_idx = 0\n",
    "        ascii_idx = np.argmax(np.matmul(W, X_train[i]))\n",
    "        y_pred = chr(ascii_idx + ord('A'))\n",
    "        if y_pred != string.ascii_uppercase[pred_idx]:\n",
    "            misclassification += 1\n",
    "        pred_idx += 1\n",
    "    print(f'Epoch {epochs} - Accuracy: {N - misclassification}/{N}')\n",
    "    return misclassification\n",
    "    \n",
    "    \n",
    "def mul_log_reg_train(data_train, target_train):\n",
    "    ALPHA = 0.01\n",
    "    LAMBDA = 0.60125 # penalty\n",
    "    \n",
    "    D = len(data_train[0])             # dimensions (including bias)\n",
    "    N = len(data_train)                # training instance\n",
    "    P = len(string.ascii_uppercase)    # number of perceptrons\n",
    "    \n",
    "    rng = default_rng()\n",
    "    W = rng.uniform(-1, +1, (P, D))\n",
    "    X_train = data_train\n",
    "    Y_train = target_train\n",
    "    \n",
    "    idx = np.arange(N)\n",
    "    w_idx = 0\n",
    "    misclassification = 0\n",
    "    epochs = 0\n",
    "    while True:\n",
    "        for i in range(N):\n",
    "            if w_idx == P:\n",
    "                w_idx = 0\n",
    "                \n",
    "            # Predict the letter using the softmax activation function of Equation 2.29 in the textbook\n",
    "            Y_hat = np.dot(W, X_train[i])\n",
    "            one_class_exp = np.exp(Y_hat)\n",
    "            sum_classes_exp = np.sum(one_class_exp)\n",
    "            probability = one_class_exp / sum_classes_exp\n",
    "            y_pred_idx = np.argmax(probability)\n",
    "\n",
    "            # prediction is incorrect, use update rule of equation 2.37 in textbook\n",
    "            if Y_train[i][y_pred_idx] == 0:\n",
    "                temp = W[w_idx]\n",
    "                W = W * (1.0 - ALPHA * LAMBDA) + (-ALPHA * probability[w_idx] * X_train[i])\n",
    "                W[w_idx] = temp * (1.0 - ALPHA * LAMBDA) + (ALPHA * (1.0 - probability[w_idx]) * X_train[i])\n",
    "                \n",
    "            w_idx += 1\n",
    "            \n",
    "        # check if all items in the training set are correctly classified\n",
    "        misclassification = check_for_misclassification(epochs, W, X_train)\n",
    "        if misclassification == 0:\n",
    "            print('All items are correctly classified')\n",
    "            print(f'number of epochs: {epochs}')\n",
    "            return W\n",
    "        else:\n",
    "            misclassification = 0\n",
    "        epochs += 1\n",
    "    return W "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "caring-responsibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Accuracy: 4/52\n",
      "Epoch 1 - Accuracy: 4/52\n",
      "Epoch 2 - Accuracy: 4/52\n",
      "Epoch 3 - Accuracy: 3/52\n",
      "Epoch 4 - Accuracy: 10/52\n",
      "Epoch 5 - Accuracy: 11/52\n",
      "Epoch 6 - Accuracy: 13/52\n",
      "Epoch 7 - Accuracy: 17/52\n",
      "Epoch 8 - Accuracy: 25/52\n",
      "Epoch 9 - Accuracy: 33/52\n",
      "Epoch 10 - Accuracy: 41/52\n",
      "Epoch 11 - Accuracy: 36/52\n",
      "Epoch 12 - Accuracy: 38/52\n",
      "Epoch 13 - Accuracy: 36/52\n",
      "Epoch 14 - Accuracy: 33/52\n",
      "Epoch 15 - Accuracy: 42/52\n",
      "Epoch 16 - Accuracy: 36/52\n",
      "Epoch 17 - Accuracy: 26/52\n",
      "Epoch 18 - Accuracy: 31/52\n",
      "Epoch 19 - Accuracy: 31/52\n",
      "Epoch 20 - Accuracy: 34/52\n",
      "Epoch 21 - Accuracy: 47/52\n",
      "Epoch 22 - Accuracy: 48/52\n",
      "Epoch 23 - Accuracy: 50/52\n",
      "Epoch 24 - Accuracy: 52/52\n",
      "All items are correctly classified\n",
      "number of epochs: 24\n",
      "(26, 36)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.59242459e-02, -5.72790780e-02,  1.92263587e-02,\n",
       "         2.10161455e-02,  1.99533293e-02, -4.16712972e-02,\n",
       "        -1.63030132e-03, -4.07090517e-03, -2.00250146e-03,\n",
       "        -9.61054547e-03,  6.42920276e-03,  6.19976871e-04,\n",
       "        -6.17557185e-03, -1.69790775e-02, -3.01960338e-03,\n",
       "         1.99247519e-02,  9.21892418e-03,  1.00776481e-02,\n",
       "         4.16763126e-04,  8.51827898e-03,  3.37431905e-02,\n",
       "         1.27301839e-03,  2.66961195e-02,  1.23674460e-02,\n",
       "         2.27300629e-02,  2.23755715e-02, -1.49070458e-03,\n",
       "        -6.66997333e-03, -9.24788889e-03, -1.83548941e-02,\n",
       "         2.54605765e-02,  1.76749007e-02, -3.86072566e-02,\n",
       "        -5.00907052e-02, -3.86741880e-02,  3.41437252e-02],\n",
       "       [-3.00356525e-02,  4.38014004e-03,  9.02985079e-03,\n",
       "         7.61123382e-03,  9.69176756e-03, -4.26237742e-02,\n",
       "        -1.60016668e-02, -4.00318384e-03, -2.25184550e-03,\n",
       "        -9.13023545e-03, -3.17724465e-03, -1.40399136e-02,\n",
       "        -2.23101972e-03, -1.72219326e-02, -3.09795801e-03,\n",
       "         7.14005156e-03, -1.11303664e-02,  2.36462280e-02,\n",
       "         1.34880697e-02,  2.62541345e-02, -3.91974983e-02,\n",
       "        -7.34394703e-03, -5.04909919e-03, -1.88621786e-02,\n",
       "        -1.10117664e-02,  9.29335087e-03, -1.56210646e-02,\n",
       "        -1.36327369e-02, -9.88507777e-03, -1.46882135e-02,\n",
       "         9.01085403e-03,  1.00533671e-02,  1.84515286e-02,\n",
       "         9.71739486e-03,  1.87919277e-02, -3.86512220e-02],\n",
       "       [-1.10286559e-02, -5.75295639e-02,  2.55210757e-02,\n",
       "         2.56401972e-02,  2.72435896e-02, -4.42306306e-02,\n",
       "        -1.28994425e-03, -6.44698474e-03, -2.75338315e-03,\n",
       "        -1.28372974e-02,  8.68317992e-03,  1.78364401e-03,\n",
       "        -1.57687633e-03, -1.23436729e-02, -7.36768008e-03,\n",
       "        -4.48327451e-02,  9.25382045e-03, -3.22014563e-02,\n",
       "        -3.54548535e-02, -2.89944433e-02, -3.73540457e-02,\n",
       "         5.42964535e-03, -7.63705300e-03, -2.13306551e-02,\n",
       "        -1.13202488e-02, -5.08094726e-02,  2.54127323e-03,\n",
       "        -1.14988445e-02, -8.31219916e-03, -1.67806625e-02,\n",
       "         2.65408736e-02, -5.09682420e-02,  3.25245230e-02,\n",
       "         2.68887975e-02,  3.70588599e-02, -3.65539307e-02],\n",
       "       [-1.83412961e-02,  1.29187184e-02,  1.41639060e-02,\n",
       "         1.36599163e-02, -9.24247382e-03, -4.34274738e-02,\n",
       "        -6.43347853e-03, -9.91903878e-03, -5.97276734e-03,\n",
       "         1.69241070e-02, -1.93577854e-02, -2.95219987e-03,\n",
       "        -5.88418175e-03, -1.55967979e-02, -3.49168609e-03,\n",
       "         1.47323894e-02, -1.20222857e-03, -2.64569180e-02,\n",
       "        -3.75285787e-02, -3.36916327e-02,  2.64499312e-02,\n",
       "        -9.89006411e-04, -3.73030666e-03, -2.00340799e-02,\n",
       "        -7.75212303e-03,  1.66608698e-02, -4.94995409e-03,\n",
       "        -1.28498288e-02, -6.61526721e-03,  1.03472085e-02,\n",
       "        -3.88363529e-03,  1.55716636e-02,  2.72537300e-02,\n",
       "         1.40319761e-02,  7.60271604e-03, -4.11380957e-02],\n",
       "       [-2.33999966e-02,  2.95534938e-03,  5.17190794e-03,\n",
       "         4.24777419e-03,  8.58907895e-03,  8.61398542e-03,\n",
       "        -1.32491732e-02, -7.03146518e-03, -2.40915623e-03,\n",
       "        -1.06014056e-02, -6.00609400e-02, -1.36275859e-02,\n",
       "        -1.33065836e-03, -1.45013120e-02, -4.17568983e-03,\n",
       "        -4.77193356e-02, -4.58586697e-03,  2.98852593e-02,\n",
       "         2.07196588e-02,  2.91707946e-02, -3.72921070e-02,\n",
       "        -1.01770564e-02, -1.78687972e-03, -2.04593973e-02,\n",
       "        -9.55384547e-03, -5.27860510e-02, -1.14115790e-02,\n",
       "        -1.05420885e-02, -8.77318939e-03, -1.73193386e-02,\n",
       "        -4.60712671e-02,  1.15218400e-02,  1.84118384e-02,\n",
       "         6.74411813e-03,  1.80232143e-02,  1.73696981e-02],\n",
       "       [-6.49551970e-03,  2.05245237e-02,  2.65594935e-02,\n",
       "         2.66433185e-02,  2.48414076e-02,  2.54930407e-02,\n",
       "         3.20152800e-03, -1.10580287e-02, -7.57836204e-03,\n",
       "        -1.06278507e-02, -6.14849660e-02,  2.81020805e-03,\n",
       "        -2.84878097e-03, -1.46216854e-02, -4.45646718e-03,\n",
       "        -4.89305225e-02,  1.05004868e-02,  4.29253940e-02,\n",
       "         3.61506960e-02,  1.57731492e-02, -3.89513301e-02,\n",
       "         3.79836910e-03, -3.00873958e-03, -1.62601949e-02,\n",
       "        -5.61568270e-03, -4.87894115e-02,  9.11318959e-03,\n",
       "        -9.55097895e-03, -6.68802408e-03, -1.96366934e-02,\n",
       "        -5.01250366e-02,  2.43952014e-02, -4.02298443e-02,\n",
       "        -4.56502414e-02, -3.76052864e-02, -4.04189670e-02],\n",
       "       [-1.52691696e-02, -5.84898122e-02,  1.61788687e-02,\n",
       "         1.69132475e-02,  1.82448581e-02, -4.70431114e-02,\n",
       "        -5.58756132e-03, -8.62626511e-03, -1.50578856e-03,\n",
       "        -8.50531017e-03,  5.38656784e-03,  1.60047218e-03,\n",
       "        -3.85499150e-03, -1.20605572e-02, -1.62481990e-03,\n",
       "        -4.99842705e-02,  1.44668733e-03, -3.13192384e-02,\n",
       "        -4.07489256e-02,  1.55857321e-03, -4.44887080e-03,\n",
       "         1.17892868e-04, -6.83110631e-03, -1.87264846e-02,\n",
       "         2.39317296e-02,  1.77856860e-02, -8.04099175e-05,\n",
       "        -1.13372465e-02, -1.04999159e-02, -1.94748074e-02,\n",
       "         1.73636829e-02, -4.85203197e-02,  2.31503691e-02,\n",
       "         1.60864524e-02,  3.40659620e-02, -3.66510922e-02],\n",
       "       [-1.56753603e-02,  1.28576972e-02, -4.99278070e-02,\n",
       "        -5.09734012e-02, -4.61866374e-02,  1.94800558e-02,\n",
       "        -1.07118158e-02, -9.05324313e-03, -3.81553995e-03,\n",
       "        -6.40071014e-03,  4.23101245e-04, -4.54279803e-03,\n",
       "        -2.56223005e-03, -1.46394604e-02, -5.27024163e-03,\n",
       "         1.33676064e-02,  1.43261634e-04,  3.84502857e-02,\n",
       "         2.30511505e-02,  3.10705018e-02,  2.53426863e-02,\n",
       "        -6.12924597e-04, -8.85579406e-03, -1.84662381e-02,\n",
       "        -5.82060305e-03,  1.39413212e-02, -4.22022358e-03,\n",
       "        -1.02485649e-02, -1.00687870e-02, -2.07906419e-02,\n",
       "         1.82911984e-02,  1.94805258e-02, -3.70884946e-02,\n",
       "        -5.04822495e-02, -3.44838451e-02,  2.56256244e-02],\n",
       "       [-4.07565527e-02, -5.78994291e-02, -5.74542958e-04,\n",
       "        -4.56500127e-03,  5.24736353e-04, -4.38484940e-02,\n",
       "        -7.15530681e-02, -6.16805231e-03,  4.17190055e-02,\n",
       "        -1.11731357e-02, -5.96903861e-02, -6.63725849e-02,\n",
       "        -1.78381852e-03,  3.20953151e-02, -1.67902381e-03,\n",
       "        -5.01778943e-02, -6.68246943e-02, -2.60773879e-02,\n",
       "         1.00207194e-02, -2.72963152e-02, -3.88062538e-02,\n",
       "        -6.98822593e-02, -2.29527054e-03,  2.99473977e-02,\n",
       "        -3.95628794e-03, -5.19804704e-02, -6.64946116e-02,\n",
       "        -8.90349780e-03,  4.00154805e-02, -1.42031821e-02,\n",
       "        -4.79114805e-02, -5.18567888e-02,  2.64369877e-03,\n",
       "        -5.40558186e-03,  9.47062301e-03, -3.68215007e-02],\n",
       "       [ 4.52853071e-03, -5.14332338e-02, -5.17110235e-02,\n",
       "        -2.46003685e-02, -2.32559904e-02,  3.78725884e-02,\n",
       "        -7.05987734e-02, -9.53853320e-03, -7.54733966e-03,\n",
       "         1.86475960e-02, -2.84663491e-03, -6.62862214e-02,\n",
       "        -2.46139877e-03, -1.48476919e-02,  1.76076242e-02,\n",
       "         1.50658319e-02, -6.53259686e-02, -3.16288643e-02,\n",
       "        -4.15392151e-02, -6.31624137e-03,  2.06370056e-02,\n",
       "        -2.48317470e-03, -5.00155237e-03, -1.58552927e-02,\n",
       "         1.91243198e-02,  7.69177410e-03,  1.93342119e-02,\n",
       "        -1.29797595e-02, -5.85725118e-03,  9.71546281e-03,\n",
       "         1.14581926e-02, -4.71061965e-02,  4.16160956e-02,\n",
       "         3.56273790e-02,  2.19834639e-02, -3.80669102e-02],\n",
       "       [-2.98826474e-02, -3.34242941e-03, -5.07643868e-02,\n",
       "        -4.63251004e-02, -4.84867192e-02,  1.27267551e-02,\n",
       "        -2.10535100e-02, -4.05697186e-03, -5.67207499e-03,\n",
       "         4.04163535e-02, -6.21381173e-02, -1.15542634e-02,\n",
       "        -6.04342028e-03,  4.08116952e-02, -4.94295781e-03,\n",
       "        -4.63311954e-02, -9.79582052e-03,  2.18634533e-02,\n",
       "        -3.86205047e-02, -3.33273618e-02, -4.19390789e-02,\n",
       "        -1.40240326e-02, -4.72860099e-03,  3.25522541e-02,\n",
       "        -1.06796977e-02, -5.32932592e-02, -1.52254209e-02,\n",
       "        -1.07938166e-02, -5.50505547e-03,  3.51563307e-02,\n",
       "        -4.55128063e-02,  4.41018511e-03, -4.27272831e-02,\n",
       "        -5.19865614e-02, -3.45892145e-02,  1.62289985e-02],\n",
       "       [-2.23186978e-02,  4.10517727e-03, -4.75613679e-02,\n",
       "        -5.25004503e-02, -4.68228982e-02, -4.58111194e-02,\n",
       "        -8.50914492e-03, -1.01827092e-02, -7.67115669e-04,\n",
       "        -1.10095327e-02, -6.39595510e-02, -3.77799355e-03,\n",
       "        -2.40451164e-03, -1.54472949e-02, -7.05385041e-03,\n",
       "        -5.01456928e-02,  3.58156949e-04, -2.71681853e-02,\n",
       "        -3.59347099e-02, -2.70503256e-02, -3.54262949e-02,\n",
       "        -2.90390160e-03, -9.13593771e-03, -1.98961147e-02,\n",
       "        -7.04942014e-03, -5.17953532e-02, -3.63223333e-03,\n",
       "        -6.66567285e-03, -8.96956762e-03, -1.46920099e-02,\n",
       "        -4.67272882e-02,  1.74852938e-02,  2.40775575e-02,\n",
       "         1.23916815e-02,  2.66207656e-02,  2.48395632e-02],\n",
       "       [-1.95560241e-02,  1.04082351e-02, -4.58957385e-02,\n",
       "        -4.99539237e-02, -5.04638034e-02,  2.17168497e-02,\n",
       "        -6.15586330e-03,  5.48890949e-02, -5.10147511e-03,\n",
       "         5.32352874e-02,  1.26239962e-03, -1.91064757e-03,\n",
       "        -1.11273997e-03,  4.84570989e-02, -5.48357822e-03,\n",
       "         1.97937500e-02, -2.76416513e-03, -2.61920614e-02,\n",
       "         2.33081091e-03, -2.68027336e-02,  2.38125681e-02,\n",
       "         4.53575245e-04, -9.06419943e-03, -2.01706333e-02,\n",
       "        -6.88991578e-03,  1.81203696e-02, -1.59216692e-03,\n",
       "        -9.89336402e-03, -9.78736504e-03, -1.62946911e-02,\n",
       "         1.94386556e-02,  1.97437976e-02, -4.38245644e-02,\n",
       "        -5.18280838e-02, -3.47882686e-02,  2.41960642e-02],\n",
       "       [-1.34482751e-02,  1.13404003e-02, -4.48806045e-02,\n",
       "        -4.95712856e-02, -4.52397771e-02,  2.89136131e-02,\n",
       "         5.51280274e-04,  4.00350553e-02, -2.49096519e-03,\n",
       "        -1.34504658e-02,  6.80885543e-03, -9.94636218e-04,\n",
       "         2.05586592e-02,  3.29036998e-02, -4.08708078e-03,\n",
       "         2.39691569e-02,  4.56050377e-03, -2.96598744e-02,\n",
       "        -1.55273865e-02,  1.05310427e-02,  3.46647067e-02,\n",
       "         5.04230950e-03, -6.81250531e-03, -1.86609851e-02,\n",
       "         1.53969823e-02,  2.38499270e-02, -3.62910394e-04,\n",
       "        -6.79608481e-03, -5.45776220e-03, -1.87768210e-02,\n",
       "         2.32658456e-02,  2.19733696e-02, -4.09117028e-02,\n",
       "        -4.69654840e-02, -3.35114239e-02,  3.46487726e-02],\n",
       "       [-2.16207179e-02, -5.83406256e-02,  1.17490173e-02,\n",
       "         1.00303789e-02,  1.49680349e-02, -4.75592749e-02,\n",
       "        -1.21516665e-02, -4.97305245e-03, -7.35491484e-03,\n",
       "        -6.21136848e-03, -3.75733703e-03, -6.86835996e-03,\n",
       "        -5.90540534e-04, -1.55192226e-02, -8.72058683e-03,\n",
       "         1.09924984e-02, -4.83396200e-03, -3.02672983e-02,\n",
       "        -4.20775506e-02, -2.92821163e-02,  2.48682328e-02,\n",
       "        -5.05383327e-03, -5.57043889e-03, -1.84432169e-02,\n",
       "        -5.34458933e-03,  1.37237185e-02, -1.02622099e-02,\n",
       "        -1.06246135e-02, -7.27013212e-03, -1.52560671e-02,\n",
       "         1.61102599e-02, -4.79462997e-02,  2.23066397e-02,\n",
       "         8.88904879e-03,  2.52535239e-02, -3.82707374e-02],\n",
       "       [-1.64465492e-02,  1.12070755e-02,  2.12311887e-02,\n",
       "         1.41731394e-02,  1.98707845e-02, -4.83159271e-02,\n",
       "        -3.47501870e-03, -8.78356478e-03, -2.98129556e-03,\n",
       "        -1.07677277e-02,  6.36098286e-03, -1.59641970e-03,\n",
       "        -4.92216427e-03, -1.59699053e-02, -4.15151401e-03,\n",
       "         1.66430661e-02,  4.19110550e-03,  3.76939792e-02,\n",
       "         3.03154832e-02,  3.81657853e-02, -4.02131014e-02,\n",
       "         4.91790662e-04, -2.40066010e-03, -1.63451328e-02,\n",
       "        -6.96607300e-03, -4.69126148e-02, -7.16187120e-04,\n",
       "        -9.40401178e-03, -9.33113592e-03, -2.08462736e-02,\n",
       "        -4.65421898e-02,  2.03736754e-02, -4.21521508e-02,\n",
       "        -4.55179669e-02, -3.46757235e-02, -3.98356284e-02],\n",
       "       [-1.55281515e-02, -5.16723929e-02,  2.25207305e-02,\n",
       "         2.00315707e-02,  1.94823909e-02, -4.14561212e-02,\n",
       "        -5.57554865e-03, -7.76043619e-03, -1.45047297e-03,\n",
       "        -1.23914041e-02,  2.89862326e-03, -1.78401706e-03,\n",
       "        -3.58727239e-03, -1.80169000e-02, -6.37039430e-03,\n",
       "         2.24776598e-02,  3.78302948e-03, -2.60481581e-02,\n",
       "        -3.70228892e-02, -3.05439976e-02,  2.50400414e-02,\n",
       "        -1.70539813e-03, -6.33294011e-03,  1.97476994e-02,\n",
       "        -8.71256081e-03,  2.05404283e-02, -3.31818808e-02,\n",
       "         2.36654172e-02,  2.51406729e-02,  5.01755995e-02,\n",
       "        -4.40551851e-02, -4.57198595e-02, -1.41492301e-03,\n",
       "        -9.73774801e-03, -3.84024720e-02,  2.90194993e-02],\n",
       "       [-2.10728481e-02,  9.14591780e-03,  1.53516000e-02,\n",
       "         1.29758656e-02,  1.43356724e-02, -4.49189599e-02,\n",
       "        -8.99241035e-03, -1.11201412e-02, -4.81248030e-03,\n",
       "        -8.72229449e-03,  9.82121007e-04, -6.00968918e-03,\n",
       "        -6.67012434e-03, -1.05730172e-02, -6.90795963e-03,\n",
       "         1.30758188e-02, -1.12767966e-03,  3.65750845e-02,\n",
       "         2.24683697e-02,  3.19377096e-02, -3.85098054e-02,\n",
       "        -6.61379143e-03, -2.85790948e-03, -4.39518424e-03,\n",
       "        -7.18248550e-03, -2.95863951e-03, -4.60434607e-03,\n",
       "        -9.78092707e-03, -1.02436767e-02,  8.49360503e-04,\n",
       "         2.74801651e-03,  1.18633066e-02, -4.45520888e-02,\n",
       "        -5.21140842e-02, -3.66879826e-02,  2.71903164e-02],\n",
       "       [-1.52619722e-02, -5.25208896e-02,  1.73796562e-02,\n",
       "         1.66465826e-02,  1.56110163e-02, -2.32538709e-02,\n",
       "        -7.98991223e-03, -9.75409265e-03, -2.41112344e-03,\n",
       "        -6.81596916e-03, -1.89611825e-02, -6.04310704e-03,\n",
       "        -4.10944044e-03, -1.32592532e-02, -4.24531924e-03,\n",
       "        -4.92897449e-02, -6.07813559e-02,  3.40425589e-02,\n",
       "         2.38080114e-02,  3.78767168e-02, -3.84570578e-02,\n",
       "        -6.32873115e-02, -2.69400328e-03, -1.51762714e-02,\n",
       "        -1.13465931e-02,  1.31229501e-02, -2.45033375e-02,\n",
       "        -1.00853134e-02, -1.00188410e-02, -2.03777955e-02,\n",
       "         2.09468901e-02, -2.34932084e-02,  2.81791535e-02,\n",
       "         1.82100520e-02,  3.12074630e-02, -3.90087941e-02],\n",
       "       [-2.90175527e-02, -5.26353720e-03,  2.93445623e-03,\n",
       "         1.79647426e-03,  1.36714546e-03,  5.11977987e-03,\n",
       "        -7.43507312e-02, -7.89152496e-03,  5.13330427e-02,\n",
       "        -9.94404744e-03, -6.34828962e-02, -6.82860193e-02,\n",
       "        -1.59436786e-03,  3.48187597e-02, -4.80517183e-03,\n",
       "        -4.77909273e-02, -6.03402176e-02, -3.19110682e-02,\n",
       "         9.51201183e-03, -3.02232474e-02, -3.96217755e-02,\n",
       "        -6.44596184e-02, -2.79227558e-03,  3.38676627e-02,\n",
       "        -7.05004979e-03, -4.88046259e-02, -6.59728124e-02,\n",
       "        -6.97518384e-03,  4.14204274e-02, -1.65501726e-02,\n",
       "        -4.32046934e-02, -4.97454734e-02, -3.73983343e-02,\n",
       "         4.11360038e-03, -3.55377984e-02, -3.50133952e-02],\n",
       "       [-2.28199386e-02,  8.14862471e-03, -4.92051889e-02,\n",
       "        -5.01851066e-02, -4.84464487e-02,  1.48244321e-02,\n",
       "        -1.22301847e-02, -3.97480106e-03, -7.66717026e-03,\n",
       "        -7.94733317e-03,  1.24697971e-03, -9.24579133e-03,\n",
       "        -2.68965148e-03, -1.74214765e-02, -6.73647767e-03,\n",
       "         1.43972794e-02, -2.03344739e-03, -3.07680177e-02,\n",
       "        -3.80780372e-02, -3.00215132e-02,  2.38766795e-02,\n",
       "        -7.58623627e-04, -7.46116175e-03, -1.70120398e-02,\n",
       "        -4.30274534e-03,  1.52815351e-02, -9.31141109e-03,\n",
       "        -1.37662434e-02, -7.33577639e-03, -1.83235038e-02,\n",
       "         1.26676805e-02, -5.17396198e-02,  2.03468501e-02,\n",
       "         1.72833516e-02,  2.34713704e-02, -3.54180711e-02],\n",
       "       [-1.26309302e-02,  1.15753954e-02, -4.61689500e-02,\n",
       "        -5.20942598e-02, -4.87602692e-02,  2.07837263e-02,\n",
       "        -3.00590090e-03, -6.39851435e-03, -2.14827736e-03,\n",
       "        -7.16103773e-03,  9.50581591e-03, -3.37104025e-03,\n",
       "        -3.74154689e-03, -1.27189902e-02, -5.26160889e-03,\n",
       "         2.35890757e-02,  5.32816741e-03, -3.05428203e-02,\n",
       "        -4.17402331e-02, -3.29742768e-02,  2.71337987e-02,\n",
       "         2.10765824e-04, -4.35874981e-03, -2.10254683e-02,\n",
       "        -1.07578029e-02,  2.23689981e-02, -6.58076885e-02,\n",
       "         5.54722478e-02, -1.16518993e-02,  5.31500150e-02,\n",
       "        -4.99372357e-02, -4.53057664e-02, -4.12231903e-02,\n",
       "         1.95979884e-02, -3.48394574e-02, -3.84048599e-02],\n",
       "       [-1.70631120e-02,  1.00624621e-02, -4.86082989e-02,\n",
       "        -4.96387364e-02, -4.81922871e-02,  1.75708986e-02,\n",
       "        -4.98478389e-03, -1.00078854e-02, -7.39876266e-03,\n",
       "        -1.30299775e-02,  5.20329782e-03, -5.96398294e-03,\n",
       "        -3.70920005e-03, -1.78309781e-02, -8.58274996e-03,\n",
       "         1.71617879e-02,  1.33478469e-03, -3.12752406e-02,\n",
       "        -2.32217715e-02, -2.86563101e-02,  2.34786072e-02,\n",
       "        -1.75173956e-03, -5.75405249e-03,  4.51275872e-02,\n",
       "        -1.00554599e-02,  1.52062389e-02, -3.62245217e-03,\n",
       "         5.66555753e-02, -1.01147434e-02,  4.90258197e-02,\n",
       "         1.94991890e-02,  1.68903462e-02, -3.92148296e-02,\n",
       "        -5.23691882e-02, -3.70719493e-02,  2.91705313e-02],\n",
       "       [-1.09483532e-02,  1.35906786e-02, -4.48730472e-02,\n",
       "        -5.02169064e-02, -4.98651974e-02,  2.40853703e-02,\n",
       "        -3.81703423e-02,  2.56945367e-02, -9.83359442e-04,\n",
       "         2.82293416e-02, -2.75208078e-02, -6.98834116e-02,\n",
       "         3.23126043e-02,  2.18066166e-02,  3.27397465e-02,\n",
       "        -5.05053511e-02, -6.09958120e-02, -2.78261270e-02,\n",
       "         2.93504323e-02, -2.97610905e-02, -4.05410147e-02,\n",
       "        -6.41203772e-02,  2.81801025e-02,  1.46185511e-02,\n",
       "         2.57292909e-02, -4.92470952e-02, -2.95511963e-02,\n",
       "         2.68068568e-02, -7.81498322e-03,  1.50751239e-02,\n",
       "        -1.26043961e-02,  2.32534110e-02, -3.83098825e-02,\n",
       "        -5.22307754e-02, -3.31894781e-02,  3.72781403e-02],\n",
       "       [-2.57694588e-02, -1.71496446e-03, -4.70785283e-02,\n",
       "        -4.69973751e-02, -5.19371123e-02,  8.50582375e-03,\n",
       "        -1.59244012e-02, -8.16779234e-03, -2.93364016e-03,\n",
       "        -7.84977774e-03, -6.96422878e-03, -2.54143267e-02,\n",
       "         7.70339179e-03, -1.14268832e-02,  9.82235595e-03,\n",
       "        -7.05616956e-03, -6.51740627e-02,  1.33624832e-02,\n",
       "        -2.98926218e-02,  1.74252702e-02, -4.10838060e-02,\n",
       "        -6.78552185e-02, -8.35022360e-03,  3.87049827e-02,\n",
       "        -6.26942283e-03, -5.34403095e-02, -6.57092215e-02,\n",
       "        -1.10005554e-02,  4.97184521e-02, -1.62870991e-02,\n",
       "        -5.01946646e-02, -5.03558958e-02, -3.89532725e-02,\n",
       "         5.10472945e-03, -3.59055290e-02, -3.97747630e-02],\n",
       "       [-3.45613688e-02, -5.29113166e-03, -2.51832045e-03,\n",
       "        -4.34542471e-03,  2.20969238e-03,  3.70553491e-03,\n",
       "        -6.93783812e-02, -7.81258330e-03, -1.27261730e-03,\n",
       "        -7.74517585e-03, -1.44497521e-02, -6.92292132e-02,\n",
       "         2.87497720e-04, -1.33043288e-02,  4.40718931e-02,\n",
       "        -5.15309058e-02, -6.71652767e-02, -2.52011171e-02,\n",
       "         1.22810690e-02, -2.89102331e-02, -3.97006088e-02,\n",
       "        -7.02565971e-02,  4.40185991e-02, -1.53182703e-02,\n",
       "        -6.69007937e-03, -4.81147428e-02, -1.79697275e-02,\n",
       "        -6.96591578e-03, -1.09951430e-02, -1.99041337e-02,\n",
       "        -4.97094106e-02, -2.04468427e-03,  1.00612811e-02,\n",
       "        -1.49381695e-03,  1.15662413e-02,  1.38186144e-02]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mul_log_reg_model = mul_log_reg_train(TRAINING_SET_2D, TRAINING_SET_LABELS)\n",
    "print(mul_log_reg_model.shape)\n",
    "mul_log_reg_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-stanley",
   "metadata": {},
   "source": [
    "# 8. Repeat experiment (6) with your softmax classifier. You can find the formula for applying softmax using NumPy in the documentation for SciPy‚Äôs softmax() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "several-compromise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: A, Target: A, True\n",
      "Prediction: B, Target: B, True\n",
      "Prediction: C, Target: C, True\n",
      "Prediction: D, Target: D, True\n",
      "Prediction: E, Target: E, True\n",
      "Prediction: F, Target: F, True\n",
      "Prediction: G, Target: G, True\n",
      "Prediction: H, Target: H, True\n",
      "Prediction: I, Target: I, True\n",
      "Prediction: J, Target: J, True\n",
      "Prediction: K, Target: K, True\n",
      "Prediction: L, Target: L, True\n",
      "Prediction: M, Target: M, True\n",
      "Prediction: N, Target: N, True\n",
      "Prediction: O, Target: O, True\n",
      "Prediction: P, Target: P, True\n",
      "Prediction: Q, Target: Q, True\n",
      "Prediction: R, Target: R, True\n",
      "Prediction: S, Target: S, True\n",
      "Prediction: T, Target: T, True\n",
      "Prediction: U, Target: U, True\n",
      "Prediction: V, Target: V, True\n",
      "Prediction: W, Target: W, True\n",
      "Prediction: X, Target: X, True\n",
      "Prediction: Y, Target: Y, True\n",
      "Prediction: Z, Target: Z, True\n",
      "Prediction: A, Target: A, True\n",
      "Prediction: B, Target: B, True\n",
      "Prediction: C, Target: C, True\n",
      "Prediction: D, Target: D, True\n",
      "Prediction: E, Target: E, True\n",
      "Prediction: F, Target: F, True\n",
      "Prediction: G, Target: G, True\n",
      "Prediction: H, Target: H, True\n",
      "Prediction: I, Target: I, True\n",
      "Prediction: J, Target: J, True\n",
      "Prediction: K, Target: K, True\n",
      "Prediction: L, Target: L, True\n",
      "Prediction: M, Target: M, True\n",
      "Prediction: N, Target: N, True\n",
      "Prediction: O, Target: O, True\n",
      "Prediction: P, Target: P, True\n",
      "Prediction: Q, Target: Q, True\n",
      "Prediction: R, Target: R, True\n",
      "Prediction: S, Target: S, True\n",
      "Prediction: T, Target: T, True\n",
      "Prediction: U, Target: U, True\n",
      "Prediction: V, Target: V, True\n",
      "Prediction: W, Target: W, True\n",
      "Prediction: X, Target: X, True\n",
      "Prediction: Y, Target: Y, True\n",
      "Prediction: Z, Target: Z, True\n",
      "\n",
      "Accuracy: 52/52 Percentage: 100.00%\n"
     ]
    }
   ],
   "source": [
    "test_model(TRAINING_SET_2D, mul_log_reg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "determined-brazil",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: A, Target: A, True\n",
      "Prediction: B, Target: B, True\n",
      "Prediction: C, Target: C, True\n",
      "Prediction: D, Target: D, True\n",
      "Prediction: E, Target: E, True\n",
      "Prediction: F, Target: F, True\n",
      "Prediction: G, Target: G, True\n",
      "Prediction: H, Target: H, True\n",
      "Prediction: I, Target: I, True\n",
      "Prediction: J, Target: J, True\n",
      "Prediction: K, Target: K, True\n",
      "Prediction: L, Target: L, True\n",
      "Prediction: M, Target: M, True\n",
      "Prediction: N, Target: N, True\n",
      "Prediction: O, Target: O, True\n",
      "Prediction: P, Target: P, True\n",
      "Prediction: Q, Target: Q, True\n",
      "Prediction: R, Target: R, True\n",
      "Prediction: S, Target: S, True\n",
      "Prediction: T, Target: T, True\n",
      "Prediction: U, Target: U, True\n",
      "Prediction: V, Target: V, True\n",
      "Prediction: N, Target: W, False\n",
      "Prediction: X, Target: X, True\n",
      "Prediction: Y, Target: Y, True\n",
      "Prediction: E, Target: Z, False\n",
      "\n",
      "Accuracy: 24/26 Percentage: 92.31%\n"
     ]
    }
   ],
   "source": [
    "test_model(TEST_SET_2D, mul_log_reg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-coating",
   "metadata": {},
   "source": [
    "# 9. Use your trained classifiers to identify the letters in MESSAGE\n",
    "## If you completed Project 1, compare the performance of that project with the performance with these classifiers. If you did not complete Project 1, use the sample code provided above under Libraries and Code.\n",
    "## If you completed Project 2 compare the performance of that project with the performance of these classifiers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "solid-charge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_with_message(model):\n",
    "    DECODED = 'WATCHJEOPARDYALEXTREBEKSFUNTVQUIZGAME'\n",
    "    pred_msg = ''\n",
    "    for letter in MESSAGE_2D:\n",
    "        ascii_idx = np.argmax(np.dot(model, letter))\n",
    "        y_pred = chr(ascii_idx + ord('A'))\n",
    "        pred_msg += y_pred\n",
    "    print(f'MSG : {DECODED}')\n",
    "    print(f'Pred: {pred_msg}')\n",
    "    correct = 0\n",
    "    for true_letter, pred_letter in zip(DECODED, pred_msg):\n",
    "        if true_letter == pred_letter:\n",
    "            correct += 1\n",
    "    print(f'accuracy: {correct/len(DECODED)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "hispanic-patio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSG : WATCHJEOPARDYALEXTREBEKSFUNTVQUIZGAME\n",
      "Pred: OGECWSEGFHPDTATEXJRGSEKCEVNTYJUTEGJME\n",
      "accuracy: 40.54%\n"
     ]
    }
   ],
   "source": [
    "# test with multiclass perceptron model\n",
    "test_model_with_message(mul_pct_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "powerful-capital",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSG : WATCHJEOPARDYALEXTREBEKSFUNTVQUIZGAME\n",
      "Pred: NATCHJFOFARDHALEXTRFBEKSFUNTVQUIEGAME\n",
      "accuracy: 83.78%\n"
     ]
    }
   ],
   "source": [
    "# test with multinomial logistic regresstion model\n",
    "test_model_with_message(mul_log_reg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-mortgage",
   "metadata": {},
   "source": [
    "### Based on our observations, the multiclass perceptron performs worse than the perceptron model in project 1. But, the multinomial logistic regression performs much better than single perceptron model in project 1 \n",
    "- When testing against MESSAGE, the accuracy of single perceptron is around 43.24% in project 1\n",
    "\n",
    "### Compare to project 2, both models do not perform as good as the Sequential Keras model does\n",
    "- When testing against MESSAGE, the accuracy of the model is around 92.30% in project 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
